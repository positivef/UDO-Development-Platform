#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ML Training System - ê¸°ê³„í•™ìŠµ ê¸°ë°˜ íŒ¨í„´ ì¸ì‹ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ
RandomForest ê¸°ë°˜ ë¶ˆí™•ì‹¤ì„± ì˜ˆì¸¡ ëª¨ë¸
"""

import sys
import os
import json
import pickle
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
import logging
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, accuracy_score, r2_score
import joblib

# Windows Unicode ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class TrainingData:
    """í›ˆë ¨ ë°ì´í„° êµ¬ì¡°"""
    features: np.ndarray
    labels: np.ndarray
    metadata: Dict[str, Any]
    timestamp: str = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()


@dataclass
class ModelMetrics:
    """ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    accuracy: float
    mse: float
    r2: float
    cross_val_scores: List[float]
    feature_importance: Dict[str, float]
    training_time: float


class MLTrainingSystem:
    """ML í›ˆë ¨ ì‹œìŠ¤í…œ"""

    def __init__(self, model_dir: str = "../models"):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True, parents=True)

        self.models = {}
        self.scalers = {}
        self.training_history = []
        self.feature_names = []

        # ê¸°ë³¸ ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()

    def _initialize_models(self):
        """ê¸°ë³¸ ëª¨ë¸ ì´ˆê¸°í™”"""
        # ë¶ˆí™•ì‹¤ì„± ì˜ˆì¸¡ ëª¨ë¸
        self.models['uncertainty_predictor'] = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        )

        # Phase ë¶„ë¥˜ ëª¨ë¸
        self.models['phase_classifier'] = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )

        # ì‹ ë¢°ë„ ì˜ˆì¸¡ ëª¨ë¸
        self.models['confidence_predictor'] = RandomForestRegressor(
            n_estimators=150,
            max_depth=15,
            min_samples_split=3,
            random_state=42
        )

        # ê° ëª¨ë¸ìš© ìŠ¤ì¼€ì¼ëŸ¬
        for model_name in self.models.keys():
            self.scalers[model_name] = StandardScaler()

        logger.info(f"Initialized {len(self.models)} ML models")

    def prepare_features(self, raw_data: Dict) -> np.ndarray:
        """ì›ì‹œ ë°ì´í„°ë¥¼ íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜"""
        features = []

        # Phase ì¸ì½”ë”©
        phase_mapping = {
            'ideation': 0, 'design': 1, 'mvp': 2,
            'implementation': 3, 'testing': 4
        }
        features.append(phase_mapping.get(raw_data.get('phase', 'ideation'), 0))

        # ì‹œê°„ì  íŠ¹ì§•
        features.append(raw_data.get('timeline_weeks', 12))
        features.append(raw_data.get('team_size', 5))
        features.append(raw_data.get('budget', 50000) / 10000)  # ìŠ¤ì¼€ì¼ë§

        # ë¶ˆí™•ì‹¤ì„± ì°¨ì›ë“¤
        features.append(raw_data.get('technical_uncertainty', 0.5))
        features.append(raw_data.get('market_uncertainty', 0.5))
        features.append(raw_data.get('resource_uncertainty', 0.3))
        features.append(raw_data.get('timeline_uncertainty', 0.3))
        features.append(raw_data.get('quality_uncertainty', 0.4))

        # ê¸°íƒ€ ë©”íŠ¸ë¦­
        features.append(raw_data.get('code_complexity', 0.5))
        features.append(raw_data.get('test_coverage', 0.0))
        features.append(raw_data.get('architecture_quality', 0.7))
        features.append(len(raw_data.get('files', [])))
        features.append(len(raw_data.get('dependencies', [])))

        # Feature names ì €ì¥ (ì²« ë²ˆì§¸ í˜¸ì¶œì‹œë§Œ)
        if not self.feature_names:
            self.feature_names = [
                'phase', 'timeline_weeks', 'team_size', 'budget_scaled',
                'tech_uncertainty', 'market_uncertainty', 'resource_uncertainty',
                'timeline_uncertainty', 'quality_uncertainty',
                'code_complexity', 'test_coverage', 'architecture_quality',
                'file_count', 'dependency_count'
            ]

        return np.array(features).reshape(1, -1)

    def train_model(
        self,
        model_name: str,
        training_data: TrainingData,
        test_size: float = 0.2
    ) -> ModelMetrics:
        """ëª¨ë¸ í›ˆë ¨"""
        if model_name not in self.models:
            raise ValueError(f"Unknown model: {model_name}")

        logger.info(f"Training {model_name}...")
        start_time = datetime.now()

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            training_data.features,
            training_data.labels,
            test_size=test_size,
            random_state=42
        )

        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scalers[model_name].fit_transform(X_train)
        X_test_scaled = self.scalers[model_name].transform(X_test)

        # ëª¨ë¸ í›ˆë ¨
        self.models[model_name].fit(X_train_scaled, y_train)

        # ì˜ˆì¸¡
        y_pred = self.models[model_name].predict(X_test_scaled)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        if hasattr(self.models[model_name], 'predict_proba'):
            # ë¶„ë¥˜ ëª¨ë¸
            accuracy = accuracy_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            r2 = 0.0  # ë¶„ë¥˜ì—ëŠ” R2 ì‚¬ìš© ì•ˆí•¨
        else:
            # íšŒê·€ ëª¨ë¸
            accuracy = 0.0  # íšŒê·€ì—ëŠ” ì •í™•ë„ ì‚¬ìš© ì•ˆí•¨
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(
            self.models[model_name],
            X_train_scaled,
            y_train,
            cv=5
        )

        # íŠ¹ì§• ì¤‘ìš”ë„
        feature_importance = {}
        if hasattr(self.models[model_name], 'feature_importances_'):
            importances = self.models[model_name].feature_importances_
            for i, name in enumerate(self.feature_names[:len(importances)]):
                feature_importance[name] = float(importances[i])

        # í›ˆë ¨ ì‹œê°„
        training_time = (datetime.now() - start_time).total_seconds()

        # ë©”íŠ¸ë¦­ ìƒì„±
        metrics = ModelMetrics(
            accuracy=accuracy,
            mse=mse,
            r2=r2,
            cross_val_scores=cv_scores.tolist(),
            feature_importance=feature_importance,
            training_time=training_time
        )

        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.training_history.append({
            'model': model_name,
            'timestamp': datetime.now().isoformat(),
            'metrics': asdict(metrics),
            'data_size': len(training_data.features)
        })

        logger.info(f"Training completed: R2={r2:.3f}, MSE={mse:.3f}")

        return metrics

    def predict(
        self,
        model_name: str,
        input_data: Dict
    ) -> Tuple[float, Dict]:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if model_name not in self.models:
            raise ValueError(f"Unknown model: {model_name}")

        # íŠ¹ì§• ì¤€ë¹„
        features = self.prepare_features(input_data)

        # ìŠ¤ì¼€ì¼ë§
        if model_name in self.scalers:
            try:
                features_scaled = self.scalers[model_name].transform(features)
            except:
                # ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì•„ì§ fitë˜ì§€ ì•Šì€ ê²½ìš°
                features_scaled = features
        else:
            features_scaled = features

        # ì˜ˆì¸¡
        prediction = self.models[model_name].predict(features_scaled)[0]

        # ì˜ˆì¸¡ í™•ë¥  (ë¶„ë¥˜ ëª¨ë¸ì˜ ê²½ìš°)
        probabilities = {}
        if hasattr(self.models[model_name], 'predict_proba'):
            proba = self.models[model_name].predict_proba(features_scaled)[0]
            probabilities = {i: float(p) for i, p in enumerate(proba)}

        # ë©”íƒ€ë°ì´í„°
        metadata = {
            'model': model_name,
            'timestamp': datetime.now().isoformat(),
            'features_used': self.feature_names,
            'probabilities': probabilities
        }

        return float(prediction), metadata

    def generate_synthetic_data(self, size: int = 1000) -> TrainingData:
        """í•©ì„± í›ˆë ¨ ë°ì´í„° ìƒì„±"""
        np.random.seed(42)

        features = []
        labels = []

        for _ in range(size):
            # ëœë¤ Phase
            phase = np.random.randint(0, 5)

            # ëœë¤ í”„ë¡œì íŠ¸ íŠ¹ì§•
            timeline = np.random.randint(4, 52)
            team_size = np.random.randint(1, 20)
            budget = np.random.uniform(10000, 500000) / 10000

            # ëœë¤ ë¶ˆí™•ì‹¤ì„±
            uncertainties = np.random.uniform(0, 1, 5)

            # ê¸°íƒ€ ë©”íŠ¸ë¦­
            complexity = np.random.uniform(0, 1)
            coverage = np.random.uniform(0, 1)
            quality = np.random.uniform(0, 1)
            files = np.random.randint(0, 100)
            deps = np.random.randint(0, 50)

            # íŠ¹ì§• ë²¡í„°
            feature_vector = np.concatenate([
                [phase, timeline, team_size, budget],
                uncertainties,
                [complexity, coverage, quality, files, deps]
            ])
            features.append(feature_vector)

            # ë ˆì´ë¸” (ì‹ ë¢°ë„ - ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
            confidence = 0.5
            confidence += (1 - uncertainties.mean()) * 0.3  # ë‚®ì€ ë¶ˆí™•ì‹¤ì„±
            confidence += coverage * 0.2  # ë†’ì€ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
            confidence += quality * 0.1  # ë†’ì€ í’ˆì§ˆ
            confidence = np.clip(confidence, 0, 1)
            labels.append(confidence)

        return TrainingData(
            features=np.array(features),
            labels=np.array(labels),
            metadata={'synthetic': True, 'size': size}
        )

    def save_models(self):
        """ëª¨ë“  ëª¨ë¸ ì €ì¥"""
        for model_name, model in self.models.items():
            model_path = self.model_dir / f"{model_name}.pkl"
            joblib.dump(model, model_path)

            # ìŠ¤ì¼€ì¼ëŸ¬ë„ ì €ì¥
            if model_name in self.scalers:
                scaler_path = self.model_dir / f"{model_name}_scaler.pkl"
                joblib.dump(self.scalers[model_name], scaler_path)

        # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥
        history_path = self.model_dir / "training_history.json"
        with open(history_path, 'w') as f:
            json.dump(self.training_history, f, indent=2)

        logger.info(f"Saved {len(self.models)} models to {self.model_dir}")

    def load_models(self):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        loaded = 0
        for model_file in self.model_dir.glob("*.pkl"):
            if "_scaler" not in model_file.stem:
                model_name = model_file.stem
                self.models[model_name] = joblib.load(model_file)

                # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
                scaler_file = self.model_dir / f"{model_name}_scaler.pkl"
                if scaler_file.exists():
                    self.scalers[model_name] = joblib.load(scaler_file)

                loaded += 1

        # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ë¡œë“œ
        history_path = self.model_dir / "training_history.json"
        if history_path.exists():
            with open(history_path, 'r') as f:
                self.training_history = json.load(f)

        logger.info(f"Loaded {loaded} models from {self.model_dir}")

    def get_model_report(self) -> Dict:
        """ëª¨ë¸ ìƒíƒœ ë³´ê³ ì„œ"""
        report = {
            'models': {},
            'training_history': len(self.training_history),
            'last_training': None
        }

        for model_name, model in self.models.items():
            report['models'][model_name] = {
                'type': model.__class__.__name__,
                'trained': hasattr(model, 'n_features_in_'),
                'features': getattr(model, 'n_features_in_', 0)
            }

        if self.training_history:
            report['last_training'] = self.training_history[-1]

        return report


def demo():
    """ë°ëª¨ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ¤– ML Training System Demo")
    print("=" * 60)

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ml_system = MLTrainingSystem()

    # í•©ì„± ë°ì´í„° ìƒì„±
    print("\nğŸ“Š Generating synthetic training data...")
    training_data = ml_system.generate_synthetic_data(size=500)
    print(f"  Generated {len(training_data.features)} samples")

    # ê° ëª¨ë¸ í›ˆë ¨
    models_to_train = ['uncertainty_predictor', 'confidence_predictor']

    for model_name in models_to_train:
        print(f"\nğŸ¯ Training {model_name}...")
        metrics = ml_system.train_model(model_name, training_data)

        print(f"  RÂ² Score: {metrics.r2:.3f}")
        print(f"  MSE: {metrics.mse:.3f}")
        print(f"  Training time: {metrics.training_time:.2f}s")

        # Top 3 ì¤‘ìš” íŠ¹ì§•
        if metrics.feature_importance:
            sorted_features = sorted(
                metrics.feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:3]
            print("  Top features:")
            for feat, imp in sorted_features:
                print(f"    - {feat}: {imp:.3f}")

    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\nğŸ”® Testing predictions...")
    test_input = {
        'phase': 'ideation',
        'timeline_weeks': 12,
        'team_size': 5,
        'budget': 50000,
        'technical_uncertainty': 0.7,
        'market_uncertainty': 0.6,
        'resource_uncertainty': 0.3,
        'timeline_uncertainty': 0.4,
        'quality_uncertainty': 0.5
    }

    for model_name in models_to_train:
        prediction, metadata = ml_system.predict(model_name, test_input)
        print(f"  {model_name}: {prediction:.3f}")

    # ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ Saving models...")
    ml_system.save_models()

    # ìƒíƒœ ë³´ê³ 
    print("\nğŸ“ˆ Model Report:")
    report = ml_system.get_model_report()
    for model_name, info in report['models'].items():
        status = "âœ… Trained" if info['trained'] else "âš ï¸ Not trained"
        print(f"  {model_name}: {status} ({info['type']})")

    print("\n" + "=" * 60)
    print("Demo completed!")


if __name__ == "__main__":
    demo()