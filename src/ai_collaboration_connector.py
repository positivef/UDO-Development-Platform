#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Collaboration Connector - ì‹¤ì œ AI ì„œë¹„ìŠ¤ ì—°ë™
Codex MCP, Claude, Gemini í†µí•©
"""

import sys
import os
import json
import asyncio
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum
import subprocess
import logging

# Windows Unicode ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AIService(Enum):
    """AI ì„œë¹„ìŠ¤ íƒ€ì…"""
    CLAUDE = "claude"
    CODEX = "codex"
    GEMINI = "gemini"
    LOCAL = "local"


@dataclass
class AIRequest:
    """AI ìš”ì²­ ë°ì´í„° í´ë˜ìŠ¤"""
    service: AIService
    prompt: str
    context: Dict[str, Any]
    max_tokens: int = 2000
    temperature: float = 0.7
    timeout: int = 30


@dataclass
class AIResponse:
    """AI ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    service: AIService
    content: str
    metadata: Dict[str, Any]
    execution_time: float
    success: bool
    error: Optional[str] = None


class CodexMCPConnector:
    """Codex MCP ì„œë²„ ì—°ê²° ê´€ë¦¬ì"""

    def __init__(self):
        self.connected = False
        self.last_response = None

    def ping(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # MCPë¥¼ í†µí•œ ping í…ŒìŠ¤íŠ¸
            result = self._execute_mcp_command("ping", {"message": "health_check"})
            self.connected = result is not None
            return self.connected
        except Exception as e:
            logger.error(f"Codex ping failed: {e}")
            self.connected = False
            return False

    def execute(self, prompt: str, context: Dict = None) -> Dict:
        """Codex ì‹¤í–‰"""
        try:
            if not self.connected and not self.ping():
                raise ConnectionError("Codex MCP not available")

            # MCPë¥¼ í†µí•œ Codex ì‹¤í–‰
            params = {
                "prompt": prompt,
                "context": context or {},
                "mode": "development"
            }

            result = self._execute_mcp_command("codex", params)
            return {
                "success": True,
                "content": result.get("output", ""),
                "metadata": result.get("metadata", {})
            }
        except Exception as e:
            logger.error(f"Codex execution failed: {e}")
            return {
                "success": False,
                "content": "",
                "error": str(e)
            }

    def _execute_mcp_command(self, command: str, params: Dict) -> Optional[Dict]:
        """MCP ëª…ë ¹ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ êµ¬í˜„ì‹œ MCP API í˜¸ì¶œ
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
        if command == "ping":
            return {"status": "ok", "timestamp": datetime.now().isoformat()}
        elif command == "codex":
            # Codex ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
            return {
                "output": f"# Codex Analysis\n{params.get('prompt', '')}",
                "metadata": {
                    "service": "codex-mcp",
                    "timestamp": datetime.now().isoformat()
                }
            }
        return None


class GeminiAPIConnector:
    """Gemini API ì—°ê²° ê´€ë¦¬ì"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"
        self.connected = False

    def validate_connection(self) -> bool:
        """ì—°ê²° ìœ íš¨ì„± ê²€ì¦"""
        if not self.api_key:
            logger.warning("Gemini API key not found")
            return False

        # ì‹¤ì œ êµ¬í˜„ì‹œ API ì—°ê²° í…ŒìŠ¤íŠ¸
        self.connected = True  # ì‹œë®¬ë ˆì´ì…˜
        return self.connected

    def generate(self, prompt: str, context: Dict = None) -> Dict:
        """Gemini í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            if not self.connected and not self.validate_connection():
                raise ConnectionError("Gemini API not available")

            # ì‹¤ì œ êµ¬í˜„ì‹œ Gemini API í˜¸ì¶œ
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
            return {
                "success": True,
                "content": f"[Gemini Response]\n{prompt[:100]}...",
                "metadata": {
                    "model": "gemini-pro",
                    "timestamp": datetime.now().isoformat()
                }
            }
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            return {
                "success": False,
                "content": "",
                "error": str(e)
            }


class AICollaborationConnector:
    """í†µí•© AI í˜‘ì—… ì—°ê²° ê´€ë¦¬ì"""

    def __init__(self):
        self.codex = CodexMCPConnector()
        self.gemini = GeminiAPIConnector()
        self.services_status = {}
        self.execution_history = []

        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self._initialize_services()

    def _initialize_services(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ìƒíƒœ í™•ì¸"""
        logger.info("Initializing AI services...")

        # Codex MCP í™•ì¸
        self.services_status[AIService.CODEX] = self.codex.ping()
        logger.info(f"Codex MCP: {'âœ… Connected' if self.services_status[AIService.CODEX] else 'âŒ Not available'}")

        # Gemini API í™•ì¸
        self.services_status[AIService.GEMINI] = self.gemini.validate_connection()
        logger.info(f"Gemini API: {'âœ… Connected' if self.services_status[AIService.GEMINI] else 'âŒ Not available'}")

        # ClaudeëŠ” í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
        self.services_status[AIService.CLAUDE] = True
        logger.info(f"Claude: âœ… Available (current context)")

        # Local ì‹¤í–‰ì€ í•­ìƒ ê°€ëŠ¥
        self.services_status[AIService.LOCAL] = True
        logger.info(f"Local: âœ… Available")

    def execute_request(self, request: AIRequest) -> AIResponse:
        """AI ìš”ì²­ ì‹¤í–‰"""
        start_time = datetime.now()

        try:
            # ì„œë¹„ìŠ¤ë³„ ì‹¤í–‰
            if request.service == AIService.CODEX:
                result = self._execute_codex(request)
            elif request.service == AIService.GEMINI:
                result = self._execute_gemini(request)
            elif request.service == AIService.CLAUDE:
                result = self._execute_claude(request)
            else:
                result = self._execute_local(request)

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = (datetime.now() - start_time).total_seconds()

            # ì‘ë‹µ ìƒì„±
            response = AIResponse(
                service=request.service,
                content=result.get("content", ""),
                metadata=result.get("metadata", {}),
                execution_time=execution_time,
                success=result.get("success", False),
                error=result.get("error")
            )

            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self._save_to_history(request, response)

            return response

        except Exception as e:
            logger.error(f"Request execution failed: {e}")
            return AIResponse(
                service=request.service,
                content="",
                metadata={},
                execution_time=(datetime.now() - start_time).total_seconds(),
                success=False,
                error=str(e)
            )

    def _execute_codex(self, request: AIRequest) -> Dict:
        """Codex ì‹¤í–‰"""
        if not self.services_status.get(AIService.CODEX):
            return {"success": False, "error": "Codex not available"}

        return self.codex.execute(request.prompt, request.context)

    def _execute_gemini(self, request: AIRequest) -> Dict:
        """Gemini ì‹¤í–‰"""
        if not self.services_status.get(AIService.GEMINI):
            return {"success": False, "error": "Gemini not available"}

        return self.gemini.generate(request.prompt, request.context)

    def _execute_claude(self, request: AIRequest) -> Dict:
        """Claude ì‹¤í–‰ (í˜„ì¬ ì»¨í…ìŠ¤íŠ¸)"""
        # ClaudeëŠ” í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì»¨í…ìŠ¤íŠ¸
        return {
            "success": True,
            "content": f"[Claude would process]: {request.prompt[:100]}...",
            "metadata": {"context": "current"}
        }

    def _execute_local(self, request: AIRequest) -> Dict:
        """ë¡œì»¬ ì‹¤í–‰ (í´ë°±)"""
        # ê°„ë‹¨í•œ ë¡œì»¬ ì²˜ë¦¬
        return {
            "success": True,
            "content": f"[Local processing]: {request.prompt[:50]}...",
            "metadata": {"fallback": True}
        }

    def _save_to_history(self, request: AIRequest, response: AIResponse):
        """ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        self.execution_history.append({
            "timestamp": datetime.now().isoformat(),
            "request": asdict(request),
            "response": asdict(response)
        })

        # ìµœëŒ€ 100ê°œ ìœ ì§€
        if len(self.execution_history) > 100:
            self.execution_history = self.execution_history[-100:]

    def orchestrate_collaboration(self, task: str, phase: str) -> Dict:
        """ë©€í‹° AI í˜‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
        logger.info(f"Orchestrating collaboration for phase: {phase}")
        results = {}

        # Phaseë³„ AI ì¡°í•© ê²°ì •
        if phase == "ideation":
            # Ideation: Claude (ì°½ì˜ì„±) + Gemini (ë¶„ì„)
            services = [AIService.CLAUDE, AIService.GEMINI]
        elif phase == "design":
            # Design: Codex (ì•„í‚¤í…ì²˜) + Claude (ê²€í† )
            services = [AIService.CODEX, AIService.CLAUDE]
        elif phase in ["mvp", "implementation"]:
            # Implementation: Codex (ì½”ë”©) + Claude (ìµœì í™”)
            services = [AIService.CODEX, AIService.CLAUDE]
        elif phase == "testing":
            # Testing: ëª¨ë“  AI í˜‘ì—…
            services = [AIService.CODEX, AIService.GEMINI, AIService.CLAUDE]
        else:
            services = [AIService.LOCAL]

        # ê° ì„œë¹„ìŠ¤ ì‹¤í–‰
        for service in services:
            if self.services_status.get(service, False):
                request = AIRequest(
                    service=service,
                    prompt=task,
                    context={"phase": phase}
                )
                response = self.execute_request(request)
                results[service.value] = {
                    "content": response.content,
                    "success": response.success,
                    "time": response.execution_time
                }

        # ì¢…í•© ê²°ê³¼ ìƒì„±
        return {
            "phase": phase,
            "task": task,
            "services_used": [s.value for s in services],
            "results": results,
            "timestamp": datetime.now().isoformat()
        }

    def get_status_report(self) -> Dict:
        """ì„œë¹„ìŠ¤ ìƒíƒœ ë³´ê³ ì„œ"""
        return {
            "services": {
                service.value: {
                    "available": status,
                    "status": "âœ… Connected" if status else "âŒ Not available"
                }
                for service, status in self.services_status.items()
            },
            "history_count": len(self.execution_history),
            "last_execution": self.execution_history[-1] if self.execution_history else None
        }


def demo():
    """ë°ëª¨ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ¤– AI Collaboration Connector Demo")
    print("=" * 60)

    # ì»¤ë„¥í„° ì´ˆê¸°í™”
    connector = AICollaborationConnector()

    # ìƒíƒœ ë³´ê³ 
    print("\nğŸ“Š Service Status:")
    status = connector.get_status_report()
    for service, info in status["services"].items():
        print(f"  {service}: {info['status']}")

    # Phaseë³„ í˜‘ì—… í…ŒìŠ¤íŠ¸
    phases = ["ideation", "design", "implementation", "testing"]

    for phase in phases:
        print(f"\nğŸ¯ Testing {phase.upper()} phase:")
        result = connector.orchestrate_collaboration(
            task=f"Test task for {phase}",
            phase=phase
        )

        print(f"  Services used: {', '.join(result['services_used'])}")
        for service, res in result['results'].items():
            status = "âœ…" if res['success'] else "âŒ"
            print(f"    {service}: {status} ({res['time']:.2f}s)")

    print("\n" + "=" * 60)
    print("Demo completed!")


if __name__ == "__main__":
    demo()