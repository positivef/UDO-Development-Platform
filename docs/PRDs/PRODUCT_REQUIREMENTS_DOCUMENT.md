# Product Requirements Document (PRD)
# UDO Development Platform v3.0

**Document Version**: 1.0
**Date**: 2025-11-19
**Status**: Active Development (45% Complete)
**Target Completion**: 2025-12-19 (1 month, 85% milestone)

---

## Executive Summary

### The Problem: Chaos in Multi-Project Development

Modern developers juggle multiple projects simultaneously, each with different contexts, states, and workflows. Current tools lack:

1. **Context Preservation**: Switching projects loses UDO state, ML models, AI preferences
2. **Workflow Continuity**: No seamless transition from web dashboard to CLI development
3. **Uncertainty Management**: No systematic approach to development risk mitigation
4. **Knowledge Retention**: Past solutions and patterns are not captured for reuse
5. **Quality Visibility**: Code quality metrics scattered across multiple tools

**Impact**: Developers waste 30-40% of time on context switching, setup, and rediscovering solutions.

### The Solution: UDO Development Platform

A unified development orchestrator that combines:

- **Predictive Uncertainty Modeling** (World's first 24-hour development uncertainty prediction)
- **Multi-Project Context Management** (Seamless project switching with complete state restoration)
- **CLI-Dashboard Integration** (Continue development from where you left off)
- **AI Collaboration Bridge** (Claude + Codex + Gemini orchestration)
- **Automated Quality Monitoring** (Real-time code quality and test coverage)

### Success Metrics (1 Month Goal)

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| **Overall Completion** | 45% | 85% | ğŸŸ¡ On Track |
| **Backend Implementation** | 95% | 100% | ğŸŸ¢ Ahead |
| **Frontend Implementation** | 30% | 75% | ğŸ”´ Behind |
| **Database Integration** | 0% | 90% | ğŸ”´ Critical |
| **E2E Testing** | 0% | 80% | ğŸ”´ Critical |
| **Type Safety** | 40% | 90% | ğŸ”´ Critical |

**Risk Assessment**: MEDIUM-HIGH (Backend strong, Frontend/Database/Testing critical gaps)

---

## Problem Statement

### Current Pain Points

#### 1. Context Fragmentation (Severity: CRITICAL)

**Problem**: Developers lose critical context when switching between projects:
- UDO system state (last decision, confidence, quantum state)
- ML model training data and predictions
- AI collaboration preferences (temperature, model selection)
- Editor state (open files, cursor positions, breakpoints)

**Evidence**:
- Average context restoration time: 15-20 minutes per switch
- Daily project switches: 3-5 times
- **Lost Productivity**: 45-100 minutes/day (18-25% of workday)

**User Quote**: *"Every time I switch projects, I have to remember what phase I was in, what the UDO recommended, and which AI model worked best. It's exhausting."*

#### 2. Dashboard-CLI Disconnect (Severity: HIGH)

**Problem**: No way to continue development from dashboard to CLI:
- Dashboard shows project status but requires manual CLI setup
- No "Continue in CLI" functionality
- Task context not preserved between sessions

**Evidence**:
- 100% of users manually copy project paths and setup commands
- Average CLI setup time: 5-8 minutes
- **Frustration Score**: 8/10 in user interviews

#### 3. Uncertainty Blindness (Severity: HIGH)

**Problem**: Developers make decisions without understanding uncertainty levels:
- No visibility into technical, market, resource, timeline, quality risks
- No predictive modeling for future uncertainty evolution
- No auto-generated mitigation strategies

**Evidence**:
- 40% of projects experience unexpected delays due to unmitigated uncertainties
- Average delay: 2-4 weeks per project
- **Cost Impact**: $50,000-$200,000 per project

#### 4. Knowledge Loss (Severity: MEDIUM)

**Problem**: Solutions to recurring problems are not captured:
- Prompt history scattered across sessions
- Code changes not linked to prompts
- No ML-based similarity recommendations

**Evidence**:
- Same problems solved 3-5 times across projects
- Average rediscovery time: 30-60 minutes per issue
- **Wasted Effort**: 5-10 hours/month per developer

#### 5. Quality Opacity (Severity: MEDIUM)

**Problem**: Code quality metrics are invisible or fragmented:
- Manual Pylint/ESLint execution required
- Test coverage not tracked automatically
- No unified quality dashboard

**Evidence**:
- Code quality checks performed only 20% of the time
- Average quality-related bugs: 15-25 per project
- **Rework Cost**: 20-30 hours per project

---

## Goals & Success Metrics

### Primary Goals (1 Month - 85% Completion)

#### Goal 1: Complete Backend Infrastructure (95% â†’ 100%)
**Current**: API endpoints, services, models 95% complete
**Gap**: Type safety, database integration, error handling edge cases

**Success Criteria**:
- âœ… All API endpoints have complete type definitions (TypeScript + Pydantic)
- âœ… PostgreSQL fully integrated with connection pooling
- âœ… 90%+ test coverage for backend services
- âœ… OpenAPI 3.0 spec 100% accurate

**Timeline**: Week 1 (Nov 19-26)

#### Goal 2: Complete Frontend Implementation (30% â†’ 75%)
**Current**: Dashboard skeleton, 2/7 components complete
**Gap**: 5 major components missing (TaskList, CLI Integration, History, Kanban, UDO State)

**Success Criteria**:
- âœ… Task List with "Continue in CLI" button
- âœ… Project Context Selector (visual state restoration)
- âœ… History Search (prompt + code changes)
- âœ… Kanban Board (basic drag-and-drop)
- âœ… UDO State Panel (uncertainty visualization)

**Timeline**: Week 2-3 (Nov 26-Dec 10)

#### Goal 3: Database Integration (0% â†’ 90%)
**Current**: Schema designed, migrations ready, no runtime integration
**Gap**: All backend services use mock data, no real persistence

**Success Criteria**:
- âœ… PostgreSQL running locally or via Docker
- âœ… All 7 tables populated with real data
- âœ… Backend services use database (not mock services)
- âœ… Database health check in /api/health endpoint
- âœ… Migration rollback tested

**Timeline**: Week 1 (Nov 19-26) - CRITICAL PATH

#### Goal 4: E2E Testing (0% â†’ 80%)
**Current**: Backend unit tests only (60% coverage), no frontend/integration tests
**Gap**: Critical user journeys untested

**Success Criteria**:
- âœ… Backend integration tests (API + Database)
- âœ… Frontend component tests (React Testing Library)
- âœ… E2E tests for 5 critical user journeys (Playwright)
- âœ… CI/CD pipeline with automated testing

**Timeline**: Week 3-4 (Dec 3-17)

#### Goal 5: Type Safety (40% â†’ 90%)
**Current**: Backend Pydantic models, Frontend partial types
**Gap**: Frontend API client types, missing TypeScript strict mode

**Success Criteria**:
- âœ… TypeScript strict mode enabled
- âœ… All API responses typed (generated from OpenAPI)
- âœ… No `any` types in critical paths
- âœ… Zod validation for runtime type safety

**Timeline**: Week 2 (Nov 26-Dec 3)

### Secondary Goals (Phase 2 - Beyond 1 Month)

#### Goal 6: AI Collaboration Integration
**Current**: Mock integration, no real API calls
**Target**: Real-time Claude + Codex + Gemini orchestration

#### Goal 7: ML Training System
**Current**: Mock predictions
**Target**: Real ML models trained on actual project data

#### Goal 8: Production Deployment
**Current**: Local development only
**Target**: Cloud deployment (AWS/GCP) with CI/CD

---

## User Personas & Use Cases

### Persona 1: Solo Developer (Primary, 60% of users)

**Profile**:
- Name: Alex Chen
- Experience: 5-7 years
- Projects: 3-5 active projects simultaneously
- Tech Stack: Full-stack (Python/FastAPI, TypeScript/React, PostgreSQL)
- Pain Point: Context switching overhead

**Goals**:
- Quickly switch between projects without losing context
- See project health at a glance
- Continue development from dashboard to CLI seamlessly
- Track quality metrics automatically

**Use Cases**:

#### UC1: Morning Project Review (Frequency: Daily)
```
1. Alex opens UDO Dashboard at 9am
2. Sees 3 active projects with status:
   - ProjectA: Ideation phase, 75% confidence, ğŸŸ¢ Deterministic
   - ProjectB: Implementation, 60% confidence, ğŸŸ  Quantum
   - ProjectC: Testing, 85% confidence, ğŸ”µ Probabilistic
3. Clicks ProjectB (highest uncertainty)
4. Reviews UDO recommendations:
   - "Add integration tests for auth module" (ROI: 4.2x)
   - "Refactor database queries for performance" (ROI: 3.1x)
5. Clicks "Continue in CLI" button
6. CLI opens with project context restored:
   - Last open files: auth.py, test_auth.py
   - Current phase: Implementation
   - Pending task: "Add JWT refresh token logic"
7. Alex continues coding immediately (0 setup time)
```

**Success Metric**: Context restoration time reduced from 15min â†’ 30sec (97% reduction)

#### UC2: Uncertainty-Driven Development (Frequency: 2-3x/week)
```
1. Alex starts new feature: "Add payment processing"
2. UDO evaluates uncertainty:
   - Technical: 0.7 (Quantum state, 3rd-party API integration)
   - Market: 0.3 (Probabilistic, validated demand)
   - Resource: 0.4 (Probabilistic, 40 hours estimated)
   - Timeline: 0.5 (Quantum, 1-2 weeks range)
   - Quality: 0.6 (Chaotic, security-critical code)
3. Overall Uncertainty: 0.54 (ğŸŸ  Quantum)
4. UDO predicts 24h evolution: 0.48 (decreasing trend)
5. Auto-generated mitigations:
   - "Research Stripe API integration patterns" (8h, -0.3 uncertainty, ROI: 3.75x)
   - "Create payment sandbox for testing" (4h, -0.2 uncertainty, ROI: 5.0x)
   - "Review PCI compliance checklist" (2h, -0.1 uncertainty, ROI: 5.0x)
6. Alex executes highest ROI mitigation first
7. Re-evaluates: Uncertainty dropped to 0.41 (ğŸ”µ Probabilistic)
8. UDO decision: "GO_WITH_CHECKPOINTS"
9. Alex proceeds with confidence
```

**Success Metric**: Unexpected delays reduced by 40% (from 40% â†’ 24% of projects)

#### UC3: Quality-Driven Refactoring (Frequency: Weekly)
```
1. Alex completes feature implementation
2. Dashboard shows quality metrics:
   - Python Code Quality: 7.8/10 (Pylint)
   - TypeScript Code Quality: 8.5/10 (ESLint)
   - Test Coverage: 72% (below 80% threshold)
   - Overall Quality: 7.6/10 (ğŸŸ¡ Warning)
3. Quality panel highlights issues:
   - "auth.py: Cyclomatic complexity 15 (max 10)"
   - "utils.py: Missing docstrings for 5 functions"
   - "test_payment.py: Not covered by tests"
4. Alex clicks "Fix Priority Issues" button
5. UDO generates refactoring tasks:
   - "Split auth.py validate_token() into 3 smaller functions"
   - "Add docstrings to utils.py functions"
   - "Create test_payment.py with 5 test cases"
6. Alex completes refactoring
7. Re-runs quality check: 8.9/10, 85% coverage (âœ… Pass)
8. Commits with confidence
```

**Success Metric**: Code quality score improved from 7.2/10 â†’ 8.5/10 average

---

### Persona 2: Team Lead (Secondary, 30% of users)

**Profile**:
- Name: Jordan Lee
- Experience: 10+ years, managing 3-5 developers
- Projects: Oversees 5-10 projects
- Pain Point: Visibility into team progress and quality

**Goals**:
- Monitor all projects at a glance
- Identify high-risk projects early
- Enforce quality standards
- Track team velocity and blockers

**Use Cases**:

#### UC4: Weekly Project Health Review (Frequency: Weekly)
```
1. Jordan opens UDO Dashboard on Monday
2. Views Project Overview (grid view):
   - 10 projects with traffic light status
   - 2 projects ğŸ”´ (high uncertainty or low quality)
   - 5 projects ğŸŸ¡ (medium risk)
   - 3 projects ğŸŸ¢ (on track)
3. Clicks Project "Mobile App Redesign" (ğŸ”´)
4. Sees:
   - Uncertainty: 0.78 (Chaotic state)
   - Quality: 6.2/10 (below threshold)
   - Last Active: 3 days ago (stalled)
   - Blockers: "Waiting for design approval"
5. Jordan assigns mitigation:
   - "Schedule design review meeting (Priority: High)"
   - "Add interim developer to unblock"
6. Updates project in Kanban board
7. Moves to next high-risk project
```

**Success Metric**: High-risk project identification time reduced from 2 hours â†’ 15 minutes (88% reduction)

---

### Persona 3: AI-Assisted Developer (Emerging, 10% of users)

**Profile**:
- Name: Riley Martinez
- Experience: 3-5 years, AI-native developer
- Projects: 2-3 AI/ML projects
- Pain Point: Manual AI tool orchestration

**Goals**:
- Let AI handle repetitive decisions
- Focus on creative problem-solving
- Learn from AI-generated patterns
- Continuously improve AI collaboration

**Use Cases**:

#### UC5: AI-Driven Development (Frequency: Daily)
```
1. Riley starts task: "Optimize database queries"
2. UDO analyzes codebase and prompts:
   - Claude: "Generate optimization strategy"
   - Codex: "Review SQL queries for N+1 problems"
   - Gemini: "Validate optimization safety"
3. AI Collaboration Bridge orchestrates:
   - Claude identifies 3 optimization opportunities
   - Codex flags 5 N+1 queries in user.py
   - Gemini confirms changes won't break tests
4. UDO presents unified recommendations:
   - "Add database index on users.email (ROI: 10x, Risk: Low)"
   - "Batch load user permissions (ROI: 5x, Risk: Medium)"
   - "Cache frequently accessed settings (ROI: 3x, Risk: Low)"
5. Riley approves recommendations
6. UDO executes changes with AI assistance
7. Runs tests (100% pass)
8. Commits optimizations
9. Performance improved 8x (validated by benchmarks)
```

**Success Metric**: AI-assisted task completion time reduced by 60% (from 4 hours â†’ 1.5 hours)

---

## Functional Requirements

### P0 (Critical - Must Have for 1 Month Goal)

#### FR1: Project Context Management

**Description**: Save and restore complete project context including UDO state, ML models, AI preferences, and editor state.

**User Story**: As a developer, I want to switch projects without losing any context, so that I can resume work immediately.

**Acceptance Criteria**:
- [ ] User can save project context via API or auto-save
- [ ] Context includes:
  - [ ] UDO state (decision, confidence, quantum_state, uncertainty_map)
  - [ ] ML models (paths, configs, training history)
  - [ ] AI preferences (model, temperature, max_tokens)
  - [ ] Editor state (open files, cursor positions, breakpoints)
  - [ ] Recent executions (last 10 tasks with results)
- [ ] User can switch projects from dashboard dropdown
- [ ] Switching auto-saves current project, loads new project
- [ ] Context restoration takes <2 seconds
- [ ] Failed restoration shows graceful error with partial state

**Technical Specs**:
- API Endpoints:
  - `POST /api/project-context/save`
  - `GET /api/project-context/load/{project_id}`
  - `POST /api/project-context/switch`
- Database Table: `project_contexts` (JSONB fields)
- Service: `ProjectContextService` (UPSERT pattern)

**Dependencies**: FR2 (Database Integration), FR6 (Frontend Selector)

**Risks**:
- JSONB size limits (mitigation: compress large ML models)
- Stale context after system updates (mitigation: version compatibility checks)

**Test Cases**:
1. Save context with full state â†’ Verify all fields stored
2. Load context â†’ Verify all fields restored correctly
3. Switch projects â†’ Verify auto-save and load sequence
4. Load missing context â†’ Verify graceful degradation
5. FIFO execution history â†’ Verify max 10 items maintained

**Uncertainty**: ğŸ”µ Probabilistic (70% success, JSONB compression unknown)

---

#### FR2: Database Integration (PostgreSQL)

**Description**: Fully integrate PostgreSQL for all data persistence, replacing mock services.

**User Story**: As a platform, I want to persist all data in PostgreSQL, so that state survives restarts and is shareable.

**Acceptance Criteria**:
- [ ] PostgreSQL running (local or Docker)
- [ ] All 7 tables operational:
  - [ ] `projects` (project info)
  - [ ] `project_contexts` (saved states)
  - [ ] `task_history` (prompt/code history)
  - [ ] `version_history` (Git commits)
  - [ ] `kanban_boards` (task boards)
  - [ ] `kanban_cards` (task cards)
  - [ ] `quality_metrics` (quality snapshots)
- [ ] Migration system working (run, rollback)
- [ ] Connection pooling (2-10 connections)
- [ ] Health check includes database status
- [ ] All backend services use database (no mocks)
- [ ] Graceful degradation when database unavailable

**Technical Specs**:
- Database: PostgreSQL 14+
- Driver: asyncpg (async) + psycopg2 (sync migrations)
- Connection Pool: 2-10 connections
- Timeouts: 5s connection, 10s command
- Migrations: Sequential versioning (001, 002, etc.)

**Dependencies**: Week 0 Schema (âœ… Complete)

**Risks**:
- Database setup complexity for users (mitigation: Docker Compose)
- Migration failures (mitigation: rollback scripts + backups)
- Connection pool exhaustion (mitigation: monitoring + alerts)

**Test Cases**:
1. Start server without DB â†’ Verify graceful degradation
2. Start server with DB â†’ Verify all services operational
3. Run migrations â†’ Verify all tables created
4. Rollback migrations â†’ Verify clean removal
5. Connection pool stress test â†’ Verify no deadlocks
6. Database crash â†’ Verify auto-reconnect

**Uncertainty**: ğŸŸ  Quantum (60% success, user environment variability)

---

#### FR3: Task List & CLI Integration

**Description**: Display active development tasks with "Continue in CLI" functionality.

**User Story**: As a developer, I want to see my tasks in the dashboard and continue them in CLI with one click, so that I don't waste time on manual setup.

**Acceptance Criteria**:
- [ ] Dashboard shows task list:
  - [ ] Task title, project, phase
  - [ ] Current step (e.g., "Creating middleware")
  - [ ] Completeness percentage
  - [ ] Status (pending/in_progress/completed)
- [ ] User can click "Continue in CLI" button
- [ ] Button action:
  - [ ] Plan A: Deep link (claude-code://continue?task={id})
  - [ ] Plan B: Copy command to clipboard
  - [ ] Plan C: Display context in modal (fallback)
- [ ] Task detail modal shows:
  - [ ] TODO groups and items
  - [ ] Acceptance criteria
  - [ ] Related files
  - [ ] Recent prompt history
- [ ] CLI receives context and resumes work

**Technical Specs**:
- API Endpoints:
  - `GET /api/tasks` (list all tasks)
  - `GET /api/tasks/{task_id}/context` (CLI handoff)
- Frontend Components:
  - `TaskList.tsx` (list view)
  - `TaskDetails.tsx` (detail modal)
  - `ContinueInCLI.tsx` (button + clipboard)

**Dependencies**: FR1 (Context Management), FR4 (Task Planning)

**Risks**:
- Deep link registration fails (mitigation: Plan B/C fallbacks)
- CLI doesn't receive context (mitigation: error handling + logs)
- Task context too large (mitigation: compression + pagination)

**Test Cases**:
1. List tasks â†’ Verify all fields displayed
2. Click "Continue in CLI" â†’ Verify command copied or deep link opened
3. Load task context â†’ Verify all fields present
4. Task with missing files â†’ Verify graceful error
5. Task with 100+ TODOs â†’ Verify pagination

**Uncertainty**: ğŸŸ  Quantum (50% success, deep link platform-dependent)

---

#### FR4: Task Planning & TODO Management

**Description**: Track TODO groups, items, subtasks, and acceptance criteria for each task.

**User Story**: As a developer, I want to see what needs to be done and track progress, so that I don't forget steps or miss acceptance criteria.

**Acceptance Criteria**:
- [ ] Task contains TODO groups (e.g., "Setup", "Implementation", "Testing")
- [ ] Each group contains TODO items
- [ ] Each item has:
  - [ ] Title, status (pending/in_progress/completed)
  - [ ] Optional subtasks
  - [ ] Optional acceptance criteria
  - [ ] Optional related files
- [ ] User can check off completed items
- [ ] Completeness score auto-calculated (% of items done)
- [ ] Dashboard shows current step indicator
- [ ] Task validation checks for missing criteria

**Technical Specs**:
- Data Model:
  ```typescript
  interface TaskPlan {
    task_id: string
    todo_groups: TodoGroup[]
    current_step: { group_index: number, item_index: number }
    completeness: { score: number, missing: string[] }
  }

  interface TodoGroup {
    title: string
    status: "completed" | "in_progress" | "pending"
    items: TodoItem[]
  }

  interface TodoItem {
    title: string
    status: "completed" | "in_progress" | "pending"
    subtasks?: string[]
    acceptance_criteria?: string[]
    files?: string[]
  }
  ```

**Dependencies**: FR3 (Task List)

**Risks**:
- Complex nested structure (mitigation: Pydantic validation)
- Completeness calculation edge cases (mitigation: comprehensive tests)

**Test Cases**:
1. Create task with 3 groups, 10 items â†’ Verify structure
2. Complete 5 items â†’ Verify 50% completeness
3. Add acceptance criteria â†’ Verify validation
4. Task with 0 items â†’ Verify graceful handling

**Uncertainty**: ğŸ”µ Probabilistic (75% success, well-defined problem)

---

#### FR5: Quality Metrics Dashboard

**Description**: Display real-time code quality metrics (Python, TypeScript, test coverage) with auto-refresh.

**User Story**: As a developer, I want to see code quality at a glance, so that I can maintain high standards without manual checks.

**Acceptance Criteria**:
- [x] Dashboard shows:
  - [x] Overall quality score (0-10, weighted average)
  - [x] Python code quality (Pylint score)
  - [x] TypeScript code quality (ESLint score)
  - [x] Test coverage (% with pass/fail counts)
- [x] Color-coded indicators:
  - [x] Green (8-10): Excellent
  - [x] Blue (7-8): Good
  - [x] Yellow (5-7): Needs improvement
  - [x] Red (<5): Critical issues
- [x] "Refresh" button to force re-analysis
- [x] Loading states during analysis
- [x] Error states if tools not installed
- [ ] Historical trends (graph over time) - Phase 2

**Technical Specs**:
- Backend Service: `QualityMetricsService`
  - Pylint integration (Python)
  - ESLint integration (TypeScript)
  - pytest-cov integration (coverage)
- Frontend Component: `QualityMetrics.tsx`
- API Endpoints:
  - `GET /api/quality-metrics` (all metrics)
  - `POST /api/quality-metrics/refresh` (force refresh)

**Status**: âœ… Week 1-2 Complete (Backend + Frontend)

**Dependencies**: None (standalone feature)

**Risks**: None (already implemented and tested)

**Test Cases**:
1. âœ… Get metrics with tools installed â†’ Verify scores
2. âœ… Get metrics without tools â†’ Verify graceful error
3. âœ… Force refresh â†’ Verify re-analysis
4. âœ… Pydantic validation â†’ Verify type safety

**Uncertainty**: ğŸŸ¢ Deterministic (100% success, already implemented)

---

#### FR6: Project Selector UI

**Description**: Dropdown component to switch between projects with visual status indicators.

**User Story**: As a developer, I want to quickly switch projects from the dashboard, so that I can manage multiple projects efficiently.

**Acceptance Criteria**:
- [x] Dropdown shows all projects:
  - [x] Project name
  - [x] Current phase (ideation/design/mvp/implementation/testing)
  - [x] Last active timestamp
  - [x] "has_context" badge (green "Saved" label)
  - [x] Current project indicator (Check icon)
- [x] Click project â†’ Switch with auto-save/load
- [x] Loading state during switch
- [x] Toast notification on success/error
- [x] localStorage persistence (remember last project)
- [x] Click outside to close dropdown
- [ ] Project search/filter (for 10+ projects) - Phase 2

**Technical Specs**:
- Frontend Component: `ProjectSelector.tsx`
- React Query: `useQuery` + `useMutation`
- API Integration:
  - `GET /api/projects` (list)
  - `POST /api/project-context/switch` (switch)

**Status**: âœ… Week 3-4 Phase 1 Complete (Frontend MVP)

**Dependencies**: FR1 (Context Management)

**Risks**: None (already implemented)

**Test Cases**:
1. âœ… List projects â†’ Verify all fields displayed
2. âœ… Switch project â†’ Verify context restored
3. âœ… Database unavailable â†’ Verify graceful error
4. âœ… localStorage persistence â†’ Verify after page refresh

**Uncertainty**: ğŸŸ¢ Deterministic (100% success, already implemented)

---

### P1 (High Priority - Should Have for 1 Month Goal)

#### FR7: Prompt & Code History

**Description**: Store and search prompt history with linked code changes for reuse and ML training.

**User Story**: As a developer, I want to search past prompts and code changes, so that I can reuse solutions and avoid solving the same problem twice.

**Acceptance Criteria**:
- [ ] Store every UDO execution:
  - [ ] User prompt (full text)
  - [ ] Context files (list)
  - [ ] UDO decision (GO/NO_GO/GO_WITH_CHECKPOINTS)
  - [ ] Confidence score
  - [ ] Quantum state
  - [ ] Files modified (list with line counts)
  - [ ] Git commit hash (if committed)
  - [ ] Execution time, success/error
- [ ] User can search history:
  - [ ] Full-text search in prompts
  - [ ] Filter by phase, category, tags
  - [ ] Sort by date, confidence, success
- [ ] Search results show:
  - [ ] Prompt preview (first 100 chars)
  - [ ] Decision and confidence
  - [ ] Files changed (count + list)
  - [ ] Timestamp
- [ ] Click result â†’ View full details
- [ ] Full detail modal shows:
  - [ ] Complete prompt
  - [ ] Full file changes (diff view)
  - [ ] AI tools used
  - [ ] Execution stats
- [ ] Export history to JSON/CSV

**Technical Specs**:
- Database Table: `task_history` (already created in Week 0)
- Full-text search: PostgreSQL `pg_trgm` extension
- Indexes:
  - `idx_task_history_prompt_fts` (full-text)
  - `idx_task_history_executed` (date)
  - `idx_task_history_tags` (GIN array)
- API Endpoints:
  - `GET /api/history` (paginated list)
  - `GET /api/history/search?q={query}` (search)
  - `GET /api/history/{execution_id}` (detail)
  - `POST /api/history` (save new execution)

**Dependencies**: FR2 (Database), UDO System Integration

**Risks**:
- Large prompt storage (mitigation: compression + pagination)
- Search performance (mitigation: indexes + limit results)
- Sensitive data in prompts (mitigation: filter API keys/passwords)

**Test Cases**:
1. Save execution with full context â†’ Verify all fields stored
2. Search "authentication" â†’ Verify relevant results
3. Search with filters (phase=implementation) â†’ Verify filtered results
4. Load execution detail â†’ Verify diff view renders
5. Export history â†’ Verify JSON/CSV format

**Uncertainty**: ğŸ”µ Probabilistic (70% success, search performance unknown)

---

#### FR8: Version History Integration

**Description**: Display Git commit history with linked UDO executions and quality snapshots.

**User Story**: As a developer, I want to see how code evolved with UDO decisions, so that I can understand the development story.

**Acceptance Criteria**:
- [ ] Dashboard shows recent commits:
  - [ ] Commit hash (short)
  - [ ] Commit message
  - [ ] Author, timestamp
  - [ ] Files changed (count)
  - [ ] Linked UDO execution (if any)
  - [ ] Quality metrics snapshot (if any)
- [ ] Click commit â†’ View details:
  - [ ] Full commit message
  - [ ] File diff (syntax highlighted)
  - [ ] UDO context at time of commit
  - [ ] Quality metrics before/after
- [ ] Compare commits:
  - [ ] Select 2 commits â†’ Show diff
  - [ ] Show quality delta (improved/degraded)
  - [ ] Show uncertainty delta
- [ ] Filter by:
  - [ ] Date range
  - [ ] Author
  - [ ] File path
  - [ ] UDO phase

**Technical Specs**:
- Database Table: `version_history` (cache Git data)
- Git Integration: `GitService` (Python GitPython library)
- API Endpoints:
  - `GET /api/version-history` (list commits)
  - `GET /api/version-history/{commit_hash}` (detail)
  - `GET /api/version-history/compare?from={hash1}&to={hash2}` (compare)

**Status**: Week 0 schema complete, Week 5-6 implementation

**Dependencies**: FR2 (Database), FR5 (Quality Metrics)

**Risks**:
- Git repository not initialized (mitigation: check + error message)
- Large repositories slow to cache (mitigation: incremental caching)

**Test Cases**:
1. List commits â†’ Verify all fields
2. Load commit detail â†’ Verify diff rendered
3. Compare commits â†’ Verify delta calculated
4. Repository with 1000+ commits â†’ Verify pagination

**Uncertainty**: ğŸŸ¢ Deterministic (90% success, Git is reliable)

---

### P2 (Medium Priority - Nice to Have)

#### FR9: Kanban Board

**Description**: Visual task board with drag-and-drop, UDO integration, and automation rules.

**User Story**: As a team lead, I want to organize tasks on a Kanban board with automated status updates, so that I can manage workflows efficiently.

**Acceptance Criteria**:
- [ ] Board shows columns:
  - [ ] Backlog, Todo, In Progress, Review, Done
  - [ ] Custom columns supported
- [ ] Cards show:
  - [ ] Title, description (preview)
  - [ ] Priority (low/medium/high)
  - [ ] Assignee, tags
  - [ ] Estimated/actual hours
  - [ ] UDO task linkage (if any)
- [ ] Drag-and-drop between columns
- [ ] Click card â†’ Edit modal:
  - [ ] Full description (Markdown editor)
  - [ ] Checklist (subtasks)
  - [ ] Comments
  - [ ] Linked UDO execution
- [ ] Automation rules:
  - [ ] Move to "In Progress" when UDO task starts
  - [ ] Move to "Review" when code committed
  - [ ] Move to "Done" when tests pass
- [ ] Board filters:
  - [ ] By assignee, priority, tags
  - [ ] By project (multi-project boards)

**Technical Specs**:
- Database Tables: `kanban_boards`, `kanban_cards`
- Frontend: React DnD library
- Real-time sync: WebSocket (for multi-user)
- API Endpoints:
  - `GET /api/kanban/boards` (list boards)
  - `POST /api/kanban/cards` (create card)
  - `PUT /api/kanban/cards/{id}/move` (drag-and-drop)

**Status**: Week 0 schema complete, Week 9-11 implementation

**Dependencies**: FR2 (Database), FR3 (Tasks)

**Risks**:
- Drag-and-drop complexity (mitigation: use battle-tested library)
- Real-time sync conflicts (mitigation: CRDT or last-write-wins)

**Test Cases**:
1. Create board â†’ Verify columns rendered
2. Drag card â†’ Verify position updated in DB
3. Automation rule triggers â†’ Verify card moved
4. Multi-user edit conflict â†’ Verify resolution

**Uncertainty**: ğŸŸ  Quantum (60% success, real-time sync complexity)

---

## Non-Functional Requirements

### NFR1: Performance

**Targets**:
- API response time: <200ms (p50), <500ms (p99)
- Dashboard load time: <2 seconds
- Project switch time: <2 seconds
- Quality analysis: <30 seconds (acceptable for async)
- Database query time: <50ms (p95)

**How to Measure**:
- Backend: FastAPI built-in metrics
- Frontend: Lighthouse performance score >90
- Database: PostgreSQL `EXPLAIN ANALYZE`

**Mitigation Strategies**:
- API: Connection pooling, async/await
- Frontend: Code splitting, lazy loading
- Database: Proper indexes, query optimization

### NFR2: Scalability

**Targets**:
- Concurrent users: 10 (local), 100 (cloud)
- Projects per user: 50
- Task history: 10,000 executions per project
- Database size: 10GB (local), 1TB (cloud)

**Horizontal Scaling**:
- Backend: Stateless API (can run multiple instances)
- Database: Read replicas for queries
- WebSocket: Redis pub/sub for multi-instance

### NFR3: Reliability

**Targets**:
- Uptime: 99.9% (local dev, best effort), 99.99% (cloud prod)
- Data loss: Zero tolerance (database backups every 6 hours)
- Error rate: <0.1% of requests

**Failure Handling**:
- Database crash: Graceful degradation (return cached data)
- API timeout: Retry with exponential backoff
- Frontend error: Error boundary + fallback UI

### NFR4: Security

**Targets** (Phase 2):
- Authentication: JWT with 24-hour expiry
- Authorization: RBAC (admin/developer/viewer)
- Data encryption: TLS 1.3 (in transit), AES-256 (at rest)
- API rate limiting: 100 req/min per IP, 1000 req/hour per user
- Audit logging: All mutations logged

**Security Measures**:
- SQL injection: Parameterized queries (asyncpg/psycopg2 default)
- XSS: React auto-escaping + Content Security Policy
- CSRF: CSRF tokens on state-changing endpoints
- Sensitive data: Filter API keys/passwords from prompt history

**Note**: Security is P1 for production deployment, P2 for local development.

### NFR5: Maintainability

**Code Quality Targets**:
- Test coverage: 80%+ (backend), 70%+ (frontend)
- Type safety: 90%+ (TypeScript strict, Pydantic models)
- Linting: Zero Pylint/ESLint errors (warnings acceptable)
- Cyclomatic complexity: <10 per function
- Documentation: All public APIs documented (OpenAPI, JSDoc)

**Development Practices**:
- Git workflow: Feature branches, PR reviews
- CI/CD: Automated tests on every commit
- Deployment: Blue-green or canary rollouts
- Monitoring: Error tracking (Sentry), metrics (Prometheus)

### NFR6: Usability

**User Experience Targets**:
- Task completion time: 50% faster than manual workflows
- Learning curve: 15 minutes for basic features, 1 hour for advanced
- Error messages: Clear, actionable (no technical jargon)
- Accessibility: WCAG 2.1 AA compliance

**Usability Testing**:
- User interviews: 5 developers (monthly)
- Task completion rate: >90% for critical paths
- User satisfaction: NPS score >50

---

## Technical Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User (Developer)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Dashboard       â”‚  â”‚   CLI (Claude Code)       â”‚
â”‚   (Next.js/React)     â”‚  â”‚   (Python)                â”‚
â”‚                       â”‚  â”‚                           â”‚
â”‚   - Project Selector  â”‚  â”‚   - Task Context Loader   â”‚
â”‚   - Task List         â”‚  â”‚   - UDO System Interface  â”‚
â”‚   - Quality Dashboard â”‚  â”‚   - Git Integration       â”‚
â”‚   - Kanban Board      â”‚  â”‚                           â”‚
â”‚   - UDO State Panel   â”‚  â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                  â”‚
             â”‚ REST API         â”‚ Direct Import
             â”‚ WebSocket        â”‚
             â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend API (FastAPI)                     â”‚
â”‚                                                         â”‚
â”‚  Routers:                                              â”‚
â”‚   - /api/projects (CRUD, switch)                       â”‚
â”‚   - /api/project-context (save, load)                  â”‚
â”‚   - /api/tasks (list, context)                         â”‚
â”‚   - /api/history (search, detail)                      â”‚
â”‚   - /api/quality-metrics (collect, trends)             â”‚
â”‚   - /api/kanban (boards, cards, move)                  â”‚
â”‚   - /api/version-history (commits, compare)            â”‚
â”‚   - /ws (real-time updates)                            â”‚
â”‚                                                         â”‚
â”‚  Services:                                             â”‚
â”‚   - ProjectContextService (state management)           â”‚
â”‚   - QualityMetricsService (code analysis)              â”‚
â”‚   - GitService (version control)                       â”‚
â”‚   - TaskService (task management)                      â”‚
â”‚                                                         â”‚
â”‚  Core Systems:                                         â”‚
â”‚   - UDO v2 (phase-aware orchestration)                 â”‚
â”‚   - Uncertainty Map v3 (predictive modeling)           â”‚
â”‚   - AI Collaboration Bridge (Claude+Codex+Gemini)      â”‚
â”‚   - ML Training System (pattern learning)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ asyncpg (async)
             â”‚ psycopg2 (sync)
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PostgreSQL Database                          â”‚
â”‚                                                         â”‚
â”‚  Tables:                                               â”‚
â”‚   - projects (project info)                            â”‚
â”‚   - project_contexts (saved states, JSONB)             â”‚
â”‚   - task_history (prompt/code history, full-text)      â”‚
â”‚   - version_history (Git commits, quality snapshots)   â”‚
â”‚   - kanban_boards (board configs)                      â”‚
â”‚   - kanban_cards (task cards, UDO linkage)             â”‚
â”‚   - quality_metrics (quality snapshots over time)      â”‚
â”‚                                                         â”‚
â”‚  Indexes:                                              â”‚
â”‚   - Full-text search (pg_trgm)                         â”‚
â”‚   - JSONB path indexes                                 â”‚
â”‚   - Timestamp indexes (DESC)                           â”‚
â”‚   - Composite indexes (project_id, date)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Backend**:
- Language: Python 3.10+
- Framework: FastAPI 0.115.5
- Database: PostgreSQL 14+ (asyncpg driver)
- Validation: Pydantic 2.10.3
- Testing: pytest 8.3.3, pytest-cov 6.0.0
- Code Quality: pylint 3.3.1
- Server: uvicorn[standard] 0.32.1

**Frontend**:
- Language: TypeScript 5.0+
- Framework: Next.js 14, React 18
- State Management: React Query (TanStack Query v5)
- UI Components: shadcn/ui (Radix UI + Tailwind CSS)
- Animations: Framer Motion
- Code Quality: ESLint, Prettier
- Testing: React Testing Library, Playwright (E2E)

**Database**:
- RDBMS: PostgreSQL 14+
- Extensions: uuid-ossp, pg_trgm (full-text search)
- Connection Pooling: asyncpg (2-10 connections)
- Migrations: Custom Python script (sequential versioning)

**DevOps** (Phase 2):
- Containerization: Docker, Docker Compose
- CI/CD: GitHub Actions
- Monitoring: Prometheus + Grafana
- Error Tracking: Sentry
- Cloud: AWS/GCP (future)

### Data Flow

#### Critical Path 1: Project Context Switching

```
User clicks project in dropdown
  â†“
Frontend: ProjectSelector.tsx
  â”œâ”€ useMutation: POST /api/project-context/switch
  â”œâ”€ Loading state: Spinner + "Switching..."
  â†“
Backend: project_context.py (router)
  â”œâ”€ Validate request: ProjectSwitchRequest (Pydantic)
  â”œâ”€ ProjectContextService.switch_project(from_id, to_id)
  â†“
Service: project_context_service.py
  â”œâ”€ Step 1: Save current project context (UPSERT)
  â”‚   â”œâ”€ db.execute("INSERT ... ON CONFLICT ... DO UPDATE")
  â”‚   â””â”€ Commit
  â”œâ”€ Step 2: Load new project context
  â”‚   â”œâ”€ db.fetch_one("SELECT * FROM project_contexts WHERE project_id = $1")
  â”‚   â”œâ”€ Update loaded_at timestamp
  â”‚   â””â”€ Return ProjectContextResponse
  â”œâ”€ Step 3: Update global state (current_project_id)
  â””â”€ Return switch result
  â†“
Backend response: ProjectSwitchResponse
  â”œâ”€ status: "success"
  â”œâ”€ previous_project: {...}
  â”œâ”€ new_project: {...}
  â””â”€ context: {...} (UDO state, ML models, etc.)
  â†“
Frontend: ProjectSelector.tsx
  â”œâ”€ onSuccess: Update localStorage
  â”œâ”€ Invalidate React Query cache:
  â”‚   â”œâ”€ ["current-project"]
  â”‚   â”œâ”€ ["quality-metrics"]
  â”‚   â”œâ”€ ["tasks"]
  â”‚   â””â”€ ["udo-state"]
  â”œâ”€ Show toast: "Switched to {project_name}"
  â””â”€ Close dropdown
  â†“
Dashboard auto-refreshes (React Query refetch)
  â”œâ”€ Quality metrics re-fetch for new project
  â”œâ”€ Task list re-fetch
  â””â”€ UDO state panel updates
```

**Performance**: <2 seconds end-to-end

---

#### Critical Path 2: Task â†’ CLI Continuation

```
User clicks "Continue in CLI" button
  â†“
Frontend: ContinueInCLI.tsx
  â”œâ”€ onClick: GET /api/tasks/{task_id}/context
  â†“
Backend: tasks.py (router)
  â”œâ”€ TaskService.get_task_context(task_id)
  â†“
Service: task_service.py
  â”œâ”€ db.fetch_one("SELECT * FROM kanban_cards WHERE id = $1")
  â”œâ”€ Load task_context (JSONB)
  â”œâ”€ Load linked UDO execution (task_history)
  â”œâ”€ Load related files (Git working tree)
  â””â”€ Return TaskContext
  â†“
Backend response: TaskContext
  â”œâ”€ task_id, title, description
  â”œâ”€ project_id, project_name, project_path
  â”œâ”€ current_phase (ideation/design/mvp/implementation/testing)
  â”œâ”€ todo_groups: [...]
  â”œâ”€ current_step: { group_index, item_index }
  â”œâ”€ files: ["auth.py", "test_auth.py"]
  â”œâ”€ git_branch: "feature/auth"
  â”œâ”€ last_prompt: "Implement JWT refresh token"
  â”œâ”€ udo_context: { decision, confidence, quantum_state, ... }
  â””â”€ editor_state: { open_files, cursor_positions, breakpoints }
  â†“
Frontend: ContinueInCLI.tsx
  â”œâ”€ Try Plan A: Deep link (if OS supports)
  â”‚   â””â”€ window.location.href = "claude-code://continue?context={base64}"
  â”‚   â””â”€ If success: Show toast "Opening in CLI..."
  â”‚   â””â”€ If fail: Fallback to Plan B
  â”œâ”€ Plan B: Copy command to clipboard
  â”‚   â””â”€ navigator.clipboard.writeText("claude-code --resume {base64}")
  â”‚   â””â”€ Show toast: "Command copied! Paste in terminal"
  â””â”€ Plan C: Display context in modal (last resort)
      â””â”€ Modal shows: project_path, files, current_step, prompt
  â†“
CLI: Claude Code receives context
  â”œâ”€ Decode base64 context
  â”œâ”€ cd {project_path}
  â”œâ”€ git checkout {git_branch}
  â”œâ”€ Open files: {files}
  â”œâ”€ Restore editor state: cursor positions, breakpoints
  â”œâ”€ Load UDO state: decision, confidence, uncertainty_map
  â”œâ”€ Display current_step: "You were working on: {current_step}"
  â””â”€ Prompt user: "Ready to continue. What's next?"
```

**Performance**: <3 seconds (API call + CLI startup)

---

## Phased Rollout Plan

### Phase 0: Design Complete (Week 0) âœ… DONE

**Status**: 100% Complete (2025-11-17)

**Deliverables**:
- [x] PostgreSQL schema (7 tables, 30+ indexes)
- [x] Migration system (run, rollback)
- [x] OpenAPI 3.0 spec (30+ endpoints)
- [x] Database connection layer (asyncpg + psycopg2)

**Time**: 1 day (faster than planned 2-3 days)

---

### Phase 1: Backend Foundation (Week 1) - IN PROGRESS

**Target**: 2025-11-26
**Current Progress**: 70% (Backend services 95%, Database integration 0%)

**Critical Tasks**:
1. **Database Integration** (P0, 2 days)
   - [ ] Set up PostgreSQL (Docker Compose)
   - [ ] Run migrations (verify all tables created)
   - [ ] Replace mock services with database services
   - [ ] Test database health check
   - [ ] Verify connection pooling under load

2. **Type Safety Improvements** (P0, 1 day)
   - [ ] Enable TypeScript strict mode (tsconfig.json)
   - [ ] Generate frontend types from OpenAPI spec (openapi-typescript)
   - [ ] Replace `any` types with proper interfaces
   - [ ] Add Zod validation for runtime type safety

3. **Backend Testing** (P1, 2 days)
   - [ ] Create integration tests (API + Database)
   - [ ] Test all CRUD operations
   - [ ] Test error cases (404, 500, 503)
   - [ ] Achieve 80%+ backend test coverage

**Risks**:
- ğŸ”´ Database setup complexity (users may struggle)
  - **Mitigation**: Docker Compose one-command setup
- ğŸŸ¡ Migration failures
  - **Mitigation**: Comprehensive rollback tests

**Success Criteria**:
- [ ] PostgreSQL running and healthy
- [ ] All backend services use database (no mocks)
- [ ] 80%+ backend test coverage
- [ ] TypeScript strict mode enabled
- [ ] Zero critical bugs

---

### Phase 2: Frontend Core Features (Week 2-3)

**Target**: 2025-12-10
**Current Progress**: 30% (2/7 components complete)

**Week 2 (Nov 26 - Dec 3): Task Management UI**

1. **Task List Component** (P0, 2 days)
   - [ ] TaskList.tsx (list all tasks)
   - [ ] TaskCard.tsx (individual task card)
   - [ ] Task filtering (by status, phase, project)
   - [ ] Pagination (20 tasks per page)
   - [ ] API integration: GET /api/tasks

2. **Task Detail Modal** (P0, 2 days)
   - [ ] TaskDetails.tsx (full task view)
   - [ ] TODO checklist (groups + items)
   - [ ] Progress indicator (current step)
   - [ ] Acceptance criteria list
   - [ ] Related files list

3. **Continue in CLI Button** (P0, 1 day)
   - [ ] ContinueInCLI.tsx (button + clipboard logic)
   - [ ] Deep link support (if OS supports)
   - [ ] Clipboard fallback
   - [ ] Modal fallback (display context)
   - [ ] API integration: GET /api/tasks/{id}/context

**Week 3 (Dec 3-10): History & UDO State**

4. **History Search Component** (P1, 2 days)
   - [ ] HistorySearch.tsx (search UI + results)
   - [ ] Full-text search (prompts)
   - [ ] Filters (phase, category, tags, date)
   - [ ] Pagination
   - [ ] API integration: GET /api/history/search

5. **History Detail Modal** (P1, 1 day)
   - [ ] HistoryDetail.tsx (full execution view)
   - [ ] Prompt display
   - [ ] File diff view (syntax highlighted)
   - [ ] Execution stats
   - [ ] API integration: GET /api/history/{id}

6. **UDO State Panel** (P1, 2 days)
   - [ ] UDOStatePanel.tsx (uncertainty visualization)
   - [ ] Last decision (GO/NO_GO/GO_WITH_CHECKPOINTS)
   - [ ] Confidence gauge (0.0-1.0)
   - [ ] Quantum state indicator (ğŸŸ¢ğŸ”µğŸŸ ğŸ”´âš«)
   - [ ] Uncertainty map (5-dimension radar chart)
   - [ ] Mitigation suggestions list

**Risks**:
- ğŸŸ¡ Diff rendering complexity
  - **Mitigation**: Use react-diff-viewer library
- ğŸŸ¡ Uncertainty visualization UX
  - **Mitigation**: User testing + iterations

**Success Criteria**:
- [ ] All 6 major components complete
- [ ] 70%+ frontend test coverage
- [ ] No TypeScript errors
- [ ] Responsive design (mobile + desktop)
- [ ] Framer Motion animations smooth (60fps)

---

### Phase 3: Testing & Quality (Week 4)

**Target**: 2025-12-17
**Current Progress**: 0%

**Week 4 (Dec 10-17): Comprehensive Testing**

1. **Backend Integration Tests** (P0, 2 days)
   - [ ] Test all API endpoints with database
   - [ ] Test project context save/load/switch
   - [ ] Test task CRUD operations
   - [ ] Test history search and filtering
   - [ ] Test quality metrics collection
   - [ ] Achieve 90%+ backend coverage

2. **Frontend Component Tests** (P0, 2 days)
   - [ ] Test ProjectSelector (switching)
   - [ ] Test TaskList (filtering, pagination)
   - [ ] Test ContinueInCLI (clipboard, deep link)
   - [ ] Test HistorySearch (search, filters)
   - [ ] Test UDOStatePanel (uncertainty display)
   - [ ] Achieve 75%+ frontend coverage

3. **E2E Tests (Playwright)** (P0, 2 days)
   - [ ] Test critical user journey 1: Project switch â†’ View tasks â†’ Continue in CLI
   - [ ] Test critical user journey 2: Search history â†’ View detail â†’ Reuse prompt
   - [ ] Test critical user journey 3: Quality metrics â†’ Fix issues â†’ Re-check
   - [ ] Test critical user journey 4: UDO decision â†’ Apply mitigation â†’ Re-evaluate
   - [ ] Test critical user journey 5: Task completion â†’ Commit â†’ Version history
   - [ ] All E2E tests passing in CI/CD

4. **Bug Fixes & Polish** (P1, 1 day)
   - [ ] Fix all critical bugs found in testing
   - [ ] Improve error messages (user-friendly)
   - [ ] Add loading skeletons (better UX)
   - [ ] Accessibility audit (keyboard navigation, screen readers)

**Risks**:
- ğŸ”´ E2E tests flaky
  - **Mitigation**: Proper waits, retry logic
- ğŸŸ¡ Database test isolation
  - **Mitigation**: Transaction rollback per test

**Success Criteria**:
- [ ] 90%+ backend test coverage
- [ ] 75%+ frontend test coverage
- [ ] 100% E2E tests passing
- [ ] Zero critical bugs
- [ ] Lighthouse score >90

---

### Phase 4: Polish & Documentation (Week 5)

**Target**: 2025-12-24
**Current Progress**: 20% (some docs exist)

**Week 5 (Dec 17-24): Final Polish**

1. **User Documentation** (P1, 2 days)
   - [ ] Update USER_GUIDE.md (all features)
   - [ ] Create video tutorial (5-10 minutes)
   - [ ] Create troubleshooting guide
   - [ ] Create FAQ

2. **Developer Documentation** (P1, 1 day)
   - [ ] Architecture diagram (updated)
   - [ ] API documentation (OpenAPI + examples)
   - [ ] Database schema diagram
   - [ ] Contributing guide

3. **Performance Optimization** (P2, 2 days)
   - [ ] Frontend code splitting (reduce bundle size)
   - [ ] Database query optimization (EXPLAIN ANALYZE)
   - [ ] API response caching (Redis, optional)
   - [ ] Frontend lazy loading (images, components)
   - [ ] Lighthouse score >95

**Success Criteria**:
- [ ] Complete user guide
- [ ] Video tutorial published
- [ ] Lighthouse score >95
- [ ] All documentation up-to-date

---

## Risk Analysis & Mitigation

### Critical Risks (Could Block 1-Month Goal)

#### Risk 1: Database Integration Complexity

**Probability**: HIGH (60%)
**Impact**: CRITICAL (blocks all features)
**Uncertainty State**: ğŸŸ  Quantum

**Description**: Users may struggle to set up PostgreSQL locally, causing development friction.

**Mitigation Strategy**:
1. **Docker Compose One-Command Setup** (Primary)
   ```bash
   docker-compose up -d postgres
   # Automatically runs migrations
   ```
   - Pre-configured with correct ports, credentials
   - Includes pgAdmin for database management
   - Health check ensures database ready before backend starts

2. **Graceful Degradation** (Fallback)
   - Backend starts without database
   - Non-database endpoints work (health, status)
   - Database endpoints return 503 with helpful error:
     ```json
     {
       "detail": "Database not available. Run: docker-compose up -d postgres"
     }
     ```

3. **Detailed Setup Guide** (Documentation)
   - Step-by-step instructions with screenshots
   - Common errors and solutions
   - Alternative: Cloud PostgreSQL (ElephantSQL free tier)

**Rollback Plan**: Revert to mock services (1-hour effort)

**Owner**: Backend Team
**Timeline**: Week 1 (Nov 19-26)

---

#### Risk 2: Frontend Implementation Velocity

**Probability**: MEDIUM (40%)
**Impact**: HIGH (delays 85% goal)
**Uncertainty State**: ğŸŸ  Quantum

**Description**: Frontend is 30% complete (2/7 components), needs 45% progress in 3 weeks. Aggressive timeline may lead to quality issues.

**Mitigation Strategy**:
1. **Component Prioritization** (Primary)
   - Week 2: TaskList + CLI Integration (P0)
   - Week 3: History + UDO State (P1)
   - Defer Kanban Board to Phase 2 (nice-to-have)

2. **Code Reuse** (Efficiency)
   - Use shadcn/ui components (pre-built, accessible)
   - Reuse ProjectSelector patterns for other dropdowns
   - Share API client logic (React Query hooks)

3. **Parallel Development** (Speed)
   - Frontend dev works on UI while backend stabilizes
   - Use mock API responses (MSW library) for independence
   - Backend generates TypeScript types from OpenAPI (automatic)

4. **Accept MVP Quality** (Scope Reduction)
   - Basic features only (no animations initially)
   - Mobile responsiveness deferred to Phase 2
   - Accessibility audit deferred to Phase 2

**Rollback Plan**: Remove incomplete features (Feature Flags)

**Owner**: Frontend Team
**Timeline**: Week 2-3 (Nov 26-Dec 10)

---

#### Risk 3: Type Safety Gaps

**Probability**: MEDIUM (50%)
**Impact**: MEDIUM (bugs, refactoring pain)
**Uncertainty State**: ğŸ”µ Probabilistic

**Description**: Frontend API client lacks proper types, increasing runtime errors and debugging time.

**Mitigation Strategy**:
1. **OpenAPI TypeScript Generator** (Primary)
   ```bash
   npx openapi-typescript docs/openapi.yaml -o src/types/api.ts
   ```
   - Generates TypeScript interfaces from OpenAPI spec
   - 100% type coverage for API responses
   - Automatic updates when spec changes

2. **Zod Runtime Validation** (Defense in Depth)
   ```typescript
   import { z } from 'zod';

   const ProjectSchema = z.object({
     id: z.string().uuid(),
     name: z.string().min(1),
     current_phase: z.enum(['ideation', 'design', 'mvp', 'implementation', 'testing']),
     // ... other fields
   });

   // Validate at API boundary
   const project = ProjectSchema.parse(apiResponse);
   ```
   - Catches type errors at runtime
   - Provides helpful error messages
   - Prevents corrupt data propagation

3. **TypeScript Strict Mode** (Foundation)
   ```json
   {
     "compilerOptions": {
       "strict": true,
       "noUncheckedIndexedAccess": true,
       "noImplicitAny": true,
       "strictNullChecks": true
     }
   }
   ```
   - Forces explicit types
   - Eliminates `any` types
   - Catches null/undefined errors

**Rollback Plan**: Temporarily disable strict mode (not recommended)

**Owner**: Frontend Team
**Timeline**: Week 1 (Nov 19-26)

---

#### Risk 4: E2E Testing Flakiness

**Probability**: MEDIUM (50%)
**Impact**: MEDIUM (delays releases)
**Uncertainty State**: ğŸŸ  Quantum

**Description**: Playwright E2E tests may be flaky (intermittent failures), causing CI/CD pipeline failures and delayed deployments.

**Mitigation Strategy**:
1. **Proper Waits** (Primary)
   ```typescript
   // âŒ Bad: Race condition
   await page.click('#button');
   expect(page.locator('#result')).toHaveText('Success');

   // âœ… Good: Wait for state
   await page.click('#button');
   await page.waitForSelector('#result:has-text("Success")');
   expect(page.locator('#result')).toHaveText('Success');
   ```

2. **Test Isolation** (Reliability)
   - Each test uses fresh database (transaction rollback)
   - Clear localStorage before each test
   - Reset application state (API call)

3. **Retry Logic** (Resilience)
   ```typescript
   // playwright.config.ts
   export default {
     retries: 2, // Retry failed tests twice
     timeout: 30000, // 30s timeout per test
   };
   ```

4. **Parallel Execution** (Speed)
   - Run tests in parallel (4 workers)
   - Total E2E test time: <5 minutes

**Rollback Plan**: Disable flaky tests temporarily (mark as `test.skip`)

**Owner**: QA Team
**Timeline**: Week 4 (Dec 10-17)

---

### Medium Risks (Could Delay Features)

#### Risk 5: CLI Integration Platform Dependencies

**Probability**: HIGH (70%)
**Impact**: LOW (fallbacks available)
**Uncertainty State**: ğŸŸ  Quantum

**Description**: Deep link registration (`claude-code://`) may not work on all platforms (Windows/macOS/Linux).

**Mitigation Strategy**:
1. **Plan B: Clipboard Fallback** (Primary)
   - Copy command to clipboard
   - Show toast: "Command copied! Paste in terminal"
   - Works on all platforms (100% success)

2. **Plan C: Context Modal** (Last Resort)
   - Display context in modal
   - User manually copies project path, files, etc.
   - Always works (100% success)

3. **Plan A: Deep Link** (Best UX)
   - Attempt deep link first
   - If fails (timeout 2s), fallback to Plan B

**Rollback Plan**: Remove deep link attempt, use clipboard only

**Owner**: Frontend Team
**Timeline**: Week 2 (Nov 26-Dec 3)

---

#### Risk 6: Quality Metrics Tool Dependencies

**Probability**: LOW (20%)
**Impact**: LOW (feature works without tools)
**Uncertainty State**: ğŸŸ¢ Deterministic

**Description**: Pylint/ESLint/pytest-cov may not be installed, breaking quality metrics.

**Mitigation Strategy**:
1. **Graceful Degradation** (Already Implemented âœ…)
   - If tool not found, return error with installation instructions
   - Dashboard shows "Tool not installed" message
   - Other features unaffected

2. **Automatic Installation** (Future Enhancement)
   ```bash
   # Check if Pylint installed
   if ! command -v pylint &> /dev/null; then
     pip install pylint
   fi
   ```

**Rollback Plan**: Not needed (already gracefully handled)

**Owner**: Backend Team
**Timeline**: N/A (already implemented)

---

## Timeline & Milestones

### 1-Month Roadmap (Nov 19 - Dec 19, 2025)

```
Week 1 (Nov 19-26): Backend Stabilization
â”œâ”€ Mon-Tue: Database Integration (PostgreSQL + Docker)
â”œâ”€ Wed: Type Safety (TypeScript strict mode + OpenAPI types)
â”œâ”€ Thu-Fri: Backend Testing (integration tests, 90% coverage)
â””â”€ Milestone 1: Backend 100% Complete âœ…

Week 2 (Nov 26-Dec 3): Frontend Core UI
â”œâ”€ Mon-Tue: Task List + Task Detail Components
â”œâ”€ Wed: Continue in CLI Button (clipboard + deep link)
â”œâ”€ Thu-Fri: History Search + History Detail Components
â””â”€ Milestone 2: Task Management UI Complete âœ…

Week 3 (Dec 3-10): Frontend Advanced UI
â”œâ”€ Mon-Tue: UDO State Panel (uncertainty visualization)
â”œâ”€ Wed-Thu: Polish & Refinement (animations, loading states)
â”œâ”€ Fri: Frontend Testing (component tests, 75% coverage)
â””â”€ Milestone 3: All UI Components Complete âœ…

Week 4 (Dec 10-17): Testing & Quality Assurance
â”œâ”€ Mon-Tue: E2E Tests (Playwright, 5 critical journeys)
â”œâ”€ Wed: Bug Fixes (critical bugs only)
â”œâ”€ Thu: Performance Optimization (code splitting, lazy loading)
â”œâ”€ Fri: Documentation (user guide, video tutorial)
â””â”€ Milestone 4: 85% Completion Achieved âœ…

Buffer (Dec 17-19): Contingency
â””â”€ Address any delays or critical bugs
```

### Key Milestones

| Milestone | Date | Completion | Status |
|-----------|------|------------|--------|
| **M0: Design Complete** | Nov 17 | 100% | âœ… DONE |
| **M1: Backend 100%** | Nov 26 | 95% â†’ 100% | ğŸ”„ In Progress |
| **M2: Task UI Complete** | Dec 3 | 30% â†’ 60% | â³ Planned |
| **M3: All UI Complete** | Dec 10 | 30% â†’ 75% | â³ Planned |
| **M4: 85% Overall** | Dec 17 | 45% â†’ 85% | ğŸ¯ Goal |
| **M5: Production Ready** | Jan 15 | 85% â†’ 100% | ğŸš€ Phase 2 |

### Daily Standups (Recommended)

**Format**:
1. What did I complete yesterday?
2. What am I working on today?
3. Any blockers?

**Tracking**: Update `docs/DAILY_PROGRESS.md` (create if missing)

---

## Success Criteria & Acceptance

### Definition of Done (1-Month Goal: 85%)

#### Backend (95% â†’ 100%)
- [x] All API endpoints implemented (30+)
- [x] Pydantic models with validation
- [ ] PostgreSQL integrated (not mocked)
- [ ] 90%+ test coverage
- [ ] OpenAPI spec 100% accurate
- [ ] Zero critical bugs

#### Frontend (30% â†’ 75%)
- [x] Project Selector (âœ… Complete)
- [x] Quality Metrics (âœ… Complete)
- [ ] Task List (with "Continue in CLI")
- [ ] Task Detail Modal
- [ ] History Search
- [ ] History Detail Modal
- [ ] UDO State Panel
- [ ] 75%+ test coverage
- [ ] TypeScript strict mode (zero errors)
- [ ] Responsive design (mobile + desktop)
- [ ] Lighthouse score >90

#### Database (0% â†’ 90%)
- [ ] PostgreSQL running (local or Docker)
- [ ] All 7 tables populated with real data
- [ ] Migrations tested (run + rollback)
- [ ] Connection pooling validated
- [ ] Database health check operational

#### Testing (0% â†’ 80%)
- [ ] Backend integration tests (90% coverage)
- [ ] Frontend component tests (75% coverage)
- [ ] E2E tests (5 critical user journeys)
- [ ] All tests passing in CI/CD

#### Documentation (40% â†’ 80%)
- [x] README.md (âœ… Complete)
- [x] OpenAPI spec (âœ… Complete)
- [x] Database schema docs (âœ… Complete)
- [ ] User guide (updated with all features)
- [ ] Video tutorial (5-10 minutes)
- [ ] Troubleshooting guide

---

### Acceptance Testing

#### User Acceptance Tests (UAT)

**Tester**: Solo Developer Persona (Alex Chen)

**Test Scenarios**:

1. **Project Context Switching** (5 minutes)
   - [ ] Open dashboard, see 3 projects
   - [ ] Click project dropdown, select different project
   - [ ] Verify context restored (UDO state, quality metrics, tasks)
   - [ ] Switch back to original project, verify state preserved
   - [ ] Success Metric: Context restoration <2 seconds

2. **Task â†’ CLI Continuation** (5 minutes)
   - [ ] View task list, select task "Implement JWT auth"
   - [ ] Click "Continue in CLI" button
   - [ ] Verify command copied to clipboard (or deep link opens)
   - [ ] Paste in CLI, verify context loaded (files, current step, prompt)
   - [ ] Success Metric: Total time <3 minutes (dashboard â†’ CLI coding)

3. **Prompt History Search** (5 minutes)
   - [ ] Search "authentication" in history
   - [ ] Verify relevant results (prompts, decisions, files)
   - [ ] Click result, view full detail (prompt, diff, stats)
   - [ ] Reuse prompt for current task
   - [ ] Success Metric: Rediscovery time <2 minutes (vs 30 minutes manual)

4. **Quality Metrics Monitoring** (5 minutes)
   - [ ] View quality dashboard, see current scores
   - [ ] Click "Refresh" button, verify re-analysis
   - [ ] Identify issue (e.g., low test coverage)
   - [ ] Improve code, re-check quality
   - [ ] Success Metric: Quality score improved >1.0 points

5. **UDO Uncertainty Evaluation** (5 minutes)
   - [ ] Start new feature "Payment integration"
   - [ ] View UDO state panel, see uncertainty breakdown
   - [ ] Review auto-generated mitigations
   - [ ] Apply highest ROI mitigation
   - [ ] Re-evaluate, verify uncertainty decreased
   - [ ] Success Metric: Uncertainty reduced by >0.2 (20%)

**Pass Criteria**: 5/5 scenarios completed successfully

---

## Open Questions & Dependencies

### Critical Dependencies

1. **PostgreSQL Setup** (Blocks: All database features)
   - **Options**: Local install, Docker, Cloud (ElephantSQL)
   - **Decision**: Docker Compose (recommended)
   - **Owner**: Backend Team
   - **Due**: Week 1 (Nov 19-26)

2. **OpenAPI TypeScript Generator** (Blocks: Frontend type safety)
   - **Tool**: openapi-typescript (npm package)
   - **Command**: `npx openapi-typescript docs/openapi.yaml -o src/types/api.ts`
   - **Owner**: Frontend Team
   - **Due**: Week 1 (Nov 19-26)

3. **E2E Testing Infrastructure** (Blocks: E2E tests)
   - **Tool**: Playwright (already in package.json)
   - **Setup**: `npx playwright install` (browsers)
   - **Owner**: QA Team
   - **Due**: Week 3 (Dec 3-10)

---

### Open Questions

#### Q1: Authentication for Production?

**Context**: Current implementation has no authentication. Production requires user accounts.

**Options**:
- **A**: JWT authentication (FastAPI-Users library)
- **B**: OAuth 2.0 (Google/GitHub login)
- **C**: Defer to Phase 2 (local dev only for now)

**Recommendation**: Option C (defer to Phase 2)
**Rationale**: 1-month goal is 85% feature-complete, not production-ready. Auth is P1 for production deployment (Phase 2).

**Decision Maker**: Product Owner
**Due Date**: Before production deployment (Phase 2)

---

#### Q2: Kanban Board Priority?

**Context**: Kanban Board is P2 (nice-to-have), but may be valuable for team leads.

**Options**:
- **A**: Include in 1-month goal (Week 3-4)
- **B**: Defer to Phase 2 (2-3 months)
- **C**: Build basic version only (static board, no drag-and-drop)

**Recommendation**: Option B (defer to Phase 2)
**Rationale**: Task List + CLI Integration are more critical for solo developers (60% of users). Kanban Board adds complexity (real-time sync, drag-and-drop).

**Decision Maker**: Product Owner
**Due Date**: Week 2 (Nov 26-Dec 3) - Final call

---

#### Q3: Multi-Project Support in Phase 1?

**Context**: Project Context Switching is implemented, but some features (e.g., History Search) may not filter by project.

**Options**:
- **A**: All features filter by current project (strict isolation)
- **B**: Some features show all projects (e.g., History Search across projects)
- **C**: User preference (toggle "Show only current project")

**Recommendation**: Option A (strict isolation)
**Rationale**: Simpler implementation, avoids cross-project confusion. Option C can be added in Phase 2.

**Decision Maker**: Product Owner
**Due Date**: Week 2 (Nov 26-Dec 3) - Before History Search implementation

---

## Appendix

### A. VibeCoding System Integration

**VibeCoding Framework**: AI-assisted development with orchestration patterns.

**Integration Points**:
1. **AI Collaboration Bridge**: Orchestrates Claude + Codex + Gemini
2. **Pattern-Based Collaboration**: Codex reviews patterns, Gemini validates
3. **Uncertainty-Driven Decisions**: UDO system guides AI tool selection

**Usage in UDO Platform**:
- `three_ai_collaboration_bridge.py`: 3-AI orchestration
- `ai_collaboration_connector.py`: MCP Codex integration
- Patterns: Creative Exploration, Risk Analysis, Refactoring

**Documentation**: `docs/UDO_V3_INTEGRATION_REPORT.md`

---

### B. Uncertainty Map v3 Technical Details

**Quantum States**:
- ğŸŸ¢ Deterministic (<10%): Fully predictable, proceed confidently
- ğŸ”µ Probabilistic (10-30%): Statistical confidence, validate assumptions
- ğŸŸ  Quantum (30-60%): Multiple possibilities, apply mitigations
- ğŸ”´ Chaotic (60-90%): High uncertainty, spike/research first
- âš« Void (>90%): Unknown territory, split into smaller experiments

**5-Dimensional Uncertainty Vector**:
1. **Technical** (0.0-1.0): Code complexity, unknown APIs, unfamiliar tech stack
2. **Market** (0.0-1.0): User demand, competitive landscape, product-market fit
3. **Resource** (0.0-1.0): Time constraints, team capacity, budget limits
4. **Timeline** (0.0-1.0): Schedule risk, dependency delays, external blockers
5. **Quality** (0.0-1.0): Test coverage, security risks, technical debt

**24-Hour Prediction**:
- ML model predicts uncertainty evolution over next 24 hours
- Trend: increasing/stable/decreasing
- Confidence: 0.0-1.0 (prediction reliability)

**Auto-Generated Mitigations**:
- Action: "Research Stripe API integration" (8 hours)
- Estimated Impact: -0.3 uncertainty (30% reduction)
- Confidence: 0.8 (80% sure this will help)
- ROI: 3.75x (impact/cost ratio)

**Documentation**: `src/uncertainty_map_v3.py`

---

### C. Glossary

**Terms**:
- **UDO**: Unified Development Orchestrator (core system)
- **Quantum State**: Uncertainty classification (Deterministic/Probabilistic/Quantum/Chaotic/Void)
- **Phase-Aware**: Different evaluation criteria per development phase
- **Context Switching**: Moving between projects with state restoration
- **CLI Integration**: Continuing development from dashboard to CLI
- **Task Context**: All information needed to resume a task (files, prompts, state)
- **UPSERT**: Insert or Update in single SQL operation
- **JSONB**: JSON Binary (PostgreSQL data type for flexible storage)
- **P0/P1/P2**: Priority levels (P0 = Critical, P1 = High, P2 = Medium)

---

### D. References

**Internal Documents**:
- `README.md`: Project overview
- `FINAL_REPORT.md`: v3.0 achievement summary
- `docs/MISSING_FEATURES_ANALYSIS.md`: Gap analysis
- `docs/UDO_V3_INTEGRATION_REPORT.md`: Integration details
- `docs/IMPLEMENTATION_ROADMAP_WITH_UNCERTAINTY.md`: Uncertainty-driven roadmap
- `docs/DESIGN_COMPLETENESS_REVIEW.md`: Design review
- `docs/WEEK_0_COMPLETION_SUMMARY.md`: Design phase completion
- `docs/WEEK_1-2_QUALITY_METRICS_COMPLETION.md`: Quality metrics completion
- `docs/WEEK_3-4_PROJECT_CONTEXT_PROGRESS.md`: Context management progress

**External References**:
- FastAPI Docs: https://fastapi.tiangolo.com/
- Next.js Docs: https://nextjs.org/docs
- PostgreSQL Docs: https://www.postgresql.org/docs/
- Pydantic Docs: https://docs.pydantic.dev/
- React Query Docs: https://tanstack.com/query/latest

---

**Document Control**:
- **Version**: 1.0
- **Last Updated**: 2025-11-19
- **Next Review**: 2025-12-19 (1-month milestone)
- **Owner**: Product Team
- **Approvers**: Engineering Lead, Product Owner

---

*End of Product Requirements Document*
