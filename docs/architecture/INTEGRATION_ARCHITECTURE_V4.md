# UDO Platform V4.0 - Integrated Architecture Design
## Achieving 95% AI Automation with Industry Best Practices

**Version**: 4.0.0
**Date**: 2025-11-20
**Status**: Design Review Phase
**Target**: Production-Ready Architecture for 95%+ Automation

---

## ğŸ“‹ Executive Summary

### Design Goal
Integrate critical VibeCoding features into UDO while leveraging 2024-2025 industry advances (GitHub Copilot multi-model, 95% automation case studies, GitHub Spark) to create a world-class AI development platform.

### Current State Analysis (UDO V3.0)
âœ… **Strengths**:
- Phase-Aware Evaluation (5 phases)
- Predictive Uncertainty Modeling (24h ahead)
- 3-AI Collaboration Bridge (Claude + Codex + Gemini)
- Backend 95% complete (19/19 tests passing)
- Real-time Dashboard (Next.js 14 + Turbopack)

âŒ **Critical Gaps**:
- No Obsidian integration â†’ Knowledge loss
- No Constitution framework â†’ AI inconsistency risk
- No time tracking â†’ ROI unmeasurable
- No 3-Tier error resolution â†’ Manual debugging
- No GI Formula/C-K Theory â†’ Limited creativity
- Single-model locked (not multi-model like Copilot)

### Target Outcomes (V4.0)
1. **95% automation rate** (measured via time tracking)
2. **485h/year time savings** (based on VibeCoding data)
3. **40% bug prevention** (Design Review First)
4. **70% error auto-resolution** (3-Tier system)
5. **3x design quality** (C-K Theory alternatives)
6. **Multi-model AI flexibility** (like GitHub Copilot 2024)

---

## ğŸ—ï¸ System Architecture Overview

### Architectural Layers (7-Layer Extended)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 7: Constitution & Governance                     â”‚
â”‚  - Design Review First (8-Risk Check)                   â”‚
â”‚  - Uncertainty Protocol (HIGH/MEDIUM/LOW)               â”‚
â”‚  - RICE Scoring, Evidence-Based Decision                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 6: Multi-Model AI Orchestration                  â”‚
â”‚  - Model Router (Claude, GPT-4o, Gemini, Codex)        â”‚
â”‚  - Task-Model Matching (Context7 for docs, etc.)       â”‚
â”‚  - Confidence-Based Selection                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: Knowledge & Learning                          â”‚
â”‚  - Obsidian Integration (3-Tier Error Resolution)       â”‚
â”‚  - GI Formula (5-step insight generation)               â”‚
â”‚  - C-K Design Theory (3 alternatives)                   â”‚
â”‚  - TRIZ Solver (40 principles)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Execution & Quality                           â”‚
â”‚  - Phase-Aware Executor (5 phases)                      â”‚
â”‚  - Time Tracking Service (ROI measurement)              â”‚
â”‚  - Quality Service (Pylint, ESLint, Pytest)             â”‚
â”‚  - Constitutional Guards (pre-commit hooks)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: State & Storage                               â”‚
â”‚  - Progressive Storage (Redis â†’ Obsidian â†’ PostgreSQL)  â”‚
â”‚  - Session Manager V2 (multi-terminal support)          â”‚
â”‚  - Distributed Locks (Redis-based)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Integration & API                             â”‚
â”‚  - REST API (FastAPI)                                   â”‚
â”‚  - WebSocket (real-time sync)                           â”‚
â”‚  - MCP Servers (Context7, Morphllm, etc.)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Infrastructure                                â”‚
â”‚  - Redis (caching, locks, pub/sub)                      â”‚
â”‚  - PostgreSQL + pgvector (semantic search)              â”‚
â”‚  - Next.js Dashboard (real-time UI)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Priority 1 Integrations (Week 1 - Foundation)

### 1. Obsidian Knowledge Integration

**Architecture Pattern**: Event-Driven Knowledge Capture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UDO Core   â”‚â”€â”€eventâ”€â†’â”‚ ObsidianBridge   â”‚â”€â”€writeâ”€â†’â”‚  Obsidian   â”‚
â”‚  (FastAPI)   â”‚         â”‚  (async worker)  â”‚         â”‚   Vault     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚                           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€3-Tier Error Resolutionâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              (Tier 1: <10ms Obsidian search)
```

**Components**:

```python
# backend/app/services/obsidian_bridge.py
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict
import asyncio

class ObsidianBridge:
    """Event-driven Obsidian integration with 3-Tier Error Resolution"""

    def __init__(self, vault_path: str):
        self.vault_path = Path(vault_path)
        self.daily_notes = self.vault_path / "ê°œë°œì¼ì§€"
        self.knowledge_base = self.vault_path / "3-Areas" / "Learning"

    async def auto_sync(self, event: Dict):
        """3-second auto-sync on critical events"""
        triggers = [
            "phase_change",      # Phase-Aware transitions
            "error_resolved",    # 3-Tier resolution success
            "decision_made",     # Constitutional decisions
            "design_completed",  # C-K Theory alternatives
            "insight_generated"  # GI Formula outputs
        ]

        if event["type"] in triggers:
            await self._write_knowledge_note(event)

    async def tier1_search(self, error_msg: str) -> Optional[str]:
        """Tier 1: Obsidian search (<10ms)"""
        # Use mcp__obsidian__obsidian_simple_search
        keywords = self._extract_keywords(error_msg)

        # Search in Debug notes folder
        results = await self._search_vault(
            query=" ".join(keywords),
            folder="3-Areas/Learning/Patterns"
        )

        if results:
            return self._extract_solution(results)
        return None

    def _extract_keywords(self, error_msg: str) -> list[str]:
        """Extract search keywords from error message"""
        # Error codes (401, 404, etc.)
        # Error types (ModuleNotFoundError, etc.)
        # Tech stack (React, FastAPI, etc.)
        pass
```

**Folder Structure** (5 Methodologies):
```
Obsidian Vault/
â”œâ”€â”€ 1-Projects/
â”‚   â””â”€â”€ UDO-Development-Platform/
â”œâ”€â”€ 2-Inbox/
â”‚   â””â”€â”€ Daily-Captures/
â”œâ”€â”€ 3-Areas/
â”‚   â””â”€â”€ Learning/
â”‚       â”œâ”€â”€ Beginner-Concepts/      # GI Formula outputs
â”‚       â”œâ”€â”€ Management-Insights/
â”‚       â”œâ”€â”€ Technical-Debt/
â”‚       â”œâ”€â”€ Patterns/               # Error solutions (Tier 1)
â”‚       â””â”€â”€ AI-Synergy/
â”œâ”€â”€ 4-Resources/
â”‚   â””â”€â”€ Knowledge-Base/
â”‚       â”œâ”€â”€ ADR/                    # Architecture Decision Records
â”‚       â””â”€â”€ CODE-Snippets/          # CODE Method
â””â”€â”€ 5-MOCs/
    â””â”€â”€ UDO-Knowledge-Map.md        # Zettelkasten links
```

**Database Schema** (PostgreSQL):
```sql
-- Mirror Obsidian knowledge in PostgreSQL for semantic search
CREATE TABLE knowledge_notes (
    id SERIAL PRIMARY KEY,
    note_path TEXT NOT NULL,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    embedding VECTOR(1536),  -- pgvector for semantic search
    category TEXT,           -- Patterns, Insights, Decisions
    created_at TIMESTAMP DEFAULT NOW(),
    obsidian_sync_at TIMESTAMP
);

CREATE INDEX ON knowledge_notes USING ivfflat (embedding vector_cosine_ops);
```

**API Design**:
```python
# backend/app/api/v1/knowledge.py
@router.post("/sync")
async def sync_to_obsidian(event: KnowledgeEvent):
    """Auto-sync knowledge to Obsidian"""
    await obsidian_bridge.auto_sync(event.dict())
    return {"status": "synced", "timestamp": datetime.now()}

@router.get("/search")
async def search_knowledge(query: str):
    """Tier 1 + Tier 2 search"""
    # Tier 1: Obsidian (<10ms)
    obsidian_result = await obsidian_bridge.tier1_search(query)
    if obsidian_result:
        return {"tier": 1, "source": "obsidian", "solution": obsidian_result}

    # Tier 2: Context7 MCP (official docs)
    context7_result = await context7_client.search(query)
    if context7_result.confidence >= 0.95:
        # Auto-save to Obsidian for future Tier 1 hits
        await obsidian_bridge.save_solution(query, context7_result.solution)
        return {"tier": 2, "source": "context7", "solution": context7_result.solution}

    # Tier 3: User intervention
    return {"tier": 3, "message": "No automated solution found"}
```

**Performance Targets**:
- Tier 1 search: <10ms (Obsidian local files)
- Auto-sync latency: <3 seconds
- Embedding generation: <500ms (PostgreSQL pgvector)
- Knowledge accumulation: 100+ notes/month

---

### 2. Constitution Framework (P1-P17)

**Architecture Pattern**: Policy-as-Code with Pre-Commit Enforcement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Git Commit  â”‚â”€â”€â”€â”€â”€â†’â”‚ Constitutional   â”‚â”€â”€â”€â”€â”€â†’â”‚   Approve   â”‚
â”‚   (Developer) â”‚      â”‚    Guards        â”‚      â”‚  or Reject  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  8-Risk Check       â”‚
                    â”‚  Uncertainty Check  â”‚
                    â”‚  Evidence Check     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Constitution File** (YAML):
```yaml
# backend/config/UDO_CONSTITUTION.yaml
constitution:
  version: "4.0.0"
  enforcement: "strict"  # strict, advisory, disabled

articles:
  P1_design_review_first:
    title: "Design Review First"
    priority: "CRITICAL"
    rules:
      - "All implementations must complete 8-Risk Check before code"
      - "Risk categories: system_impact, git_conflict, multi_session, performance, complexity, workflow, rollback, test"
      - "Design doc must be created in docs/designs/ with ADR format"
    enforcement:
      - type: "pre-commit"
        script: "scripts/guards/design_review_guard.py"
      - type: "api-endpoint"
        validator: "backend/app/guards/design_validator.py"
    exceptions:
      - condition: "file_count < 3 AND lines_changed < 50"
        action: "skip_review"

  P2_uncertainty_disclosure:
    title: "Uncertainty Disclosure Protocol"
    priority: "CRITICAL"
    rules:
      - "All AI predictions must include confidence level: HIGH (â‰¥95%), MEDIUM (70-95%), LOW (<70%)"
      - "MEDIUM confidence requires user confirmation"
      - "LOW confidence blocks auto-execution"
    enforcement:
      - type: "runtime"
        decorator: "@require_confidence_disclosure"

  P3_evidence_based_decision:
    title: "Evidence-Based Decision Making"
    priority: "HIGH"
    rules:
      - "All optimizations require benchmark data before/after"
      - "All architectural decisions require ADR with trade-off analysis"
      - "No speculation without A/B test results"
    enforcement:
      - type: "manual-review"
        reviewer: "senior-architect"

  P5_3tier_error_resolution:
    title: "3-Tier Automated Error Resolution"
    priority: "HIGH"
    rules:
      - "Tier 1 (Obsidian): <10ms, 70% target hit rate"
      - "Tier 2 (Context7): <500ms, auto-apply if confidence â‰¥95%"
      - "Tier 3 (User): Only if Tier 1+2 fail, save solution to Obsidian"
    enforcement:
      - type: "runtime"
        service: "ErrorResolutionService"
```

**Constitutional Guard Implementation**:
```python
# scripts/guards/constitutional_guard.py
import yaml
from pathlib import Path
from typing import Dict, List

class ConstitutionalGuard:
    """Pre-commit constitutional enforcement"""

    def __init__(self):
        self.constitution = self._load_constitution()

    def check_commit(self, staged_files: List[str], commit_msg: str) -> bool:
        """Run all applicable guards"""
        violations = []

        # P1: Design Review First
        if self._requires_design_review(staged_files):
            if not self._has_design_doc(commit_msg):
                violations.append({
                    "article": "P1",
                    "severity": "CRITICAL",
                    "message": "Design review required for this change",
                    "files_changed": len(staged_files),
                    "action": "Create design doc in docs/designs/"
                })

        # P3: Evidence-Based Decision
        if "optimize" in commit_msg.lower() or "performance" in commit_msg.lower():
            if not self._has_benchmark_data(commit_msg):
                violations.append({
                    "article": "P3",
                    "severity": "HIGH",
                    "message": "Optimization requires benchmark evidence",
                    "action": "Include before/after metrics"
                })

        if violations:
            self._report_violations(violations)
            return False

        return True

    def _requires_design_review(self, files: List[str]) -> bool:
        """Check if change requires design review"""
        # Thresholds from P1 exceptions
        if len(files) < 3:
            return False

        total_lines = sum(self._count_lines_changed(f) for f in files)
        if total_lines < 50:
            return False

        # Check for architectural changes
        arch_patterns = [
            "backend/app/core/",
            "backend/app/services/",
            "config/",
            "docker-compose"
        ]

        return any(any(p in f for p in arch_patterns) for f in files)
```

**Pre-Commit Hook** (.git/hooks/pre-commit):
```bash
#!/bin/bash
# Constitutional Guard Enforcement

# Run Python guard
python scripts/guards/constitutional_guard.py --staged

if [ $? -ne 0 ]; then
    echo "âŒ Constitutional violation detected!"
    echo "See above for required actions."
    exit 1
fi

echo "âœ… Constitutional compliance verified"
exit 0
```

**API Integration**:
```python
# backend/app/api/v1/constitution.py
@router.post("/validate")
async def validate_action(action: ActionRequest):
    """Validate action against constitution"""
    guard = ConstitutionalGuard()

    # Check applicable articles
    violations = guard.validate_action(
        action_type=action.type,
        context=action.context
    )

    if violations:
        return {
            "allowed": False,
            "violations": violations,
            "required_actions": [v["action"] for v in violations]
        }

    return {"allowed": True, "articles_checked": guard.checked_articles}
```

**Performance Targets**:
- Pre-commit check: <200ms (0.18s like dev-rules)
- Design review detection: 100% accuracy
- Violation rate: <5% (high compliance)

---

### 3. Time Tracking & ROI Measurement

**Architecture Pattern**: Passive Instrumentation with Real-Time Aggregation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UDO Services   â”‚â”€â”€logâ”€â”€â†’â”‚ TimeTracker      â”‚â”€â”€aggâ”€â”€â†’â”‚  PostgreSQL  â”‚
â”‚  (auto-timed)   â”‚        â”‚  (Redis stream)  â”‚        â”‚  (metrics)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ Dashboard Charts â”‚
                           â”‚  (ROI, trends)   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Service Implementation**:
```python
# backend/app/services/time_tracking_service.py
from datetime import datetime
from typing import Optional, Dict
import asyncio

class TimeTrackingService:
    """Passive time tracking for all UDO operations"""

    def __init__(self, redis_client, postgres_client):
        self.redis = redis_client
        self.postgres = postgres_client
        self.sessions = {}

    async def start_task(self, task_id: str, task_type: str, metadata: Dict):
        """Start timing a task"""
        session_data = {
            "task_id": task_id,
            "type": task_type,
            "start_time": datetime.now().isoformat(),
            "phase": metadata.get("phase"),
            "ai_model": metadata.get("ai_model"),
            "user_id": metadata.get("user_id")
        }

        # Store in Redis for active tracking
        await self.redis.setex(
            f"task:active:{task_id}",
            3600,  # 1 hour TTL
            session_data
        )

        self.sessions[task_id] = session_data

    async def end_task(self, task_id: str, result: Dict):
        """End timing and calculate metrics"""
        session = self.sessions.get(task_id)
        if not session:
            # Try to recover from Redis
            session = await self.redis.get(f"task:active:{task_id}")

        if not session:
            raise ValueError(f"Task {task_id} not found in active sessions")

        # Calculate duration
        start = datetime.fromisoformat(session["start_time"])
        end = datetime.now()
        duration_seconds = (end - start).total_seconds()

        # Determine manual baseline (for ROI calculation)
        manual_baseline = self._get_manual_baseline(session["type"])
        time_saved = manual_baseline - duration_seconds

        # Save to PostgreSQL
        await self._save_task_metrics({
            "task_id": task_id,
            "type": session["type"],
            "phase": session["phase"],
            "ai_model": session["ai_model"],
            "start_time": start,
            "end_time": end,
            "duration_seconds": duration_seconds,
            "manual_baseline_seconds": manual_baseline,
            "time_saved_seconds": time_saved,
            "success": result.get("success", True),
            "error_count": result.get("error_count", 0),
            "tier1_hits": result.get("tier1_hits", 0),
            "tier2_hits": result.get("tier2_hits", 0)
        })

        # Auto-sync to Obsidian
        await self.obsidian_bridge.log_task_completion({
            "task_id": task_id,
            "duration_minutes": duration_seconds / 60,
            "time_saved_minutes": time_saved / 60
        })

        # Cleanup
        await self.redis.delete(f"task:active:{task_id}")
        del self.sessions[task_id]

        return {
            "duration_seconds": duration_seconds,
            "time_saved_seconds": time_saved,
            "roi_percentage": (time_saved / manual_baseline) * 100 if manual_baseline > 0 else 0
        }

    def _get_manual_baseline(self, task_type: str) -> float:
        """Manual baseline times (from VibeCoding data)"""
        baselines = {
            "error_resolution": 1800,  # 30 min
            "design": 7200,            # 2 hours
            "implementation": 14400,   # 4 hours
            "testing": 3600,           # 1 hour
            "documentation": 3600,     # 1 hour
            "code_review": 1800,       # 30 min
            "debugging": 2400          # 40 min
        }
        return baselines.get(task_type, 3600)  # Default 1 hour
```

**ROI Calculation Engine**:
```python
# backend/app/services/roi_calculator.py
class ROICalculator:
    """Calculate time savings and ROI metrics"""

    async def calculate_weekly_roi(self, week_start: datetime) -> Dict:
        """Weekly ROI summary"""
        tasks = await self._get_weekly_tasks(week_start)

        # Aggregate metrics
        total_manual_time = sum(t["manual_baseline_seconds"] for t in tasks)
        total_actual_time = sum(t["duration_seconds"] for t in tasks)
        total_time_saved = total_manual_time - total_actual_time

        # Breakdown by category
        by_type = {}
        for task in tasks:
            task_type = task["type"]
            if task_type not in by_type:
                by_type[task_type] = {
                    "count": 0,
                    "manual_time": 0,
                    "actual_time": 0,
                    "time_saved": 0
                }
            by_type[task_type]["count"] += 1
            by_type[task_type]["manual_time"] += task["manual_baseline_seconds"]
            by_type[task_type]["actual_time"] += task["duration_seconds"]
            by_type[task_type]["time_saved"] += task["manual_baseline_seconds"] - task["duration_seconds"]

        # Calculate automation rate
        automated_tasks = sum(1 for t in tasks if t["tier1_hits"] > 0 or t["tier2_hits"] > 0)
        automation_rate = (automated_tasks / len(tasks)) * 100 if tasks else 0

        return {
            "week_start": week_start.isoformat(),
            "total_tasks": len(tasks),
            "manual_time_hours": total_manual_time / 3600,
            "actual_time_hours": total_actual_time / 3600,
            "time_saved_hours": total_time_saved / 3600,
            "efficiency_gain_percent": (total_time_saved / total_manual_time) * 100 if total_manual_time > 0 else 0,
            "automation_rate_percent": automation_rate,
            "by_type": by_type,
            "roi_percentage": (total_time_saved / total_actual_time) * 100 if total_actual_time > 0 else 0
        }
```

**Dashboard Component**:
```typescript
// web-dashboard/components/TimeTrackingDashboard.tsx
export function TimeTrackingDashboard() {
  const [weeklyROI, setWeeklyROI] = useState<ROIData | null>(null);

  useEffect(() => {
    // Fetch weekly ROI
    fetch('/api/v1/roi/weekly')
      .then(res => res.json())
      .then(data => setWeeklyROI(data));
  }, []);

  if (!weeklyROI) return <Loading />;

  return (
    <div className="grid grid-cols-3 gap-6">
      <MetricCard
        title="Time Saved This Week"
        value={`${weeklyROI.time_saved_hours.toFixed(1)} hours`}
        change={`+${weeklyROI.efficiency_gain_percent.toFixed(1)}%`}
        trend="up"
      />

      <MetricCard
        title="Automation Rate"
        value={`${weeklyROI.automation_rate_percent.toFixed(1)}%`}
        target="95%"
        progress={weeklyROI.automation_rate_percent}
      />

      <MetricCard
        title="Weekly ROI"
        value={`${weeklyROI.roi_percentage.toFixed(0)}%`}
        target="377%"
        progress={(weeklyROI.roi_percentage / 377) * 100}
      />

      <div className="col-span-3">
        <BarChart
          data={Object.entries(weeklyROI.by_type).map(([type, metrics]) => ({
            name: type,
            manual: metrics.manual_time / 3600,
            actual: metrics.actual_time / 3600,
            saved: metrics.time_saved / 3600
          }))}
          xKey="name"
          bars={[
            { key: "manual", color: "#ef4444", name: "Manual Time" },
            { key: "actual", color: "#10b981", name: "Actual Time" },
            { key: "saved", color: "#3b82f6", name: "Time Saved" }
          ]}
        />
      </div>
    </div>
  );
}
```

**Database Schema**:
```sql
CREATE TABLE task_metrics (
    id SERIAL PRIMARY KEY,
    task_id TEXT NOT NULL,
    type TEXT NOT NULL,
    phase TEXT,
    ai_model TEXT,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP NOT NULL,
    duration_seconds INTEGER NOT NULL,
    manual_baseline_seconds INTEGER NOT NULL,
    time_saved_seconds INTEGER NOT NULL,
    success BOOLEAN DEFAULT TRUE,
    error_count INTEGER DEFAULT 0,
    tier1_hits INTEGER DEFAULT 0,
    tier2_hits INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_task_metrics_week ON task_metrics(DATE_TRUNC('week', start_time));
CREATE INDEX idx_task_metrics_type ON task_metrics(type);
