# ì—­í• ë³„ ì•¡ì…˜ í”Œëœ (Role-Based Action Plans)

> **ìƒì„±ì¼**: 2025-11-28
> **ê¸°ë°˜**: í†µí•© ê°œë°œ ê°€ì´ë“œ (INTEGRATED_DEVELOPMENT_GUIDE.md)
> **ëª©ì **: ê° ì—­í• ì´ ì¦‰ì‹œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì‘ì—… ëª©ë¡

---

## ëª©ì°¨

1. [Backend Developer ì•¡ì…˜ í”Œëœ](#backend-developer-ì•¡ì…˜-í”Œëœ)
2. [Frontend Developer ì•¡ì…˜ í”Œëœ](#frontend-developer-ì•¡ì…˜-í”Œëœ)
3. [DevOps Engineer ì•¡ì…˜ í”Œëœ](#devops-engineer-ì•¡ì…˜-í”Œëœ)
4. [AI/ML Engineer ì•¡ì…˜ í”Œëœ](#aiml-engineer-ì•¡ì…˜-í”Œëœ)
5. [íŒ€ í˜‘ì—… ì²´í¬í¬ì¸íŠ¸](#íŒ€-í˜‘ì—…-ì²´í¬í¬ì¸íŠ¸)

---

## Backend Developer ì•¡ì…˜ í”Œëœ

### ğŸ¯ í•µì‹¬ ëª©í‘œ
- Week 1: API-UI Bridge ì™„ì„± (ì‚¬ìš©ìê°€ ë°ì´í„° ë³¼ ìˆ˜ ìˆê²Œ)
- Week 2: ìë™í™” ë£¨í”„ ì™„ì„± (Time Tracking â†’ Uncertainty ìë™ ì—…ë°ì´íŠ¸)
- Week 3: AI ê¸°ë°˜ Mitigation Strategy
- Week 4: ì„±ëŠ¥ + ë³´ì•ˆ ìµœì í™”

### Week 1: Foundation (24ì‹œê°„)

#### Day 1 - Monday

**ì˜¤ì „ (9am-12pm)** - 4ì‹œê°„

**Task 1.1: mypy íƒ€ì… ì˜¤ë¥˜ ìˆ˜ì •** (4ì‹œê°„)
```bash
# Terminal 1
cd C:\Users\user\Documents\GitHub\UDO-Development-Platform
.venv\Scripts\activate
mypy --strict src/ backend/ > mypy_errors.txt

# ì˜¤ë¥˜ íŒŒì¼ ë¶„ì„
# ì˜ˆìƒ ì˜¤ë¥˜:
# 1. src/unified_development_orchestrator_v2.py:45 - Optional[str] vs str
# 2. backend/app/services/quality_service.py:123 - Dict[str, Any] vs TypedDict
# 3. src/uncertainty_map_v3.py:67 - List[float] vs np.ndarray

# ìˆ˜ì • ë°©ë²•:
# - Optional íƒ€ì… ëª…ì‹œ
# - TypedDict ì‚¬ìš©
# - numpy typing (from numpy.typing import NDArray)

# ê²€ì¦
mypy --strict src/ backend/  # ì˜¤ë¥˜ 0ê°œ ëª©í‘œ
```

**ì˜¤í›„ (1pm-5pm)** - 4ì‹œê°„

**Task 1.2: PostgreSQL + Dual-Write** (4ì‹œê°„)
```bash
# PostgreSQL ì‹œì‘
docker-compose up -d db

# ì—°ê²° í…ŒìŠ¤íŠ¸
psql -h localhost -U udo_user -d udo_dev

# Alembic ë§ˆì´ê·¸ë ˆì´ì…˜
cd backend
alembic upgrade head

# í…Œì´ë¸” í™•ì¸
psql -h localhost -U udo_user -d udo_dev -c '\dt'
# ì˜ˆìƒ í…Œì´ë¸”: projects, tasks, time_tracking_sessions, uncertainty_history ë“±

# Dual-write ë§¤ë‹ˆì € í™•ì¸
cat app/db/dual_write_manager.py
# ë¡œì§:
# - write() â†’ PostgreSQL (primary) + SQLite (shadow)
# - read() â†’ PostgreSQL
# - sync_check() â†’ ë§¤ì‹œê°„ ë°ì´í„° ì •í•©ì„± í™•ì¸

# í…ŒìŠ¤íŠ¸
.venv\Scripts\python.exe -c "
from backend.app.db.dual_write_manager import DualWriteManager
dm = DualWriteManager()
dm.write('projects', {'name': 'Test', 'id': 1})
print('PostgreSQL:', dm.read_postgres('projects', 1))
print('SQLite:', dm.read_sqlite('projects', 1))
# ê²°ê³¼: ì–‘ìª½ì— ë™ì¼í•œ ë°ì´í„° ì¡´ì¬
"
```

**Evening Review (5pm-6pm)** - 1ì‹œê°„
```yaml
ì²´í¬ë¦¬ìŠ¤íŠ¸:
  - âœ… mypy ì˜¤ë¥˜ 0ê°œ
  - âœ… PostgreSQL ì—°ê²° ì„±ê³µ
  - âœ… Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
  - âœ… Dual-write ì‘ë™ í™•ì¸

git_commit:
  message: "feat(week1-day1): PostgreSQL setup + mypy fixes complete"
  files: [src/, backend/, alembic/]
```

---

#### Day 2 - Tuesday

**ì˜¤ì „ (9am-12pm)** - 4ì‹œê°„

**Task 2.1: Uncertainty API ì—”ë“œí¬ì¸íŠ¸** (3ì‹œê°„)
```python
# íŒŒì¼: backend/app/routers/uncertainty.py

from fastapi import APIRouter, Depends
from app.models.uncertainty import UncertaintyResponse
from src.uncertainty_map_v3 import UncertaintyMapV3

router = APIRouter(prefix="/api/uncertainty", tags=["uncertainty"])

@router.get("/status", response_model=UncertaintyResponse)
async def get_uncertainty_status(project_id: str = "default"):
    """
    ë¶ˆí™•ì‹¤ì„± í˜„ì¬ ìƒíƒœ ì¡°íšŒ

    Returns:
        uncertainty_vector: [ê¸°ìˆ , ì¼ì •, ì˜ˆì‚°, í’ˆì§ˆ, íŒ€] 5D ë²¡í„°
        quantum_state: DETERMINISTIC/PROBABILISTIC/QUANTUM/CHAOTIC/VOID
        confidence: 0.0-1.0 (Bayesian confidence)
        last_updated: ISO timestamp
        mitigation_suggestions: [] (ë‚˜ì¤‘ì— êµ¬í˜„)
    """
    uncertainty_map = UncertaintyMapV3(project_id=project_id)

    # 5D ë²¡í„° ê³„ì‚°
    vector = uncertainty_map.calculate_current_vector()

    # ì–‘ì ìƒíƒœ ë¶„ë¥˜
    state = uncertainty_map.classify_quantum_state(vector)

    # Bayesian ì‹ ë¢°ë„
    confidence = uncertainty_map.calculate_confidence(vector)

    return UncertaintyResponse(
        uncertainty_vector=vector.tolist(),
        quantum_state=state,
        confidence=confidence,
        last_updated=uncertainty_map.get_last_update_time(),
        mitigation_suggestions=[]
    )

# í…ŒìŠ¤íŠ¸
# curl http://localhost:8000/api/uncertainty/status
# ì˜ˆìƒ ì‘ë‹µ:
# {
#   "uncertainty_vector": [0.3, 0.5, 0.2, 0.4, 0.1],
#   "quantum_state": "PROBABILISTIC",
#   "confidence": 0.72,
#   "last_updated": "2025-11-28T09:30:00Z",
#   "mitigation_suggestions": []
# }
```

**Task 2.2: Friendly Error Formatter** (1ì‹œê°„)
```python
# íŒŒì¼: backend/app/core/error_formatter.py

from typing import Dict, Any
from fastapi import HTTPException
from sqlalchemy.exc import DatabaseError, IntegrityError

class FriendlyErrorFormatter:
    """ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ë³€í™˜"""

    ERROR_MESSAGES = {
        # ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬
        "DatabaseError": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "IntegrityError": "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",

        # ê²€ì¦ ì—ëŸ¬
        "ValidationError": "ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {field}",

        # AI API ì—ëŸ¬
        "AIAPIError": "AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìºì‹œëœ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "RateLimitError": "ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. {retry_after}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",

        # ê¶Œí•œ ì—ëŸ¬
        "AuthenticationError": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "AuthorizationError": "ì´ ì‘ì—…ì„ ìˆ˜í–‰í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.",
    }

    @classmethod
    def format(cls, error: Exception) -> Dict[str, Any]:
        """ì—ëŸ¬ë¥¼ ì¹œí™”ì ì¸ ë©”ì‹œì§€ë¡œ ë³€í™˜"""
        error_type = type(error).__name__

        if error_type in cls.ERROR_MESSAGES:
            message = cls.ERROR_MESSAGES[error_type]
            # í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜
            if hasattr(error, 'field'):
                message = message.format(field=error.field)
            elif hasattr(error, 'retry_after'):
                message = message.format(retry_after=error.retry_after)
        else:
            message = "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."

        return {
            "error": True,
            "message": message,
            "detail": str(error),  # ë””ë²„ê¹…ìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œê±°)
            "error_type": error_type
        }

# FastAPI exception handler
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

app = FastAPI()

@app.exception_handler(Exception)
async def friendly_exception_handler(request: Request, exc: Exception):
    formatted = FriendlyErrorFormatter.format(exc)
    return JSONResponse(
        status_code=500,
        content=formatted
    )
```

**ì˜¤í›„ (1pm-5pm)** - 4ì‹œê°„

**Task 2.3: Uncertainty ê³„ì‚° ê²€ì¦** (4ì‹œê°„)
```bash
# í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‘ì„±
# backend/tests/test_uncertainty_integration.py

pytest backend/tests/test_uncertainty_integration.py -v

# ì˜ˆìƒ í…ŒìŠ¤íŠ¸:
# 1. test_uncertainty_vector_calculation
#    - ì…ë ¥: ì‘ì—… 3ê°œ (2ê°œ ì§€ì—°, 1ê°œ ì •ì‹œ)
#    - ì˜ˆìƒ: technical_risk > 0.5
#
# 2. test_quantum_state_classification
#    - ì…ë ¥: vector = [0.1, 0.2, 0.1, 0.15, 0.05]
#    - ì˜ˆìƒ: DETERMINISTIC (ì´í•© < 0.1)
#
# 3. test_bayesian_confidence
#    - ì…ë ¥: historical_accuracy = 0.85, vector_magnitude = 0.4
#    - ì˜ˆìƒ: confidence â‰ˆ 0.68
#
# 4. test_api_endpoint
#    - GET /api/uncertainty/status
#    - ì‘ë‹µ ì½”ë“œ: 200
#    - ì‘ë‹µ êµ¬ì¡°: uncertainty_vector (list), quantum_state (str), confidence (float)

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
pytest --cov=backend --cov-report=html
# ëª©í‘œ: 80% ì´ìƒ
```

---

#### Day 3 - Wednesday

**ì „ì²´ (9am-5pm)** - 8ì‹œê°„

**Task 3.1: Prometheus + Monitoring** (4ì‹œê°„)
```python
# íŒŒì¼: backend/app/monitoring.py (ì´ë¯¸ ì¡´ì¬, ê°œì„ )

from prometheus_client import Counter, Histogram, Gauge
from functools import wraps
import time

# ë©”íŠ¸ë¦­ ì •ì˜
api_latency_seconds = Histogram(
    'api_latency_seconds',
    'API latency in seconds',
    ['endpoint', 'method'],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0]
)

uncertainty_updates_total = Counter(
    'uncertainty_updates_total',
    'Total number of uncertainty updates',
    ['quantum_state']
)

ai_api_calls_total = Counter(
    'ai_api_calls_total',
    'Total number of AI API calls',
    ['model', 'status']  # model: claude/codex/gemini, status: success/failure
)

current_uncertainty = Gauge(
    'current_uncertainty',
    'Current uncertainty magnitude',
    ['project_id']
)

# ë°ì½”ë ˆì´í„°
def measure_latency(func):
    """API ë ˆì´í„´ì‹œ ì¸¡ì •"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            latency = time.time() - start
            api_latency_seconds.labels(
                endpoint=func.__name__,
                method='GET'  # requestì—ì„œ ê°€ì ¸ì˜¤ê¸°
            ).observe(latency)
    return wrapper

# ì‚¬ìš© ì˜ˆì‹œ
@router.get("/uncertainty/status")
@measure_latency
async def get_uncertainty_status(...):
    ...
```

**ì„¤ì • íŒŒì¼**:
```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'fastapi'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'

  - job_name: 'celery'
    static_configs:
      - targets: ['localhost:5555']  # Flower

# Docker Composeì— ì¶”ê°€
docker-compose up -d prometheus grafana

# Grafana ëŒ€ì‹œë³´ë“œ í™•ì¸
# http://localhost:3001 (admin/admin)
```

**Task 3.2: Celery + Redis** (4ì‹œê°„)
```python
# íŒŒì¼: backend/app/background_tasks.py (ì´ë¯¸ ì¡´ì¬, ê°œì„ )

from celery import Celery
from celery.utils.log import get_task_logger

logger = get_task_logger(__name__)

celery_app = Celery(
    'udo_tasks',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/0'
)

# Celery ì„¤ì •
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Seoul',
    enable_utc=True,
    task_acks_late=True,
    worker_prefetch_multiplier=1,
    task_time_limit=300,  # 5ë¶„
)

# AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íƒœìŠ¤í¬
@celery_app.task(name='ai_orchestration', bind=True, max_retries=3)
def orchestrate_ai(self, query: str, context: dict):
    """3-AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬"""
    from src.three_ai_collaboration_bridge import ThreeAICollaborationBridge

    try:
        bridge = ThreeAICollaborationBridge()
        result = bridge.orchestrate(query, context)

        # ë©”íŠ¸ë¦­ ê¸°ë¡
        ai_api_calls_total.labels(
            model='claude',  # ë˜ëŠ” ì‹¤ì œ ì‚¬ìš©ëœ ëª¨ë¸
            status='success'
        ).inc()

        return result
    except Exception as exc:
        logger.error(f"AI orchestration failed: {exc}")
        ai_api_calls_total.labels(
            model='unknown',
            status='failure'
        ).inc()
        # ì¬ì‹œë„
        raise self.retry(exc=exc, countdown=60)

# Celery worker ì‹œì‘
# celery -A backend.app.background_tasks worker --loglevel=info --concurrency=3
```

---

#### Day 4 - Thursday

**ì˜¤ì „ (9am-12pm)** - 4ì‹œê°„

**Task 4.1: Notification Service** (4ì‹œê°„)
```python
# íŒŒì¼: backend/app/services/notification_service.py (ì‹ ê·œ)

from typing import List, Dict, Any
from datetime import datetime, timedelta
import aiohttp
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail

class NotificationService:
    """ì•Œë¦¼ ì„œë¹„ìŠ¤ (Email + Slack)"""

    def __init__(self):
        self.sendgrid_client = SendGridAPIClient(os.getenv('SENDGRID_API_KEY'))
        self.slack_webhook_url = os.getenv('SLACK_WEBHOOK_URL')
        self.rate_limiter = {}  # {category: last_sent_time}
        self.rate_limit_minutes = 15

    async def send_notification(
        self,
        category: str,  # 'uncertainty_spike', 'budget_warning', 'task_overrun'
        title: str,
        message: str,
        channels: List[str] = ['email', 'slack'],
        severity: str = 'info'  # 'info', 'warning', 'critical'
    ):
        """ì•Œë¦¼ ì „ì†¡ (Rate Limiting ì ìš©)"""

        # Rate Limiting ì²´í¬
        if not self._can_send(category):
            logger.info(f"Rate limit: Skipping {category} (sent within {self.rate_limit_minutes} minutes)")
            return

        # ì´ë©”ì¼ ì „ì†¡
        if 'email' in channels:
            await self._send_email(title, message, severity)

        # ìŠ¬ë™ ì „ì†¡
        if 'slack' in channels:
            await self._send_slack(title, message, severity)

        # Rate Limiter ì—…ë°ì´íŠ¸
        self.rate_limiter[category] = datetime.now()

    def _can_send(self, category: str) -> bool:
        """Rate Limiting ì²´í¬"""
        if category not in self.rate_limiter:
            return True

        last_sent = self.rate_limiter[category]
        elapsed = (datetime.now() - last_sent).total_seconds() / 60
        return elapsed >= self.rate_limit_minutes

    async def _send_email(self, title: str, message: str, severity: str):
        """SendGrid ì´ë©”ì¼ ì „ì†¡"""
        mail = Mail(
            from_email='noreply@udo-platform.com',
            to_emails='dev-team@company.com',
            subject=f"[{severity.upper()}] {title}",
            html_content=f"""
            <h2>{title}</h2>
            <p>{message}</p>
            <p><a href="http://localhost:3000">ëŒ€ì‹œë³´ë“œ í™•ì¸</a></p>
            """
        )

        try:
            response = self.sendgrid_client.send(mail)
            logger.info(f"Email sent: {response.status_code}")
        except Exception as e:
            logger.error(f"Email failed: {e}")

    async def _send_slack(self, title: str, message: str, severity: str):
        """Slack Webhook ì „ì†¡"""
        emoji_map = {
            'info': ':information_source:',
            'warning': ':warning:',
            'critical': ':rotating_light:'
        }

        payload = {
            "text": f"{emoji_map[severity]} *{title}*",
            "blocks": [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*{title}*"}
                },
                {
                    "type": "section",
                    "text": {"type": "plain_text", "text": message}
                },
                {
                    "type": "actions",
                    "elements": [
                        {
                            "type": "button",
                            "text": {"type": "plain_text", "text": "ëŒ€ì‹œë³´ë“œ í™•ì¸"},
                            "url": "http://localhost:3000"
                        }
                    ]
                }
            ]
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(self.slack_webhook_url, json=payload) as resp:
                if resp.status == 200:
                    logger.info("Slack notification sent")
                else:
                    logger.error(f"Slack failed: {resp.status}")

# íŠ¸ë¦¬ê±° ì˜ˆì‹œ
notification_service = NotificationService()

async def on_uncertainty_spike(quantum_state: str):
    """ë¶ˆí™•ì‹¤ì„± ê¸‰ì¦ ì‹œ ì•Œë¦¼"""
    if quantum_state in ['QUANTUM', 'CHAOTIC', 'VOID']:
        await notification_service.send_notification(
            category='uncertainty_spike',
            title='ë¶ˆí™•ì‹¤ì„± ì„ê³„ê°’ ì´ˆê³¼',
            message=f'í”„ë¡œì íŠ¸ì˜ ë¶ˆí™•ì‹¤ì„±ì´ {quantum_state} ìƒíƒœì…ë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.',
            channels=['email', 'slack'],
            severity='warning' if quantum_state == 'QUANTUM' else 'critical'
        )
```

**ì˜¤í›„ (1pm-5pm)** - 4ì‹œê°„

**Task 4.2: í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80%** (4ì‹œê°„)
```bash
# í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¶”ê°€
# backend/tests/test_uncertainty_api.py
# backend/tests/test_notification_service.py
# backend/tests/test_dual_write.py

pytest backend/tests/ --cov=backend --cov-report=html --cov-report=term

# ì»¤ë²„ë¦¬ì§€ ëª©í‘œ:
# - backend/app/routers/: 85%
# - backend/app/services/: 80%
# - backend/app/models/: 90%
# - ì „ì²´: 80%+

# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ í™•ì¸
# htmlcov/index.html
```

---

### Week 2-4: ìì„¸í•œ ê³„íšì€ í†µí•© ê°œë°œ ê°€ì´ë“œ ì°¸ì¡°

---

## Frontend Developer ì•¡ì…˜ í”Œëœ

### ğŸ¯ í•µì‹¬ ëª©í‘œ
- Week 1: API ì—°ë™ + ì‹œê°ì  í”¼ë“œë°±
- Week 2: Uncertainty ì‹œê°í™” + ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- Week 3: Mitigation Panel + AI Persona
- Week 4: E2E í…ŒìŠ¤íŠ¸ + ë¬¸ì„œí™”

### Week 1: API Connection (16ì‹œê°„)

#### Day 1 - Monday

**ì˜¤ì „ (9am-12pm)** - 4ì‹œê°„

**Task 1.1: One-Click Start ìŠ¤í¬ë¦½íŠ¸** (2ì‹œê°„)
```json
// íŒŒì¼: web-dashboard/package.json

{
  "scripts": {
    "dev": "next dev",
    "dev:full": "concurrently \"cd ../backend && .venv/Scripts/python.exe -m uvicorn main:app --reload\" \"npm run dev\"",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "devDependencies": {
    "concurrently": "^8.0.0"  // ì¶”ê°€
  }
}

// npm install concurrently

// í…ŒìŠ¤íŠ¸
// npm run dev:full
// â†’ Backend (http://localhost:8000) + Frontend (http://localhost:3000) ë™ì‹œ ì‹œì‘
```

**Task 1.2: Scripts í¬ë¡œìŠ¤ í”Œë«í¼** (2ì‹œê°„)
```bash
# íŒŒì¼: scripts/dev-start.sh (Unix)
#!/bin/bash
cd "$(dirname "$0")/.."
source .venv/bin/activate
concurrently "cd backend && uvicorn main:app --reload" "cd web-dashboard && npm run dev"

# íŒŒì¼: scripts/dev-start.ps1 (Windows)
$scriptPath = Split-Path -Parent $MyInvocation.MyCommand.Path
cd "$scriptPath/.."
.venv\Scripts\activate
concurrently "cd backend && uvicorn main:app --reload" "cd web-dashboard && npm run dev"

# ì‹¤í–‰ ê¶Œí•œ
chmod +x scripts/dev-start.sh

# í…ŒìŠ¤íŠ¸
# Windows: ./scripts/dev-start.ps1
# Mac/Linux: ./scripts/dev-start.sh
```

---

#### Day 2 - Tuesday

**ì˜¤ì „ (9am-12pm)** - 4ì‹œê°„

**Task 2.1: API Integration** (4ì‹œê°„)
```typescript
// íŒŒì¼: web-dashboard/app/page.tsx

"use client"

import { useQuery } from '@tanstack/react-query'
import { UncertaintyMap } from '@/components/dashboard/uncertainty-map'
import { UncertaintyMapSkeleton } from '@/components/dashboard/skeleton'
import { ErrorFallback } from '@/components/ErrorFallback'

interface UncertaintyData {
  uncertainty_vector: number[]  // [ê¸°ìˆ , ì¼ì •, ì˜ˆì‚°, í’ˆì§ˆ, íŒ€]
  quantum_state: 'DETERMINISTIC' | 'PROBABILISTIC' | 'QUANTUM' | 'CHAOTIC' | 'VOID'
  confidence: number  // 0.0-1.0
  last_updated: string
  mitigation_suggestions: any[]
}

export default function Dashboard() {
  const { data, isLoading, error, refetch } = useQuery<UncertaintyData>({
    queryKey: ['uncertainty'],
    queryFn: async () => {
      const response = await fetch('http://localhost:8000/api/uncertainty/status')
      if (!response.ok) {
        throw new Error('Failed to fetch uncertainty data')
      }
      return response.json()
    },
    refetchInterval: 5000,  // 5ì´ˆë§ˆë‹¤ ìë™ ìƒˆë¡œê³ ì¹¨
    retry: 3,
    retryDelay: 1000,
  })

  if (isLoading) {
    return <UncertaintyMapSkeleton />
  }

  if (error) {
    return <ErrorFallback error={error} onRetry={refetch} />
  }

  return (
    <div className="container mx-auto p-6">
      <h1 className="text-3xl font-bold mb-6">UDO Dashboard</h1>
      <UncertaintyMap data={data!} />
    </div>
  )
}
```

**ì˜¤í›„ (1pm-5pm)** - 4ì‹œê°„

**Task 2.2: Connection Status UI** (3ì‹œê°„)
```typescript
// íŒŒì¼: web-dashboard/components/ConnectionStatus.tsx

import { Loader2, AlertCircle, RefreshCw } from 'lucide-react'
import { Button } from '@/components/ui/button'

export function UncertaintyMapSkeleton() {
  return (
    <div className="animate-pulse space-y-4">
      <div className="h-8 bg-gray-200 rounded w-1/4"></div>
      <div className="h-64 bg-gray-200 rounded"></div>
      <div className="flex items-center space-x-2 text-gray-500">
        <Loader2 className="h-4 w-4 animate-spin" />
        <span>ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...</span>
      </div>
    </div>
  )
}

export function ErrorFallback({
  error,
  onRetry
}: {
  error: Error
  onRetry: () => void
}) {
  return (
    <div className="flex flex-col items-center justify-center h-64 space-y-4">
      <AlertCircle className="h-12 w-12 text-red-500" />
      <h2 className="text-xl font-semibold text-gray-900">ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</h2>
      <p className="text-gray-600 text-center max-w-md">
        ì„œë²„ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
      </p>
      <p className="text-sm text-gray-500 font-mono bg-gray-100 p-2 rounded">
        {error.message}
      </p>
      <Button onClick={onRetry} className="flex items-center space-x-2">
        <RefreshCw className="h-4 w-4" />
        <span>ë‹¤ì‹œ ì‹œë„</span>
      </Button>
    </div>
  )
}

export function EmptyState() {
  return (
    <div className="flex flex-col items-center justify-center h-64 space-y-4">
      <div className="text-6xl">ğŸ“Š</div>
      <h2 className="text-xl font-semibold text-gray-900">ì•„ì§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤</h2>
      <p className="text-gray-600 text-center max-w-md">
        ì²« ì‘ì—…ì„ ì‹œì‘í•˜ë©´ ë¶ˆí™•ì‹¤ì„± ì§€ë„ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
      </p>
      <Button>ì‘ì—… ì‹œì‘í•˜ê¸°</Button>
    </div>
  )
}
```

**Task 2.3: Toast Notifications** (1ì‹œê°„)
```bash
# ì„¤ì¹˜
npm install react-hot-toast

# íŒŒì¼: web-dashboard/components/ToastNotifications.tsx
```

```typescript
import toast, { Toaster } from 'react-hot-toast'

// Layoutì— ì¶”ê°€
export default function RootLayout({ children }: { children: React.ReactNode }) {
  return (
    <html lang="ko">
      <body>
        {children}
        <Toaster position="top-right" />
      </body>
    </html>
  )
}

// ì‚¬ìš© ì˜ˆì‹œ
export function showNotifications(event: string, data: any) {
  switch (event) {
    case 'uncertainty_spike':
      toast.error(`âš ï¸ ë¶ˆí™•ì‹¤ì„±ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤! (${data.quantum_state})`, {
        duration: 5000,
      })
      break

    case 'task_overrun':
      toast.warning(`â±ï¸ ì‘ì—…ì´ ì˜ˆìƒë³´ë‹¤ ${data.overrun_pct}% ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤`, {
        duration: 4000,
      })
      break

    case 'budget_warning':
      toast(`ğŸ’° AI ë¹„ìš©ì´ ì„ê³„ê°’ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤ ($${data.current}/$${data.limit})`, {
        icon: 'ğŸ’°',
        duration: 6000,
      })
      break
  }
}
```

---

### Week 2-4: ìì„¸í•œ ê³„íšì€ í†µí•© ê°œë°œ ê°€ì´ë“œ ì°¸ì¡°

---

## DevOps Engineer ì•¡ì…˜ í”Œëœ

### Week 1: Infrastructure (20ì‹œê°„)

#### Day 1 - ì„¤ì • ê²€ì¦ ë° ê°œì„  (4ì‹œê°„)

**Task 1.1: docker-compose.yml ì ê²€** (2ì‹œê°„)
```yaml
# íŒŒì¼: docker-compose.yml

version: '3.8'

services:
  db:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_USER: udo_user
      POSTGRES_PASSWORD: udo_pass
      POSTGRES_DB: udo_dev
    ports:
      - "5432:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - udo-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - udo-network

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - udo-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - udo-network

volumes:
  db-data:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  udo-network:
    driver: bridge

# í…ŒìŠ¤íŠ¸
# docker-compose up -d
# docker-compose ps
```

---

## AI/ML Engineer ì•¡ì…˜ í”Œëœ

### Week 2: ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ (20ì‹œê°„)

#### Sprint 3: Bayesian ì‹œìŠ¤í…œ (12ì‹œê°„)

**Task: Bayesian Update ì•Œê³ ë¦¬ì¦˜**
```python
# íŒŒì¼: src/adaptive_bayesian_uncertainty.py

import numpy as np
from scipy.stats import beta
from typing import List, Tuple

class AdaptiveBayesianUncertainty:
    """ì ì‘í˜• Bayesian ë¶ˆí™•ì‹¤ì„± ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.prior = np.array([0.5] * 5)  # 5D prior (neutral)
        self.historical_accuracy = 0.7  # ì´ˆê¸° ì •í™•ë„

    def update_uncertainty(
        self,
        observed_vector: np.ndarray,
        likelihood: float = 0.8
    ) -> np.ndarray:
        """
        Bayesian update

        Args:
            observed_vector: ê´€ì¸¡ëœ 5D ë²¡í„°
            likelihood: ê´€ì¸¡ ì‹ ë¢°ë„

        Returns:
            posterior: ì—…ë°ì´íŠ¸ëœ ë¶ˆí™•ì‹¤ì„± ë²¡í„°
        """
        # Bayes' Theorem: P(H|E) = P(E|H) * P(H) / P(E)
        evidence = self._calculate_evidence(observed_vector)
        posterior = (likelihood * observed_vector * self.prior) / evidence

        # Prior ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´)
        self.prior = posterior

        return posterior

    def _calculate_evidence(self, observed: np.ndarray) -> float:
        """ì£¼ë³€ í™•ë¥  ê³„ì‚°"""
        # Normalization constant
        return np.sum(observed * self.prior)

    def calculate_confidence(
        self,
        uncertainty_vector: np.ndarray
    ) -> float:
        """
        Bayesian confidence ê³„ì‚°

        Returns:
            confidence: 0.0-1.0 (ë†’ì„ìˆ˜ë¡ í™•ì‹ )
        """
        magnitude = np.linalg.norm(uncertainty_vector)
        # ë¶ˆí™•ì‹¤ì„±ì´ ë‚®ì„ìˆ˜ë¡ confidence ë†’ìŒ
        base_confidence = 1 / (1 + magnitude)
        # Historical accuracy ë°˜ì˜
        adjusted_confidence = base_confidence * self.historical_accuracy
        return np.clip(adjusted_confidence, 0.0, 1.0)

    def process_rlhf_feedback(
        self,
        decision_id: str,
        rating: int,  # 1 (ê¸ì •) or 0 (ë¶€ì •)
        uncertainty_at_decision: float
    ):
        """
        RLHF í”¼ë“œë°± ì²˜ë¦¬

        - ê¸ì • í”¼ë“œë°±: ë¶ˆí™•ì‹¤ì„± ê°ì†Œ, accuracy ì¦ê°€
        - ë¶€ì • í”¼ë“œë°±: ë¶ˆí™•ì‹¤ì„± ì¦ê°€, accuracy ê°ì†Œ
        """
        if rating == 1:  # ê¸ì •
            # ë¶ˆí™•ì‹¤ì„± 10% ê°ì†Œ
            self.prior = np.maximum(self.prior - 0.1, 0.1)
            # Accuracy 5% ì¦ê°€
            self.historical_accuracy = min(self.historical_accuracy + 0.05, 1.0)
        else:  # ë¶€ì •
            # ë¶ˆí™•ì‹¤ì„± 20% ì¦ê°€
            self.prior = np.minimum(self.prior + 0.2, 0.9)
            # Accuracy 5% ê°ì†Œ
            self.historical_accuracy = max(self.historical_accuracy - 0.05, 0.5)

        logger.info(f"RLHF feedback processed: rating={rating}, new_accuracy={self.historical_accuracy:.2f}")

# í…ŒìŠ¤íŠ¸
# pytest tests/test_adaptive_bayesian.py -v
```

---

## íŒ€ í˜‘ì—… ì²´í¬í¬ì¸íŠ¸

### Week 1 Friday 5pm - ì „ì²´ íŒ€ ê²€ì¦

**ì°¸ì„ì**: Backend, Frontend, DevOps, AI/ML (ì „ì›)

**ì•ˆê±´**:
1. âœ… ê° ì—­í•  Week 1 ì‘ì—… ì™„ë£Œ í™•ì¸
2. âœ… í†µí•© í…ŒìŠ¤íŠ¸ (`npm run dev:full` + API í˜¸ì¶œ)
3. âœ… ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì¸¡ì • (k6)
4. âœ… Week 2 ê²½ë¡œ ì„ íƒ (Optimistic/Realistic/Pessimistic)

**ì¤€ë¹„ë¬¼**:
- Backend: API ì—”ë“œí¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ + Swagger UI
- Frontend: ë¸Œë¼ìš°ì € ë°ëª¨ (localhost:3000)
- DevOps: Prometheus/Grafana ëŒ€ì‹œë³´ë“œ (localhost:9090, :3001)
- AI/ML: ë¶ˆí™•ì‹¤ì„± ê³„ì‚° ê²€ì¦ ê²°ê³¼

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```yaml
infrastructure:
  - âœ… PostgreSQL ì—°ê²°
  - âœ… Redis ì—°ê²°
  - âœ… Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  - âœ… Grafana ëŒ€ì‹œë³´ë“œ í‘œì‹œ

backend:
  - âœ… GET /api/uncertainty/status ì‘ë™
  - âœ… Friendly Error ë©”ì‹œì§€ ì‘ë™
  - âœ… í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ >= 80%
  - âœ… mypy ì˜¤ë¥˜ 0ê°œ

frontend:
  - âœ… npm run dev:full ì‘ë™
  - âœ… API ë°ì´í„° ë Œë”ë§
  - âœ… ë¡œë”©/ì—ëŸ¬/ë¹ˆ ìƒíƒœ UI
  - âœ… Toast ì•Œë¦¼ ì‘ë™

integration:
  - âœ… Backend â†’ Frontend ë°ì´í„° íë¦„
  - âœ… WebSocket ì—°ê²° (ì¤€ë¹„)
  - âœ… CI/CD íŒŒì´í”„ë¼ì¸ ì‘ë™
```

**Week 2 ê²½ë¡œ ì„ íƒ**:
```
IF all_checkboxes == TRUE AND velocity >= 1.2x:
  â†’ Optimistic Path (ì¶”ê°€ ê¸°ëŠ¥ ê°€ëŠ¥)
ELSIF velocity >= 0.8x:
  â†’ Realistic Path (ê³„íšëŒ€ë¡œ)
ELSE:
  â†’ Pessimistic Path (Scope ì¶•ì†Œ)
```

---

**ìƒì„±ì¼**: 2025-11-28
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: Week 1 Day 5 (ì²´í¬í¬ì¸íŠ¸ í›„)
