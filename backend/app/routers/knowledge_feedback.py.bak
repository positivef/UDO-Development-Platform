"""
Knowledge Feedback Router - Track knowledge reuse quality

Week 6 Day 4: Knowledge Reuse Accuracy Tracking

Endpoints:
- POST /api/knowledge/feedback - Submit feedback
- GET /api/knowledge/metrics - Get accuracy metrics
- GET /api/knowledge/documents/{doc_id}/score - Get document usefulness score

Benchmarking:
- Notion AI: Explicit üëç/üëé feedback
- Linear: Confidence-based accuracy tracking
- GitHub Copilot: Acceptance rate metrics
"""

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime, timezone
from uuid import UUID, uuid4
from sqlalchemy.orm import Session

from backend.app.db.database import get_db
from backend.app.services.knowledge_feedback_service import KnowledgeFeedbackService

router = APIRouter(prefix="/api/knowledge", tags=["knowledge-feedback"])

# ============================================================================
# Pydantic Models
# ============================================================================

class FeedbackCreate(BaseModel):
    """
    Feedback submission request

    Benchmarking:
    - Notion AI: is_helpful (boolean)
    - Linear: reason (optional text)
    - Copilot: implicit_accept (tab/esc)
    """
    document_id: str = Field(..., description="Obsidian document ID or filename")
    search_query: str = Field(..., description="User's original search query")
    is_helpful: bool = Field(..., description="Explicit feedback: helpful or not")
    reason: Optional[str] = Field(None, description="Optional reason for negative feedback")
    session_id: Optional[str] = Field(None, description="Session identifier for tracking")
    implicit_accept: Optional[bool] = Field(None, description="Implicit signal (copy/dismiss)")

class FeedbackResponse(BaseModel):
    """Feedback submission response"""
    feedback_id: str
    message: str
    timestamp: datetime

class DocumentScore(BaseModel):
    """
    Document usefulness score

    Calculation:
    - Explicit positive: +1.0
    - Implicit positive: +0.5
    - Explicit negative: -1.0
    - Implicit negative: -0.3
    """
    document_id: str
    usefulness_score: float = Field(..., description="Score: -5.0 to +5.0")
    total_searches: int
    helpful_count: int
    unhelpful_count: int
    acceptance_rate: float = Field(..., description="Percentage: 0-100")
    last_updated: datetime

class KnowledgeMetrics(BaseModel):
    """
    Overall knowledge reuse metrics

    Benchmarking:
    - Linear: Accuracy target 60%+
    - Copilot: Acceptance target 26-40%
    - Notion: False positive <10%
    """
    search_accuracy: float = Field(..., description="Percentage of helpful searches")
    acceptance_rate: float = Field(..., description="Percentage of accepted solutions")
    false_positive_rate: float = Field(..., description="Percentage of unhelpful searches")
    total_searches: int
    total_feedback_count: int
    avg_resolution_time_minutes: Optional[float] = None
    top_documents: List[DocumentScore] = Field(default_factory=list, description="Top 10 useful documents")
    low_quality_documents: List[str] = Field(default_factory=list, description="Documents needing improvement")
    period_start: datetime
    period_end: datetime

# ============================================================================
# API Endpoints (Week 7-8: PostgreSQL Integration)
# ============================================================================

@router.get("/health")
async def health_check():
    """Simple health check endpoint to verify router is working"""
    return {"status": "ok", "router": "knowledge-feedback"}

@router.post("/feedback", response_model=FeedbackResponse, status_code=201)
async def submit_feedback(
    feedback: FeedbackCreate,
    db: Session = Depends(get_db)
):
    """
    Submit knowledge reuse feedback

    Flow:
    1. Store feedback (PostgreSQL)
    2. Update document usefulness score
    3. Calculate metrics
    4. Return confirmation

    Benchmarking:
    - Notion AI: Simple üëç/üëé submission
    - Linear: Feedback with confidence tracking
    """
    service = KnowledgeFeedbackService(db)

    # Create feedback entry
    feedback_entry = service.create_feedback(
        document_id=feedback.document_id,
        search_query=feedback.search_query,
        is_helpful=feedback.is_helpful,
        reason=feedback.reason,
        session_id=feedback.session_id,
        implicit_accept=feedback.implicit_accept
    )

    return FeedbackResponse(
        feedback_id=str(feedback_entry.id),
        message="Feedback received. Thank you for helping improve knowledge quality!",
        timestamp=feedback_entry.created_at,
    )

@router.get("/metrics", response_model=KnowledgeMetrics)
async def get_knowledge_metrics(
    days: int = 7,
    db: Session = Depends(get_db)
):
    """
    Get knowledge reuse accuracy metrics

    Metrics:
    1. Search Accuracy: % of helpful searches (Target: 70%+)
    2. Acceptance Rate: % of accepted solutions (Target: 40%+)
    3. False Positive Rate: % of unhelpful searches (Target: <15%)

    Benchmarking:
    - Linear: 60%+ accuracy
    - GitHub Copilot: 26-40% acceptance
    - Notion AI: <10% false positive
    """
    service = KnowledgeFeedbackService(db)
    metrics = service.get_knowledge_metrics(days=days)

    return KnowledgeMetrics(**metrics)

@router.get("/documents/{document_id}/score", response_model=DocumentScore)
async def get_document_score(
    document_id: str,
    db: Session = Depends(get_db)
):
    """
    Get document usefulness score

    Score calculation:
    - Explicit positive (+1.0) + Implicit positive (+0.5)
    - Explicit negative (-1.0) + Implicit negative (-0.3)
    - Final: sum / total_searches

    Benchmarking:
    - Obsidian: Backlinks count
    - Notion AI: CTR + helpful rate
    """
    service = KnowledgeFeedbackService(db)
    doc_score = service.get_document_score(document_id)

    if not doc_score:
        raise HTTPException(
            status_code=404,
            detail=f"No feedback data for document: {document_id}"
        )

    return DocumentScore(
        document_id=doc_score.document_id,
        usefulness_score=doc_score.usefulness_score,
        total_searches=doc_score.total_searches,
        helpful_count=doc_score.helpful_count,
        unhelpful_count=doc_score.unhelpful_count,
        acceptance_rate=doc_score.acceptance_rate,
        last_updated=doc_score.last_updated
    )

# ============================================================================
# Admin Endpoints (for quality management)
# ============================================================================

@router.get("/improvement-suggestions", response_model=List[dict])
async def get_improvement_suggestions(
    db: Session = Depends(get_db)
):
    """
    Auto-generated improvement suggestions

    Rules:
    1. Usefulness < 2.0 + searches ‚â• 3 ‚Üí "Consider rewriting or archiving"
    2. False positive rate > 20% ‚Üí "Review search keywords"
    3. No feedback for 30+ days ‚Üí "Document may be outdated"

    Benchmarking:
    - Linear: Weekly accuracy reports
    - GitHub Copilot: Model fine-tuning based on telemetry
    """
    service = KnowledgeFeedbackService(db)
    return service.get_improvement_suggestions()

@router.delete("/feedback/{feedback_id}", status_code=204)
async def delete_feedback(
    feedback_id: str,
    db: Session = Depends(get_db)
):
    """Delete feedback (admin only - for spam/test data removal)"""
    service = KnowledgeFeedbackService(db)
    deleted = service.delete_feedback(feedback_id)

    if not deleted:
        raise HTTPException(status_code=404, detail="Feedback not found")

    return None

# ============================================================================
# Export
# ============================================================================

__all__ = ["router"]
