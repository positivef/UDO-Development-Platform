#!/usr/bin/env python
"""
Obsidian Auto-Sync v3.0 - AI-Enhanced Development Log Generator

ìë™ìœ¼ë¡œ Git commit ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ Obsidian ê°œë°œì¼ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

Features (v3.0):
- 14ê°œ Frontmatter í•„ë“œ (ê¸°ë³¸4 + í”Œë˜ê·¸7 + AIì»¨í…ìŠ¤íŠ¸3 + ìë™ìˆ˜ì§‘2 + schema1)
- 9ê°œ Daily ì„¹ì…˜ (ì¡°ê±´ë¶€ ë Œë”ë§)
- 4ê°œ Weekly ì„¹ì…˜ (ì£¼ê°„ ì§‘ê³„)
- í”Œë˜ê·¸ ìë™ ê°ì§€ (Git diff ë¶„ì„)
- í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë¦¬ê±° (Git Hook + session_state.json)
- Schema ë²„ì „ ê´€ë¦¬

Features (v2.0):
- íŠ¸ë¦¬ê±° ì¡°ê±´ ìë™ ê°ì§€ (3+ íŒŒì¼, feat:/fix: ë©”ì‹œì§€)
- AI ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„± (ë°°ìš´ ì , ì‹œí–‰ì°©ì˜¤, ë‹¤ìŒ ë‹¨ê³„)
- ì‹œê°„ëŒ€ë³„ ì‘ì—… ë‚´ì—­ ì¶”ë¡ 
- YAML frontmatter ìë™ ìƒì„±

Usage:
  python scripts/obsidian_auto_sync.py --commit-hash <hash>
  python scripts/obsidian_auto_sync.py --commit-hash HEAD
  python scripts/obsidian_auto_sync.py --commit-hash HEAD --version 3

Requirements:
- Git repository
- Obsidian vault configured in environment or default location

Author: System Automation Team
Date: 2025-12-29
Version: 3.0.0
"""

import argparse
import json
import os
import re
import subprocess
import sys
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any


# =============================================================================
# v3.0: Flag Detection System
# =============================================================================


class FlagDetector:
    """Git diffì™€ ì»¤ë°‹ ì •ë³´ì—ì„œ í”Œë˜ê·¸ ìë™ ê°ì§€"""

    def __init__(self, diff: str, commit_info: Dict):
        self.diff = diff
        self.commit_info = commit_info
        self.message = commit_info.get("message", "").lower()
        self.files = commit_info.get("files_changed", [])

    def detect_all(self) -> Dict[str, bool]:
        """ëª¨ë“  í”Œë˜ê·¸ ê°ì§€"""
        return {
            "has_til": self.detect_til(),
            "has_solution": self.detect_solution(),
            "has_pattern": self.detect_pattern(),
            "has_uncertainty": self.detect_uncertainty(),
            "has_rollback": self.detect_rollback(),
            "has_debt": self.detect_debt(),
            "has_decision": self.detect_decision(),
        }

    def detect_til(self) -> bool:
        """ë°°ìš´ ì  ê°ì§€: ìƒˆë¡œìš´ íŒ¨í„´, í…ŒìŠ¤íŠ¸ ì¶”ê°€, ë¬¸ì„œí™”"""
        patterns = [
            r"def test_",  # ìƒˆ í…ŒìŠ¤íŠ¸ ì¶”ê°€
            r"# TIL:",  # ëª…ì‹œì  TIL ì£¼ì„
            r"learned|í•™ìŠµ|ë°°ì›€",  # í‚¤ì›Œë“œ
            r"\.md$.*tutorial",  # íŠœí† ë¦¬ì–¼ ë¬¸ì„œ
            r"refactor",  # ë¦¬íŒ©í† ë§ (í•™ìŠµ í¬í•¨)
        ]
        # íŒŒì¼ ê¸°ë°˜ ê°ì§€
        if any("test" in f.lower() for f in self.files):
            return True
        # diff ê¸°ë°˜ ê°ì§€
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_solution(self) -> bool:
        """í•´ê²°ì±… ê°ì§€: ë²„ê·¸ ìˆ˜ì •, ë¬¸ì œ í•´ê²°"""
        patterns = [
            r"fix:|bug:|resolve:",  # ì»¤ë°‹ ë©”ì‹œì§€ íŒ¨í„´
            r"# Solution:",  # ëª…ì‹œì  ì£¼ì„
            r"í•´ê²°|ìˆ˜ì •|ê³ ì¹¨",  # í•œê¸€ í‚¤ì›Œë“œ
            r"fixed|resolved",  # ì˜ì–´ í‚¤ì›Œë“œ
        ]
        if any(p in self.message for p in ["fix", "bug", "resolve", "í•´ê²°"]):
            return True
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_pattern(self) -> bool:
        """íŒ¨í„´ ê°ì§€: ë””ìì¸ íŒ¨í„´, ì•„í‚¤í…ì²˜ íŒ¨í„´"""
        patterns = [
            r"# Pattern:",  # ëª…ì‹œì  ì£¼ì„
            r"íŒ¨í„´|pattern",  # í‚¤ì›Œë“œ
            r"singleton|factory|observer|strategy",  # ë””ìì¸ íŒ¨í„´
            r"decorator|adapter|facade",  # ë””ìì¸ íŒ¨í„´
        ]
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_uncertainty(self) -> bool:
        """ë¶ˆí™•ì‹¤ì„± ê°ì§€: ë¯¸í™•ì • ì‚¬í•­, ë¦¬ìŠ¤í¬"""
        patterns = [
            r"# TODO:",  # TODOëŠ” ë¶ˆí™•ì‹¤ì„±
            r"# FIXME:",  # FIXMEë„ ë¶ˆí™•ì‹¤ì„±
            r"ë¶ˆí™•ì‹¤|uncertain",  # í‚¤ì›Œë“œ
            r"\?\?\?|XXX",  # ì˜ë¬¸ ë§ˆì»¤
            r"risk|ë¦¬ìŠ¤í¬|ìœ„í—˜",  # ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ
            r"maybe|perhaps|ì•„ë§ˆ",  # ë¶ˆí™•ì‹¤ í‘œí˜„
        ]
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_rollback(self) -> bool:
        """ë¡¤ë°± ê³„íš ê°ì§€: ë¡¤ë°± ì „ëµ, ë³µêµ¬ ê³„íš"""
        patterns = [
            r"# Rollback:",  # ëª…ì‹œì  ì£¼ì„
            r"rollback|ë¡¤ë°±",  # í‚¤ì›Œë“œ
            r"revert|ë³µêµ¬|ë˜ëŒë¦¬",  # ë³µêµ¬ í‚¤ì›Œë“œ
            r"backup|ë°±ì—…",  # ë°±ì—… í‚¤ì›Œë“œ
            r"feature.?flag",  # í”¼ì²˜ í”Œë˜ê·¸
        ]
        # ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡¤ë°± ê³„íš í•„ìš”
        if any("migration" in f.lower() for f in self.files):
            return True
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_debt(self) -> bool:
        """ê¸°ìˆ ë¶€ì±„ ê°ì§€: TODO, FIXME, ì„ì‹œ í•´ê²°ì±…"""
        patterns = [
            r"#\s*TODO:",  # TODO ì£¼ì„
            r"#\s*FIXME:",  # FIXME ì£¼ì„
            r"#\s*HACK:",  # HACK ì£¼ì„
            r"#\s*XXX:",  # XXX ì£¼ì„
            r"temporary|ì„ì‹œ",  # ì„ì‹œ í‚¤ì›Œë“œ
            r"workaround",  # ìš°íšŒ í•´ê²°ì±…
            r"@pytest\.mark\.skip",  # ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸
            r"# type:\s*ignore",  # íƒ€ì… ë¬´ì‹œ
        ]
        return any(re.search(p, self.diff, re.I) for p in patterns)

    def detect_decision(self) -> bool:
        """ì˜ì‚¬ê²°ì • ê°ì§€: ì•„í‚¤í…ì²˜ ë³€ê²½, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€"""
        patterns = [
            r"# Decision:",  # ëª…ì‹œì  ì£¼ì„
            r"# Why:",  # ì´ìœ  ì„¤ëª…
            r"ì„ íƒ|ê²°ì •|ì±„íƒ",  # í•œê¸€ í‚¤ì›Œë“œ
            r"chose|decided|selected",  # ì˜ì–´ í‚¤ì›Œë“œ
        ]
        # requirements.txt ë˜ëŠ” package.json ë³€ê²½
        if any(f in ["requirements.txt", "package.json", "pyproject.toml"] for f in self.files):
            return True
        # ìƒˆ ì˜ì¡´ì„± ì¶”ê°€ ê°ì§€
        if re.search(r"requirements\.txt.*\+", self.diff):
            return True
        return any(re.search(p, self.diff, re.I) for p in patterns)


# =============================================================================
# v3.0: AI Context Generator
# =============================================================================


class AIContextGenerator:
    """AI ì»¨í…ìŠ¤íŠ¸ ìë™ ìƒì„±"""

    def __init__(self, commit_info: Dict, diff: str):
        self.commit_info = commit_info
        self.diff = diff
        self.message = commit_info.get("message", "")
        self.files = commit_info.get("files_changed", [])

    def generate(self) -> Dict[str, Any]:
        """AI ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        return {
            "summary": self._generate_summary(),
            "next_actions": self._extract_next_actions(),
            "warnings": self._extract_warnings(),
        }

    def _generate_summary(self) -> str:
        """1-2ë¬¸ì¥ ìš”ì•½ ìƒì„±"""
        # ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„ ì‚¬ìš©
        first_line = self.message.split("\n")[0]

        # íƒ€ì… ì¶”ì¶œ
        work_type = "ì‘ì—…"
        if "feat" in first_line.lower():
            work_type = "ê¸°ëŠ¥ ì¶”ê°€"
        elif "fix" in first_line.lower():
            work_type = "ë²„ê·¸ ìˆ˜ì •"
        elif "refactor" in first_line.lower():
            work_type = "ë¦¬íŒ©í† ë§"
        elif "docs" in first_line.lower():
            work_type = "ë¬¸ì„œí™”"
        elif "test" in first_line.lower():
            work_type = "í…ŒìŠ¤íŠ¸"

        files_count = len(self.files)
        return f"{work_type}: {files_count}ê°œ íŒŒì¼ ë³€ê²½. {first_line[:50]}"

    def _extract_next_actions(self) -> List[str]:
        """ë‹¤ìŒ ì•¡ì…˜ ì¶”ì¶œ"""
        actions = []

        # TODOì—ì„œ ì¶”ì¶œ
        todos = re.findall(r"#\s*TODO:?\s*(.+)", self.diff)
        for todo in todos[:3]:
            actions.append(f"TODO: {todo.strip()[:50]}")

        # ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜ ì¶”ë¡ 
        if "feat" in self.message.lower():
            actions.append("í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        if "fix" in self.message.lower():
            actions.append("íšŒê·€ í…ŒìŠ¤íŠ¸ í™•ì¸")
        if not actions:
            actions.append("ì½”ë“œ ë¦¬ë·° ìš”ì²­")

        return actions[:5]  # ìµœëŒ€ 5ê°œ

    def _extract_warnings(self) -> List[str]:
        """ê²½ê³ ì‚¬í•­ ì¶”ì¶œ"""
        warnings = []

        # FIXMEì—ì„œ ì¶”ì¶œ
        fixmes = re.findall(r"#\s*FIXME:?\s*(.+)", self.diff)
        for fixme in fixmes[:3]:
            warnings.append(f"FIXME: {fixme.strip()[:50]}")

        # ìœ„í—˜ íŒ¨í„´ ê°ì§€
        if re.search(r"rm\s+-rf|DROP\s+TABLE|DELETE\s+FROM", self.diff, re.I):
            warnings.append("ìœ„í—˜í•œ ëª…ë ¹ì–´ ê°ì§€ - ì£¼ì˜ í•„ìš”")

        if re.search(r"password|secret|api.?key", self.diff, re.I):
            warnings.append("ë¯¼ê° ì •ë³´ ë…¸ì¶œ ê°€ëŠ¥ì„± - í™•ì¸ í•„ìš”")

        if len(self.files) > 20:
            warnings.append(f"ëŒ€ê·œëª¨ ë³€ê²½ ({len(self.files)}ê°œ íŒŒì¼) - ì‹ ì¤‘í•œ ë¦¬ë·° í•„ìš”")

        return warnings[:5]  # ìµœëŒ€ 5ê°œ


# =============================================================================
# v3.0: Section Generator (9 Daily Sections + Conditional Rendering)
# =============================================================================


class SectionGenerator:
    """9ê°œ Daily ì„¹ì…˜ ìƒì„±ê¸° (ì¡°ê±´ë¶€ ë Œë”ë§ ì§€ì›)"""

    def __init__(self, commit_info: Dict, flags: Dict[str, bool], session_state: Dict, diff: str, repo_root: Path):
        self.commit_info = commit_info
        self.flags = flags
        self.session_state = session_state
        self.diff = diff
        self.repo_root = repo_root
        self.message = commit_info.get("message", "")
        self.files = commit_info.get("files_changed", [])

    def generate_all_sections(self) -> str:
        """ëª¨ë“  ì„¹ì…˜ ìƒì„± (ì¡°ê±´ë¶€ ë Œë”ë§ ì ìš©)"""
        content = ""

        # 1. Executive Summary (í•­ìƒ)
        content += self._section_executive_summary()

        # 2. Work Timeline (í•­ìƒ)
        content += self._section_work_timeline()

        # 3. TIL (has_til)
        if self.flags.get("has_til"):
            content += self._section_til()

        # 4. Solutions & Patterns (has_solution OR has_pattern)
        if self.flags.get("has_solution") or self.flags.get("has_pattern"):
            content += self._section_solutions_patterns()

        # 5. Uncertainty & Blockers (has_uncertainty)
        if self.flags.get("has_uncertainty"):
            content += self._section_uncertainty()

        # 6. Rollback Plans (has_rollback)
        if self.flags.get("has_rollback"):
            content += self._section_rollback()

        # 7. Related Docs (í•­ìƒ)
        content += self._section_related_docs()

        # 8. Technical Debt Daily (has_debt)
        if self.flags.get("has_debt"):
            content += self._section_tech_debt()

        # 9. Decisions Made (has_decision)
        if self.flags.get("has_decision"):
            content += self._section_decisions()

        return content

    # -------------------------------------------------------------------------
    # Section 1: Executive Summary (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_executive_summary(self) -> str:
        """Executive Summary ì„¹ì…˜"""
        title = self.message.split("\n")[0]
        files_count = len(self.files)

        # ì‘ì—… ìœ í˜• ì¶”ë¡ 
        work_type = "ì‘ì—…"
        if "feat" in title.lower():
            work_type = "ê¸°ëŠ¥ ì¶”ê°€"
        elif "fix" in title.lower():
            work_type = "ë²„ê·¸ ìˆ˜ì •"
        elif "refactor" in title.lower():
            work_type = "ë¦¬íŒ©í† ë§"
        elif "docs" in title.lower():
            work_type = "ë¬¸ì„œí™”"
        elif "test" in title.lower():
            work_type = "í…ŒìŠ¤íŠ¸"

        content = f"\n# {title}\n\n"
        content += "## Executive Summary\n\n"
        content += f"**ì‘ì—… ìœ í˜•**: {work_type}  \n"
        content += f"**ë³€ê²½ íŒŒì¼**: {files_count}ê°œ  \n"

        # ì£¼ìš” ë³€ê²½ ì˜ì—­ (ì¹´í…Œê³ ë¦¬ë³„)
        categories = self._categorize_files()
        if categories:
            areas = [f"{cat} ({count})" for cat, count in categories.items() if count > 0]
            content += f"**ë³€ê²½ ì˜ì—­**: {', '.join(areas[:4])}  \n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 2: Work Timeline (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_work_timeline(self) -> str:
        """Work Timeline ì„¹ì…˜ - session_state.jsonì—ì„œ ì¶”ì¶œ"""
        content = "## Work Timeline\n\n"

        checkpoints = self.session_state.get("checkpoints", [])
        if checkpoints:
            content += "| ì‹œê°„ | ì‘ì—… ë‚´ìš© |\n"
            content += "|------|----------|\n"

            for cp in checkpoints[-10:]:  # ìµœê·¼ 10ê°œë§Œ
                time_str = cp.get("time", "")[:16]  # YYYY-MM-DD HH:MM
                notes = cp.get("notes", "ì²´í¬í¬ì¸íŠ¸")[:50]
                content += f"| {time_str} | {notes} |\n"

            content += "\n"
        else:
            # session_stateê°€ ì—†ìœ¼ë©´ ì»¤ë°‹ ì •ë³´ ê¸°ë°˜
            commit_time = self.commit_info.get("time", "")[:16]
            content += f"- **{commit_time}**: {self.message.split(chr(10))[0][:50]}\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 3: TIL - Today I Learned (has_til)
    # -------------------------------------------------------------------------
    def _section_til(self) -> str:
        """TIL ì„¹ì…˜ - ë°°ìš´ ì  ìë™ ì¶”ì¶œ"""
        content = "## Today I Learned (TIL)\n\n"

        learnings = []

        # í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê°ì§€
        if any("test" in f.lower() for f in self.files):
            learnings.append("í…ŒìŠ¤íŠ¸ ìš°ì„  ê°œë°œ (TDD) íŒ¨í„´ ì ìš©")

        # ë¦¬íŒ©í† ë§ ê°ì§€
        if "refactor" in self.message.lower():
            learnings.append("ì½”ë“œ êµ¬ì¡° ê°œì„ ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ")

        # ìƒˆ íŒ¨í„´ ê°ì§€
        patterns = re.findall(r"(singleton|factory|observer|strategy|decorator|adapter|facade)", self.diff, re.I)
        if patterns:
            learnings.append(f"ë””ìì¸ íŒ¨í„´ ì ìš©: {', '.join(set(patterns))}")

        # ì„±ëŠ¥ ìµœì í™”
        if any(kw in self.diff.lower() for kw in ["cache", "optimize", "performance"]):
            learnings.append("ì„±ëŠ¥ ìµœì í™” ê¸°ë²• í•™ìŠµ")

        # ë³´ì•ˆ ê´€ë ¨
        if any(kw in self.diff.lower() for kw in ["auth", "security", "token"]):
            learnings.append("ë³´ì•ˆ ê°•í™” ê¸°ë²• ì ìš©")

        # ëª…ì‹œì  TIL ì£¼ì„ ì¶”ì¶œ
        til_comments = re.findall(r"#\s*TIL:?\s*(.+)", self.diff)
        learnings.extend([t.strip()[:80] for t in til_comments[:3]])

        if learnings:
            for item in learnings[:5]:
                content += f"- {item}\n"
        else:
            content += "- (ìë™ ê°ì§€ëœ í•™ìŠµ í•­ëª© ì—†ìŒ - ìˆ˜ë™ ì‘ì„± ê¶Œì¥)\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 4: Solutions & Patterns (has_solution OR has_pattern)
    # -------------------------------------------------------------------------
    def _section_solutions_patterns(self) -> str:
        """Solutions & Patterns ì„¹ì…˜"""
        content = "## Solutions & Patterns\n\n"

        # í•´ê²°ì±… ì¶”ì¶œ
        if self.flags.get("has_solution"):
            content += "### Solutions\n\n"
            solutions = re.findall(r"#\s*Solution:?\s*(.+)", self.diff)
            if solutions:
                for sol in solutions[:5]:
                    content += f"- {sol.strip()[:80]}\n"
            elif "fix" in self.message.lower():
                content += f"- {self.message.split(chr(10))[0]}\n"
            content += "\n"

        # íŒ¨í„´ ì¶”ì¶œ
        if self.flags.get("has_pattern"):
            content += "### Patterns Applied\n\n"
            patterns = re.findall(
                r"(singleton|factory|observer|strategy|decorator|adapter|facade|mixin|proxy)", self.diff, re.I
            )
            pattern_comments = re.findall(r"#\s*Pattern:?\s*(.+)", self.diff)

            if patterns:
                for p in set(patterns):
                    content += f"- **{p.capitalize()}** íŒ¨í„´\n"
            if pattern_comments:
                for pc in pattern_comments[:3]:
                    content += f"- {pc.strip()[:80]}\n"
            content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 5: Uncertainty & Blockers (has_uncertainty)
    # -------------------------------------------------------------------------
    def _section_uncertainty(self) -> str:
        """Uncertainty & Blockers ì„¹ì…˜"""
        content = "## Uncertainty & Blockers\n\n"

        uncertainties = []

        # TODO ì¶”ì¶œ
        todos = re.findall(r"#\s*TODO:?\s*(.+)", self.diff)
        uncertainties.extend([f"TODO: {t.strip()[:60]}" for t in todos[:5]])

        # FIXME ì¶”ì¶œ
        fixmes = re.findall(r"#\s*FIXME:?\s*(.+)", self.diff)
        uncertainties.extend([f"FIXME: {f.strip()[:60]}" for f in fixmes[:3]])

        # ë¶ˆí™•ì‹¤ì„± í‚¤ì›Œë“œ
        if re.search(r"maybe|perhaps|ì•„ë§ˆ|possibly", self.diff, re.I):
            uncertainties.append("ë¶ˆí™•ì‹¤í•œ êµ¬í˜„ ê°ì§€ - ê²€í†  í•„ìš”")

        # ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ
        risks = re.findall(r"#\s*RISK:?\s*(.+)", self.diff)
        uncertainties.extend([f"RISK: {r.strip()[:60]}" for r in risks[:3]])

        if uncertainties:
            for item in uncertainties[:8]:
                content += f"- {item}\n"
        else:
            content += "- (ë¶ˆí™•ì‹¤ì„± í•­ëª© ê°ì§€ë¨ - ìƒì„¸ ë‚´ìš© ìˆ˜ë™ ì‘ì„± ê¶Œì¥)\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 6: Rollback Plans (has_rollback)
    # -------------------------------------------------------------------------
    def _section_rollback(self) -> str:
        """Rollback Plans ì„¹ì…˜"""
        content = "## Rollback Plans\n\n"

        rollbacks = []

        # ëª…ì‹œì  ë¡¤ë°± ì£¼ì„
        rollback_comments = re.findall(r"#\s*Rollback:?\s*(.+)", self.diff)
        rollbacks.extend([r.strip()[:80] for r in rollback_comments[:3]])

        # ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ê°ì§€
        migrations = [f for f in self.files if "migration" in f.lower()]
        if migrations:
            rollbacks.append(f"DB ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±: `python manage.py migrate --reverse` ({len(migrations)}ê°œ íŒŒì¼)")

        # Feature flag ê°ì§€
        if re.search(r"feature.?flag", self.diff, re.I):
            rollbacks.append("Feature Flag ë¹„í™œì„±í™”ë¡œ ì¦‰ì‹œ ë¡¤ë°± ê°€ëŠ¥")

        # ë°±ì—… ì „ëµ
        if re.search(r"backup|ë°±ì—…", self.diff, re.I):
            rollbacks.append("ë°±ì—… ë³µì› ì „ëµ ì¤€ë¹„ë¨")

        # ê¸°ë³¸ ë¡¤ë°± ê°€ì´ë“œ
        if not rollbacks:
            commit_hash = self.commit_info.get("hash", "HEAD")[:7]
            rollbacks = [
                f"Git Revert: `git revert {commit_hash}`",
                "ì¦‰ì‹œ ë¡¤ë°± ê°€ëŠ¥ (1ë¶„ ì´ë‚´)",
            ]

        content += "| ì „ëµ | ì„¤ëª… |\n"
        content += "|------|------|\n"
        for idx, item in enumerate(rollbacks[:5], 1):
            content += f"| Tier {idx} | {item} |\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 7: Related Docs (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_related_docs(self) -> str:
        """Related Docs ì„¹ì…˜ - ê´€ë ¨ ë¬¸ì„œ ìë™ ë§í¬"""
        content = "## Related Docs\n\n"

        # ë³€ê²½ëœ docs íŒŒì¼
        doc_files = [f for f in self.files if f.startswith("docs/") or f.endswith(".md")]
        if doc_files:
            content += "### ë³€ê²½ëœ ë¬¸ì„œ\n"
            for doc in doc_files[:5]:
                content += f"- [[{Path(doc).stem}]] (`{doc}`)\n"
            content += "\n"

        # ê´€ë ¨ ë§í¬ ì¶”ë¡ 
        content += "### ê´€ë ¨ ë§í¬\n"

        # CLAUDE.md ì°¸ì¡°
        if any("claude" in f.lower() for f in self.files):
            content += "- [[CLAUDE]] (í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸)\n"

        # í…ŒìŠ¤íŠ¸ ê´€ë ¨
        if any("test" in f.lower() for f in self.files):
            content += "- [[Testing Guide]]\n"

        # Backend ê´€ë ¨
        if any("backend" in f.lower() for f in self.files):
            content += "- [[Backend Architecture]]\n"

        # Frontend ê´€ë ¨
        if any("web-dashboard" in f.lower() or "frontend" in f.lower() for f in self.files):
            content += "- [[Frontend Guide]]\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 8: Technical Debt Daily (has_debt)
    # -------------------------------------------------------------------------
    def _section_tech_debt(self) -> str:
        """Technical Debt Daily ì„¹ì…˜"""
        content = "## Technical Debt (Daily)\n\n"

        debts = []

        # TODO ì¶”ì¶œ
        todos = re.findall(r"#\s*TODO:?\s*(.+)", self.diff)
        debts.extend([{"type": "TODO", "desc": t.strip()[:60]} for t in todos[:5]])

        # FIXME ì¶”ì¶œ
        fixmes = re.findall(r"#\s*FIXME:?\s*(.+)", self.diff)
        debts.extend([{"type": "FIXME", "desc": f.strip()[:60]} for f in fixmes[:3]])

        # HACK ì¶”ì¶œ
        hacks = re.findall(r"#\s*HACK:?\s*(.+)", self.diff)
        debts.extend([{"type": "HACK", "desc": h.strip()[:60]} for h in hacks[:2]])

        # ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸
        skips = re.findall(r"@pytest\.mark\.skip\(reason=[\"'](.+?)[\"']\)", self.diff)
        debts.extend([{"type": "SKIP", "desc": s[:60]} for s in skips[:2]])

        # íƒ€ì… ë¬´ì‹œ
        ignores = len(re.findall(r"#\s*type:\s*ignore", self.diff))
        if ignores > 0:
            debts.append({"type": "TYPE", "desc": f"type: ignore ì£¼ì„ {ignores}ê°œ"})

        if debts:
            content += "| ìœ í˜• | ì„¤ëª… | ìš°ì„ ìˆœìœ„ |\n"
            content += "|------|------|----------|\n"
            for debt in debts[:8]:
                priority = "P1" if debt["type"] == "FIXME" else "P2"
                content += f"| {debt['type']} | {debt['desc']} | {priority} |\n"
        else:
            content += "- (ê¸°ìˆ ë¶€ì±„ í•­ëª© ê°ì§€ë¨ - ìƒì„¸ ë¶„ì„ ê¶Œì¥)\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 9: Decisions Made (has_decision)
    # -------------------------------------------------------------------------
    def _section_decisions(self) -> str:
        """Decisions Made ì„¹ì…˜"""
        content = "## Decisions Made (Daily)\n\n"

        decisions = []

        # ëª…ì‹œì  Decision ì£¼ì„
        decision_comments = re.findall(r"#\s*Decision:?\s*(.+)", self.diff)
        decisions.extend([d.strip()[:80] for d in decision_comments[:5]])

        # Why ì£¼ì„
        why_comments = re.findall(r"#\s*Why:?\s*(.+)", self.diff)
        decisions.extend([f"ì´ìœ : {w.strip()[:70]}" for w in why_comments[:3]])

        # ì˜ì¡´ì„± ë³€ê²½ ê°ì§€
        if "requirements.txt" in self.files or "package.json" in self.files:
            # ì¶”ê°€ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì¶œ
            added_deps = re.findall(r"\+([a-zA-Z0-9_-]+)==", self.diff)
            if added_deps:
                decisions.append(f"ì˜ì¡´ì„± ì¶”ê°€: {', '.join(added_deps[:3])}")

        # pyproject.toml ë³€ê²½
        if "pyproject.toml" in self.files:
            decisions.append("Python í”„ë¡œì íŠ¸ ì„¤ì • ë³€ê²½")

        if decisions:
            for idx, decision in enumerate(decisions[:6], 1):
                content += f"{idx}. {decision}\n"
        else:
            content += "- (ì˜ì‚¬ê²°ì • ê°ì§€ë¨ - ìƒì„¸ ë‚´ìš© ìˆ˜ë™ ì‘ì„± ê¶Œì¥)\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Helper Methods
    # -------------------------------------------------------------------------
    def _categorize_files(self) -> Dict[str, int]:
        """íŒŒì¼ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            "Backend": 0,
            "Frontend": 0,
            "Tests": 0,
            "Docs": 0,
            "Scripts": 0,
            "Config": 0,
        }

        for f in self.files:
            if f.startswith("backend/"):
                categories["Backend"] += 1
            elif f.startswith("web-dashboard/") or f.startswith("frontend/"):
                categories["Frontend"] += 1
            elif "test" in f.lower():
                categories["Tests"] += 1
            elif f.startswith("docs/") or f.endswith(".md"):
                categories["Docs"] += 1
            elif f.startswith("scripts/"):
                categories["Scripts"] += 1
            elif any(f.endswith(ext) for ext in [".yaml", ".yml", ".json", ".toml", ".env"]):
                categories["Config"] += 1

        return {k: v for k, v in categories.items() if v > 0}


# =============================================================================
# v3.0: Weekly Summary Generator (4 Weekly Sections with Dataview)
# =============================================================================


class WeeklySummaryGenerator:
    """4ê°œ Weekly ì„¹ì…˜ ìƒì„±ê¸° (Dataview ì¿¼ë¦¬ í™œìš©)"""

    def __init__(self, week_start: datetime, week_end: datetime, project: str = "UDO-Development-Platform"):
        self.week_start = week_start
        self.week_end = week_end
        self.project = project
        self.week_str = week_start.strftime("%Y-W%W")

    def generate_weekly_note(self) -> str:
        """ì£¼ê°„ ìš”ì•½ ë…¸íŠ¸ ìƒì„±"""
        content = self._generate_frontmatter()
        content += f"\n# Weekly Summary: {self.week_str}\n\n"
        content += f"**ê¸°ê°„**: {self.week_start.strftime('%Y-%m-%d')} ~ {self.week_end.strftime('%Y-%m-%d')}\n\n"

        # 4ê°œ Weekly ì„¹ì…˜
        content += self._section_tech_debt_summary()
        content += self._section_decision_audit()
        content += self._section_performance_trends()
        content += self._section_next_week_actions()

        # í‘¸í„°
        content += "\n---\n"
        content += f"**ìë™ ìƒì„±**: Obsidian Auto-Sync v3.0 Weekly  \n"
        content += f"**ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M')}  \n"

        return content

    def _generate_frontmatter(self) -> str:
        """Weekly Frontmatter ìƒì„±"""
        frontmatter = f"""---
title: "{self.week_str} Weekly Summary"
created: {datetime.now().strftime('%Y-%m-%d')}
type: weekly
status: completed
week_start: {self.week_start.strftime('%Y-%m-%d')}
week_end: {self.week_end.strftime('%Y-%m-%d')}
project: {self.project}
schema_version: "1.0"
tags: [weekly, summary, review]
---
"""
        return frontmatter

    # -------------------------------------------------------------------------
    # Section 1: Tech Debt Summary (ì£¼ê°„ ê¸°ìˆ ë¶€ì±„ ì§‘ê³„)
    # -------------------------------------------------------------------------
    def _section_tech_debt_summary(self) -> str:
        """Tech Debt Summary - Dataview ì¿¼ë¦¬ë¡œ ì§‘ê³„"""
        content = "## Tech Debt Summary\n\n"
        content += "> ì´ë²ˆ ì£¼ ë°œìƒí•œ ê¸°ìˆ ë¶€ì±„ë¥¼ Dataviewë¡œ ìë™ ì§‘ê³„í•©ë‹ˆë‹¤.\n\n"

        # Dataview ì¿¼ë¦¬ (has_debt=trueì¸ Daily ë…¸íŠ¸ ì§‘ê³„)
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  length(filter(file.outlinks, (l) => contains(string(l), "TODO"))) as "TODO",\n'
        content += '  length(filter(file.outlinks, (l) => contains(string(l), "FIXME"))) as "FIXME"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_debt = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ìˆ˜ë™ ì²´í¬ë¦¬ìŠ¤íŠ¸
        content += "### ì£¼ê°„ ê¸°ìˆ ë¶€ì±„ ì•¡ì…˜\n\n"
        content += "- [ ] ì´ë²ˆ ì£¼ TODO ì •ë¦¬ (ìš°ì„ ìˆœìœ„ P1 ë¨¼ì €)\n"
        content += "- [ ] FIXME í•­ëª© ë¦¬ë·°\n"
        content += "- [ ] ë‹¤ìŒ ì£¼ ì´ì›” í•­ëª© ê²°ì •\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 2: Decision Audit Summary (ì£¼ê°„ ì˜ì‚¬ê²°ì • ê°ì‚¬)
    # -------------------------------------------------------------------------
    def _section_decision_audit(self) -> str:
        """Decision Audit - ì£¼ê°„ ì˜ì‚¬ê²°ì • ê°ì‚¬"""
        content = "## Decision Audit Summary\n\n"
        content += "> ì´ë²ˆ ì£¼ ë‚´ë¦° ì£¼ìš” ê²°ì •ë“¤ì„ ì¶”ì í•©ë‹ˆë‹¤.\n\n"

        # Dataview ì¿¼ë¦¬ (has_decision=trueì¸ Daily ë…¸íŠ¸)
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  context_summary as "ìš”ì•½"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_decision = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ê²°ì • ê²€í†  ì²´í¬ë¦¬ìŠ¤íŠ¸
        content += "### ê²°ì • ê²€í†  ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"
        content += "| ê²°ì • | ê²°ê³¼ | í›„ì† ì¡°ì¹˜ |\n"
        content += "|------|------|----------|\n"
        content += "| (ìˆ˜ë™ ì…ë ¥) | (ì„±ê³µ/ì‹¤íŒ¨/ì§„í–‰ì¤‘) | (í•„ìš”ì‹œ) |\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 3: Performance Trends (ì„±ëŠ¥ íŠ¸ë Œë“œ)
    # -------------------------------------------------------------------------
    def _section_performance_trends(self) -> str:
        """Performance Trends - ìƒì‚°ì„± ë° ì„±ê³¼ íŠ¸ë Œë“œ"""
        content = "## Performance Trends\n\n"
        content += "> ì´ë²ˆ ì£¼ ê°œë°œ ìƒì‚°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n\n"

        # ì»¤ë°‹ í†µê³„ Dataview
        content += "### ì»¤ë°‹ í†µê³„\n\n"
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  files_changed as "íŒŒì¼ìˆ˜",\n'
        content += '  commits as "ì»¤ë°‹ìˆ˜"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "SORT created ASC\n"
        content += "```\n\n"

        # í•™ìŠµ ì¶”ì 
        content += "### í•™ìŠµ í†µê³„ (TIL)\n\n"
        content += "```dataview\n"
        content += "LIST\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_til = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ì£¼ê°„ ìš”ì•½ ë©”íŠ¸ë¦­
        content += "### ì£¼ê°„ ë©”íŠ¸ë¦­ (ìˆ˜ë™ ì…ë ¥)\n\n"
        content += "| ì§€í‘œ | ì´ë²ˆ ì£¼ | ì§€ë‚œ ì£¼ | ë³€í™” |\n"
        content += "|------|---------|---------|------|\n"
        content += "| ì´ ì»¤ë°‹ ìˆ˜ | - | - | - |\n"
        content += "| ë³€ê²½ íŒŒì¼ ìˆ˜ | - | - | - |\n"
        content += "| TIL í•­ëª© ìˆ˜ | - | - | - |\n"
        content += "| í•´ê²°ëœ ì´ìŠˆ | - | - | - |\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 4: Next Week Actions (ë‹¤ìŒ ì£¼ ê³„íš)
    # -------------------------------------------------------------------------
    def _section_next_week_actions(self) -> str:
        """Next Week Actions - ë‹¤ìŒ ì£¼ ê³„íš"""
        content = "## Next Week Actions\n\n"
        content += "> ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ ì‘ì—…ì„ ì •ì˜í•©ë‹ˆë‹¤.\n\n"

        # ì´ì›” í•­ëª© ìë™ ì¶”ì¶œ (Dataview)
        content += "### ì´ì›” í•­ëª© (ìë™ ì§‘ê³„)\n\n"
        content += "```dataview\n"
        content += "LIST next_actions\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND length(next_actions) > 0\n"
        content += "FLATTEN next_actions\n"
        content += "LIMIT 10\n"
        content += "```\n\n"

        # ì£¼ê°„ ê²½ê³ ì‚¬í•­ ì§‘ê³„
        content += "### ê²½ê³ ì‚¬í•­ (ìë™ ì§‘ê³„)\n\n"
        content += "```dataview\n"
        content += "LIST warnings\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND length(warnings) > 0\n"
        content += "FLATTEN warnings\n"
        content += "LIMIT 5\n"
        content += "```\n\n"

        # ìˆ˜ë™ ê³„íš
        content += "### ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ (ìˆ˜ë™ ì…ë ¥)\n\n"
        content += "| ìš°ì„ ìˆœìœ„ | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ë‹´ë‹¹ |\n"
        content += "|----------|------|----------|------|\n"
        content += "| P0 | (í•„ìˆ˜ ì‘ì—…) | - | - |\n"
        content += "| P1 | (ì¤‘ìš” ì‘ì—…) | - | - |\n"
        content += "| P2 | (ì„ íƒ ì‘ì—…) | - | - |\n"
        content += "\n"

        return content


class ObsidianAutoSync:
    """Obsidian ìë™ ë™ê¸°í™” í´ë˜ìŠ¤"""

    def __init__(self, repo_root: Path, vault_path: Optional[Path] = None):
        self.repo_root = repo_root
        self.vault_path = vault_path or self._get_default_vault_path()
        self.dev_log_dir = self.vault_path / "ê°œë°œì¼ì§€"

    def _get_default_vault_path(self) -> Path:
        """ê¸°ë³¸ Obsidian vault ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¨¼ì € í™•ì¸
        vault_env = os.getenv("OBSIDIAN_VAULT_PATH")
        if vault_env:
            return Path(vault_env)

        # Windows ê¸°ë³¸ ê²½ë¡œ
        default_path = Path.home() / "Documents" / "Obsidian Vault"
        if default_path.exists():
            return default_path

        # Fallback
        return Path.home() / "obsidian-vault"

    def get_commit_info(self, commit_hash: str) -> Dict:
        """ì»¤ë°‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ì»¤ë°‹ ë©”ì‹œì§€
            message = subprocess.check_output(
                ["git", "log", "-1", "--pretty=%B", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # ì»¤ë°‹ ì‹œê°„
            commit_time = subprocess.check_output(
                ["git", "log", "-1", "--pretty=%ai", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # ë³€ê²½ íŒŒì¼ ëª©ë¡
            files_changed = (
                subprocess.check_output(
                    ["git", "diff-tree", "--no-commit-id", "--name-only", "-r", commit_hash],
                    cwd=self.repo_root,
                    encoding="utf-8",
                    errors="replace",
                )
                .strip()
                .split("\n")
            )

            # í†µê³„
            stats = subprocess.check_output(
                ["git", "log", "-1", "--stat", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # diff (ê°„ë‹¨í•œ ë²„ì „)
            diff = subprocess.check_output(
                ["git", "show", "--stat", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            return {
                "hash": commit_hash,
                "message": message,
                "time": commit_time,
                "files_changed": [f for f in files_changed if f],
                "stats": stats,
                "diff": diff,
            }
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] Failed to get commit info: {e}", file=sys.stderr)
            return {}

    def check_trigger_conditions(self, commit_info: Dict) -> Tuple[bool, str]:
        """íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸"""
        files_count = len(commit_info.get("files_changed", []))
        message = commit_info.get("message", "")

        # ì¡°ê±´ 1: 3ê°œ ì´ìƒ íŒŒì¼ ë³€ê²½
        if files_count >= 3:
            return True, f"{files_count} files changed (>=3)"

        # ì¡°ê±´ 2: feat:/fix:/docs: ë“± ì»¤ë°‹ ë©”ì‹œì§€
        trigger_patterns = [r"^feat:", r"^feature:", r"^fix:", r"^bug:", r"^docs:", r"^refactor:", r"^analyze:", r"^analysis:"]

        for pattern in trigger_patterns:
            if re.match(pattern, message, re.IGNORECASE):
                return True, f"Commit message matches: {pattern}"

        return False, f"No trigger (files: {files_count}, message: {message[:30]}...)"

    def generate_ai_insights(self, commit_info: Dict) -> Dict[str, List[str]]:
        """AI ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„± (íŒ¨í„´ ê¸°ë°˜)"""
        files = commit_info.get("files_changed", [])
        message = commit_info.get("message", "")
        diff = commit_info.get("diff", "")

        insights = {"learned": [], "challenges": [], "next_steps": []}

        # ë°°ìš´ ì  ì¶”ì¶œ
        if any("test" in f.lower() for f in files):
            insights["learned"].append("TDD ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìš°ì„  ì‘ì„±")

        if "refactor" in message.lower():
            insights["learned"].append("ì½”ë“œ êµ¬ì¡° ê°œì„ ì„ í†µí•œ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ")

        if any(keyword in message.lower() for keyword in ["performance", "optimize"]):
            insights["learned"].append("ì„±ëŠ¥ ìµœì í™” ê¸°ë²• ì ìš©")

        if any(keyword in message.lower() for keyword in ["security", "auth"]):
            insights["learned"].append("ë³´ì•ˆ ê°•í™” ë°©ë²• í•™ìŠµ")

        if len(files) >= 5:
            insights["learned"].append("ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì ìš© (ë‹¤ìˆ˜ íŒŒì¼ ë™ì‹œ ì‘ì—…)")

        # ì‹œí–‰ì°©ì˜¤ ê°ì§€
        if "fix" in message.lower():
            insights["challenges"].append(f"ë¬¸ì œ ë°œê²¬: {message.split(':')[0]} â†’ í•´ê²° ì™„ë£Œ")

        if len(files) > 10:
            insights["challenges"].append("ëŒ€ê·œëª¨ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ë³µì¡ë„ ê´€ë¦¬")

        # ë‹¤ìŒ ë‹¨ê³„ (TODO ì£¼ì„ ì¶”ì¶œ)
        todo_pattern = r"#\s*TODO:?\s*(.+)"
        todos_found = re.findall(todo_pattern, diff)
        if todos_found:
            insights["next_steps"].extend([f"TODO: {todo}" for todo in todos_found[:3]])

        # ê¸°ë³¸ ë‹¤ìŒ ë‹¨ê³„
        if "feat" in message.lower():
            insights["next_steps"].append("í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")

        if "fix" in message.lower():
            insights["next_steps"].append("íšŒê·€ í…ŒìŠ¤íŠ¸ë¡œ ì¬ë°œ ë°©ì§€ í™•ì¸")

        return insights

    def categorize_work_type(self, commit_info: Dict) -> str:
        """ì‘ì—… ìœ í˜• ë¶„ë¥˜"""
        message = commit_info.get("message", "").lower()

        if any(kw in message for kw in ["feat", "feature", "add"]):
            return "feature"
        elif any(kw in message for kw in ["fix", "bug", "resolve"]):
            return "bugfix"
        elif "refactor" in message:
            return "refactor"
        elif any(kw in message for kw in ["docs", "document"]):
            return "documentation"
        elif "test" in message:
            return "testing"
        else:
            return "maintenance"

    def generate_frontmatter(self, commit_info: Dict, work_type: str) -> str:
        """YAML frontmatter ìƒì„±"""
        commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
        today = commit_time.strftime("%Y-%m-%d")
        time_str = commit_time.strftime("%H:%M")

        # íŒŒì¼ ë¶„ë¥˜
        files = commit_info.get("files_changed", [])
        tags = ["commit"]

        if any("test" in f.lower() for f in files):
            tags.append("testing")
        if any("docs" in f.lower() for f in files):
            tags.append("documentation")
        if work_type not in tags:
            tags.append(work_type)

        # Topic ìƒì„± (ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„ì—ì„œ)
        topic = commit_info.get("message", "").split("\n")[0]
        if ":" in topic:
            topic = topic.split(":", 1)[1].strip()

        frontmatter = f"""---
date: {today}
time: "{time_str}"
project: UDO-Development-Platform
topic: {topic}
commit: {commit_info['hash'][:7]}
type: {work_type}
tags: [{', '.join(tags)}]
files_changed: {len(files)}
---
"""
        return frontmatter

    # =========================================================================
    # v3.0: Extended Frontmatter Generator (14 fields)
    # =========================================================================

    def generate_frontmatter_v3(
        self, commit_info: Dict, work_type: str, flags: Dict[str, bool], ai_context: Dict[str, Any]
    ) -> str:
        """v3.0 Frontmatter ìƒì„± (14ê°œ í•„ë“œ)"""
        commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
        today = commit_time.strftime("%Y-%m-%d")

        # Topic ì¶”ì¶œ (ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„)
        topic = commit_info.get("message", "").split("\n")[0]
        if ":" in topic:
            topic = topic.split(":", 1)[1].strip()
        topic = topic[:50]  # ìµœëŒ€ 50ì

        # íƒœê·¸ ìƒì„±
        tags = self._generate_tags_v3(commit_info, work_type, flags)

        # Frontmatter ë°ì´í„° êµ¬ì¡°
        frontmatter_data = {
            # ê¸°ë³¸ (4)
            "title": f"{today} {topic}",
            "created": today,
            "type": "daily",
            "status": "completed",
            # í”Œë˜ê·¸ (7)
            "has_til": flags.get("has_til", False),
            "has_solution": flags.get("has_solution", False),
            "has_pattern": flags.get("has_pattern", False),
            "has_uncertainty": flags.get("has_uncertainty", False),
            "has_rollback": flags.get("has_rollback", False),
            "has_debt": flags.get("has_debt", False),
            "has_decision": flags.get("has_decision", False),
            # AI ì»¨í…ìŠ¤íŠ¸ (3)
            "context_summary": ai_context.get("summary", ""),
            "next_actions": ai_context.get("next_actions", []),
            "warnings": ai_context.get("warnings", []),
            # ìë™ ìˆ˜ì§‘ (2)
            "files_changed": len(commit_info.get("files_changed", [])),
            "commits": self._count_today_commits(commit_time),
            # Schema ë²„ì „ (1)
            "schema_version": "1.0",
            # ë¶„ë¥˜ íƒœê·¸
            "tags": tags,
        }

        # YAML safe dump (ë°°ì—´ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)
        yaml_content = yaml.dump(frontmatter_data, default_flow_style=False, allow_unicode=True, sort_keys=False)

        return f"---\n{yaml_content}---\n"

    def _generate_tags_v3(self, commit_info: Dict, work_type: str, flags: Dict[str, bool]) -> List[str]:
        """v3.0 íƒœê·¸ ìƒì„±"""
        tags = ["commit", work_type]
        files = commit_info.get("files_changed", [])

        # íŒŒì¼ ê¸°ë°˜ íƒœê·¸
        if any("test" in f.lower() for f in files):
            tags.append("testing")
        if any("docs" in f.lower() for f in files):
            tags.append("documentation")
        if any("backend" in f.lower() for f in files):
            tags.append("backend")
        if any("frontend" in f.lower() or "web-dashboard" in f.lower() for f in files):
            tags.append("frontend")

        # í”Œë˜ê·¸ ê¸°ë°˜ íƒœê·¸
        if flags.get("has_debt"):
            tags.append("tech-debt")
        if flags.get("has_decision"):
            tags.append("decision")

        return list(set(tags))  # ì¤‘ë³µ ì œê±°

    def _count_today_commits(self, commit_time: datetime) -> int:
        """ë‹¹ì¼ ì»¤ë°‹ ìˆ˜ ê³„ì‚°"""
        try:
            today_str = commit_time.strftime("%Y-%m-%d")
            result = subprocess.check_output(
                ["git", "log", "--oneline", f"--since={today_str} 00:00:00", f"--until={today_str} 23:59:59"],
                cwd=self.repo_root,
                encoding="utf-8",
                errors="replace",
            ).strip()
            return len([line for line in result.split("\n") if line])
        except subprocess.CalledProcessError:
            return 1

    def _get_full_diff(self, commit_hash: str) -> str:
        """ì „ì²´ diff ê°€ì ¸ì˜¤ê¸°"""
        try:
            return subprocess.check_output(
                ["git", "show", "--format=", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()
        except subprocess.CalledProcessError:
            return ""

    def _load_session_state(self) -> Dict:
        """session_state.json ë¡œë“œ"""
        session_file = self.repo_root / ".udo" / "session_state.json"

        if not session_file.exists():
            return {}

        try:
            with open(session_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}

    def generate_dev_log(self, commit_info: Dict) -> str:
        """ê°œë°œì¼ì§€ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        work_type = self.categorize_work_type(commit_info)
        frontmatter = self.generate_frontmatter(commit_info, work_type)
        insights = self.generate_ai_insights(commit_info)

        # ì»¤ë°‹ ë©”ì‹œì§€
        message = commit_info.get("message", "")
        message_lines = message.split("\n")
        title = message_lines[0]
        description = "\n".join(message_lines[1:]).strip() if len(message_lines) > 1 else ""

        # íŒŒì¼ ë³€ê²½ ì‚¬í•­
        files = commit_info.get("files_changed", [])
        files_by_category = {
            "Backend": [f for f in files if f.startswith("backend/")],
            "Frontend": [f for f in files if f.startswith("web-dashboard/")],
            "Docs": [f for f in files if f.startswith("docs/")],
            "Scripts": [f for f in files if f.startswith("scripts/")],
            "Tests": [f for f in files if "test" in f.lower()],
            "Other": [],
        }

        # Other ì¹´í…Œê³ ë¦¬ ì±„ìš°ê¸°
        categorized = sum(files_by_category.values(), [])
        files_by_category["Other"] = [f for f in files if f not in categorized]

        # ë§ˆí¬ë‹¤ìš´ ìƒì„±
        content = frontmatter + f"\n# {title}\n\n"

        if description:
            content += f"{description}\n\n"

        content += "## ë³€ê²½ ì‚¬í•­\n\n"
        for category, category_files in files_by_category.items():
            if category_files:
                content += f"### {category} ({len(category_files)})\n"
                for file in category_files[:10]:  # ìµœëŒ€ 10ê°œë§Œ
                    content += f"- `{file}`\n"
                if len(category_files) > 10:
                    content += f"- ... and {len(category_files) - 10} more\n"
                content += "\n"

        # AI ì¸ì‚¬ì´íŠ¸
        if insights["learned"]:
            content += "## ğŸ’¡ ë°°ìš´ ì \n\n"
            for item in insights["learned"]:
                content += f"- {item}\n"
            content += "\n"

        if insights["challenges"]:
            content += "## ğŸ”§ ì‹œí–‰ì°©ì˜¤\n\n"
            for item in insights["challenges"]:
                content += f"- {item}\n"
            content += "\n"

        if insights["next_steps"]:
            content += "## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„\n\n"
            for item in insights["next_steps"]:
                content += f"- {item}\n"
            content += "\n"

        # ì»¤ë°‹ í†µê³„
        content += "## ğŸ“Š í†µê³„\n\n"
        content += f"```\n{commit_info.get('stats', '')}\n```\n\n"

        content += f"**ì»¤ë°‹ í•´ì‹œ**: `{commit_info['hash'][:7]}`  \n"
        content += f"**ì‘ì„± ì‹œê°**: {commit_info['time']}  \n"
        content += f"**ìë™ ìƒì„±**: Obsidian Auto-Sync v2.0  \n"

        return content

    def sync(self, commit_hash: str, version: int = 2) -> bool:
        """Obsidian ë™ê¸°í™” ì‹¤í–‰

        Args:
            commit_hash: Git ì»¤ë°‹ í•´ì‹œ
            version: ì‚¬ìš©í•  ë²„ì „ (2=v2.0, 3=v3.0)
        """
        try:
            # 1. ì»¤ë°‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            commit_info = self.get_commit_info(commit_hash)
            if not commit_info:
                print("[ERROR] Failed to get commit info", file=sys.stderr)
                return False

            # 2. íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸
            triggered, reason = self.check_trigger_conditions(commit_info)
            if not triggered:
                print(f"[SKIP] Trigger condition not met: {reason}")
                return True  # ì—ëŸ¬ëŠ” ì•„ë‹˜

            print(f"[TRIGGER] {reason}")

            # 3. ê°œë°œì¼ì§€ ìƒì„± (ë²„ì „ì— ë”°ë¼ ë¶„ê¸°)
            if version >= 3:
                dev_log_content = self.generate_dev_log_v3(commit_info)
                version_str = "v3.0"
            else:
                dev_log_content = self.generate_dev_log(commit_info)
                version_str = "v2.0"

            # 4. Obsidianì— ì €ì¥
            commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
            date_folder = commit_time.strftime("%Y-%m-%d")
            topic = commit_info.get("message", "").split("\n")[0].replace(":", "-").replace("/", "-")[:50]
            filename = f"{topic}.md"

            # ë‚ ì§œ í´ë” ìƒì„±
            date_dir = self.dev_log_dir / date_folder
            date_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            file_path = date_dir / filename
            file_path.write_text(dev_log_content, encoding="utf-8")

            print(f"[OK] Obsidian dev log created ({version_str}): {date_folder}/{filename}")
            return True

        except Exception as e:
            print(f"[ERROR] Sync failed: {e}", file=sys.stderr)
            import traceback

            traceback.print_exc()
            return False

    # =========================================================================
    # v3.0: Full Dev Log Generator (9 Daily Sections)
    # =========================================================================

    def generate_dev_log_v3(self, commit_info: Dict) -> str:
        """v3.0 ê°œë°œì¼ì§€ ë§ˆí¬ë‹¤ìš´ ìƒì„± (9ê°œ Daily ì„¹ì…˜)"""
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        work_type = self.categorize_work_type(commit_info)
        commit_hash = commit_info.get("hash", "HEAD")

        # ì „ì²´ diff ê°€ì ¸ì˜¤ê¸°
        full_diff = self._get_full_diff(commit_hash)

        # í”Œë˜ê·¸ ê°ì§€
        flag_detector = FlagDetector(full_diff, commit_info)
        flags = flag_detector.detect_all()

        # AI ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        ai_context_gen = AIContextGenerator(commit_info, full_diff)
        ai_context = ai_context_gen.generate()

        # v3 Frontmatter ìƒì„±
        frontmatter = self.generate_frontmatter_v3(commit_info, work_type, flags, ai_context)

        # ì„¸ì…˜ ìƒíƒœ ë¡œë“œ
        session_state = self._load_session_state()

        # ì„¹ì…˜ ìƒì„±ê¸° ì´ˆê¸°í™”
        section_gen = SectionGenerator(
            commit_info=commit_info, flags=flags, session_state=session_state, diff=full_diff, repo_root=self.repo_root
        )

        # ì „ì²´ ì½˜í…ì¸  ì¡°í•©
        content = frontmatter
        content += section_gen.generate_all_sections()

        # í‘¸í„°
        content += "\n---\n"
        content += f"**ì»¤ë°‹ í•´ì‹œ**: `{commit_info['hash'][:7]}`  \n"
        content += f"**ì‘ì„± ì‹œê°**: {commit_info['time']}  \n"
        content += "**ìë™ ìƒì„±**: Obsidian Auto-Sync v3.0  \n"

        return content

    # =========================================================================
    # v3.0: Weekly Sync Method
    # =========================================================================

    def sync_weekly(self, week_offset: int = 0) -> bool:
        """ì£¼ê°„ ìš”ì•½ ë™ê¸°í™” ì‹¤í–‰

        Args:
            week_offset: 0=ì´ë²ˆ ì£¼, -1=ì§€ë‚œ ì£¼, -2=2ì£¼ ì „ ë“±
        """
        try:
            # ì£¼ê°„ ë²”ìœ„ ê³„ì‚°
            today = datetime.now()
            # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ ì°¾ê¸°
            week_start = today - timedelta(days=today.weekday())
            week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)

            # offset ì ìš©
            week_start = week_start + timedelta(weeks=week_offset)
            week_end = week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)

            print(f"[WEEKLY] Generating summary for {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}")

            # Weekly ìƒì„±ê¸° ì´ˆê¸°í™”
            weekly_gen = WeeklySummaryGenerator(week_start, week_end)
            weekly_content = weekly_gen.generate_weekly_note()

            # ì €ì¥ ê²½ë¡œ ì„¤ì • (ê°œë°œì¼ì§€/Weekly/)
            weekly_dir = self.dev_log_dir / "Weekly"
            weekly_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ëª…
            week_str = week_start.strftime("%Y-W%W")
            filename = f"{week_str}-weekly-summary.md"
            file_path = weekly_dir / filename

            # ì €ì¥
            file_path.write_text(weekly_content, encoding="utf-8")

            print(f"[OK] Weekly summary created: Weekly/{filename}")
            return True

        except Exception as e:
            print(f"[ERROR] Weekly sync failed: {e}", file=sys.stderr)
            import traceback

            traceback.print_exc()
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Obsidian Auto-Sync v3.0 - AI-Enhanced Development Log Generator")
    parser.add_argument("--commit-hash", default="HEAD", help="Commit hash to sync")
    parser.add_argument("--vault", help="Obsidian vault path (optional)")
    parser.add_argument(
        "--version", type=int, default=2, choices=[2, 3], help="Sync version (2=v2.0, 3=v3.0 with extended frontmatter)"
    )
    parser.add_argument("--weekly", action="store_true", help="Generate weekly summary instead of daily log")
    parser.add_argument("--week-offset", type=int, default=0, help="Week offset for weekly summary (0=current, -1=last week)")
    args = parser.parse_args()

    # Repo root ì°¾ê¸°
    repo_root = Path(__file__).resolve().parents[1]

    # Vault ê²½ë¡œ
    vault_path = Path(args.vault) if args.vault else None

    # ë™ê¸°í™” ì‹¤í–‰
    syncer = ObsidianAutoSync(repo_root, vault_path)

    if args.weekly:
        # ì£¼ê°„ ìš”ì•½ ìƒì„±
        success = syncer.sync_weekly(week_offset=args.week_offset)
    else:
        # ì¼ì¼ ë¡œê·¸ ìƒì„±
        success = syncer.sync(args.commit_hash, version=args.version)

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
