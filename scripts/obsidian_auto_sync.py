#!/usr/bin/env python
"""
Obsidian Auto-Sync v3.6.2 - AI-Enhanced Development Log Generator

ìë™ìœ¼ë¡œ Git commit ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ Obsidian ê°œë°œì¼ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

Features (v3.6.2):
- ë¡œê¹… ê°œì„ : print() â†’ logging ëª¨ë“ˆ (í‘œì¤€ Python ë¡œê¹…)
- ìŠ¤í‚¤ë§ˆ ê²€ì¦: ì»¤ë¦¬í˜ëŸ¼ í•­ëª© í•„ìˆ˜ í•„ë“œ ë° íƒ€ì… ê²€ì¦
- Path Traversal ë°©ì–´: í™˜ê²½ë³€ìˆ˜ ê²½ë¡œ ë³´ì•ˆ ê²€ì¦

Features (v3.6.1):
- ì»¤ë¦¬í˜ëŸ¼ ì™¸ë¶€í™”: YAML ì„¤ì • íŒŒì¼ ë¶„ë¦¬ (config/learning_curriculum.yaml)
- íŒ¨í„´ë„ YAMLì—ì„œ ë¡œë“œ (CHECKPOINT_PATTERNS)
- Fallback ì§€ì›: YAML ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìµœì†Œ ê¸°ëŠ¥ ìœ ì§€

Features (v3.6):
- ì²´í¬í¬ì¸íŠ¸ ìë™ ê°ì§€ (ì»¤ë°‹ ë©”ì‹œì§€ + diff íŒ¨í„´ ë¶„ì„)
- ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ìë™ ì²´í¬ ë° ì €ì¥

Features (v3.5):
- í•™ìŠµ ì§„í–‰ ìƒí™© ì¶”ì  (Learning Progress Tracking)
- ê³ ë ¤ì‚¬í•­(Considerations) + ì£¼ì˜ì (Warnings) í‘œì‹œ
- Bridge Review/Preview (ì›”ê°„ ì „í™˜ ì‹œ)

Features (v3.0):
- 14ê°œ Frontmatter í•„ë“œ (ê¸°ë³¸4 + í”Œë˜ê·¸7 + AIì»¨í…ìŠ¤íŠ¸3 + ìë™ìˆ˜ì§‘2 + schema1)
- 9ê°œ Daily ì„¹ì…˜ (ì¡°ê±´ë¶€ ë Œë”ë§)
- 4ê°œ Weekly ì„¹ì…˜ (ì£¼ê°„ ì§‘ê³„)
- í”Œë˜ê·¸ ìë™ ê°ì§€ (Git diff ë¶„ì„)
- í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë¦¬ê±° (Git Hook + session_state.json)
- Schema ë²„ì „ ê´€ë¦¬

Features (v2.0):
- íŠ¸ë¦¬ê±° ì¡°ê±´ ìë™ ê°ì§€ (3+ íŒŒì¼, feat:/fix: ë©”ì‹œì§€)
- AI ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„± (ë°°ìš´ ì , ì‹œí–‰ì°©ì˜¤, ë‹¤ìŒ ë‹¨ê³„)
- ì‹œê°„ëŒ€ë³„ ì‘ì—… ë‚´ì—­ ì¶”ë¡ 
- YAML frontmatter ìë™ ìƒì„±

Usage:
  python scripts/obsidian_auto_sync.py --commit-hash <hash>
  python scripts/obsidian_auto_sync.py --commit-hash HEAD
  python scripts/obsidian_auto_sync.py --commit-hash HEAD --version 3

Requirements:
- Git repository
- Obsidian vault configured in environment or default location

Author: System Automation Team
Date: 2025-12-29
Version: 3.6.2 (Logging + Schema Validation + Path Traversal Defense)
"""

import argparse
import json
import logging
import os
import re
import subprocess
import sys
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

# =============================================================================
# Logging Configuration
# =============================================================================
logger = logging.getLogger(__name__)

# ê¸°ë³¸ ë¡œê¹… ì„¤ì • (í˜¸ì¶œìê°€ ì„¤ì •í•˜ì§€ ì•Šì€ ê²½ìš°)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stderr)
    handler.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)


# =============================================================================
# v3.0: Diff Utilities (Git diff ë¶„ì„ í—¬í¼)
# =============================================================================


def extract_added_lines(diff: str) -> str:
    """Git diffì—ì„œ ì¶”ê°€ëœ ì¤„ë§Œ ì¶”ì¶œ (+ ë¡œ ì‹œì‘í•˜ëŠ” ì¤„)

    ì´ í•¨ìˆ˜ëŠ” diff ì „ì²´ê°€ ì•„ë‹Œ ì‹¤ì œ 'ì¶”ê°€ëœ ì½”ë“œ'ë§Œ ë¶„ì„í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    ë¬¸ìì—´ ë¦¬í„°ëŸ´ ë‚´ ì£¼ì„ ì˜¤íƒì§€ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    lines = []
    for line in diff.split("\n"):
        # +ë¡œ ì‹œì‘í•˜ì§€ë§Œ +++ (íŒŒì¼ í—¤ë”)ëŠ” ì œì™¸
        if line.startswith("+") and not line.startswith("+++"):
            # ì•ì˜ + ì œê±°
            lines.append(line[1:])
    return "\n".join(lines)


# =============================================================================
# v3.1: AI Metacognition Support (AI ë©”íƒ€ì¸ì§€ ì—°ë™)
# =============================================================================


def load_ai_metacognition() -> Dict[str, Any]:
    """AI ì„¸ì…˜ì—ì„œ ì €ì¥í•œ ë©”íƒ€ì¸ì§€ ì •ë³´ ë¡œë“œ

    Returns:
        AI ë©”íƒ€ì¸ì§€ ë”•ì…”ë„ˆë¦¬:
        - least_confident: ê°€ì¥ ëœ ìì‹ ìˆëŠ” ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸
        - simplifications: ë‹¨ìˆœí™” ê°€ì • ë¦¬ìŠ¤íŠ¸
        - opinion_changers: ì˜ê²¬ ë³€ê²½ ê°€ëŠ¥ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        - areas_to_improve: ë³´ì™„ í•„ìš” ì˜ì—­ ë¦¬ìŠ¤íŠ¸
        - blockers: í˜„ì¬ ì°¨ë‹¨ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
    """
    session_file = Path(".udo/session_state.json")
    if not session_file.exists():
        return {}

    try:
        with open(session_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("ai_metacognition", {})
    except (json.JSONDecodeError, IOError):
        return {}


def save_ai_metacognition(metacognition: Dict[str, Any]) -> bool:
    """AI ë©”íƒ€ì¸ì§€ ì •ë³´ë¥¼ session_state.jsonì— ì €ì¥

    Args:
        metacognition: AI ë©”íƒ€ì¸ì§€ ë”•ì…”ë„ˆë¦¬

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    session_file = Path(".udo/session_state.json")
    session_file.parent.mkdir(parents=True, exist_ok=True)

    try:
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        if session_file.exists():
            with open(session_file, "r", encoding="utf-8") as f:
                data = json.load(f)
        else:
            data = {}

        # ë©”íƒ€ì¸ì§€ ì •ë³´ ì—…ë°ì´íŠ¸
        data["ai_metacognition"] = metacognition
        data["ai_metacognition_updated"] = datetime.now().isoformat()

        with open(session_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except (json.JSONDecodeError, IOError):
        return False


# =============================================================================
# v3.6.1: External YAML Configuration Loading
# =============================================================================

# ì»¤ë¦¬í˜ëŸ¼ í•­ëª© í•„ìˆ˜ í•„ë“œ ì •ì˜
REQUIRED_CURRICULUM_FIELDS = {"title", "focus", "checkpoints"}
OPTIONAL_CURRICULUM_FIELDS = {"considerations", "warnings", "guide"}


def _validate_curriculum_entry(key: str, entry: Any) -> Tuple[bool, str]:
    """ì»¤ë¦¬í˜ëŸ¼ í•­ëª© ìŠ¤í‚¤ë§ˆ ê²€ì¦

    Args:
        key: ì»¤ë¦¬í˜ëŸ¼ í‚¤ (ì˜ˆ: "1-2")
        entry: ì»¤ë¦¬í˜ëŸ¼ í•­ëª© ë”•ì…”ë„ˆë¦¬

    Returns:
        (is_valid, error_message) íŠœí”Œ
    """
    if not isinstance(entry, dict):
        return False, f"Entry '{key}' must be a dictionary, got {type(entry).__name__}"

    # í•„ìˆ˜ í•„ë“œ ê²€ì¦
    missing = REQUIRED_CURRICULUM_FIELDS - set(entry.keys())
    if missing:
        return False, f"Entry '{key}' missing required fields: {missing}"

    # íƒ€ì… ê²€ì¦
    if not isinstance(entry.get("title"), str):
        return False, f"Entry '{key}' field 'title' must be a string"
    if not isinstance(entry.get("focus"), str):
        return False, f"Entry '{key}' field 'focus' must be a string"
    if not isinstance(entry.get("checkpoints"), list):
        return False, f"Entry '{key}' field 'checkpoints' must be a list"

    # ì„ íƒì  í•„ë“œ íƒ€ì… ê²€ì¦
    if "considerations" in entry and not isinstance(entry["considerations"], list):
        return False, f"Entry '{key}' field 'considerations' must be a list"
    if "warnings" in entry and not isinstance(entry["warnings"], list):
        return False, f"Entry '{key}' field 'warnings' must be a list"
    if "guide" in entry and not isinstance(entry["guide"], str):
        return False, f"Entry '{key}' field 'guide' must be a string"

    return True, ""


def _is_path_within_allowed_dirs(path: Path, allowed_dirs: List[Path]) -> bool:
    """ê²½ë¡œê°€ í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸ (Path Traversal ë°©ì–´)

    Args:
        path: ê²€ì¦í•  ê²½ë¡œ
        allowed_dirs: í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ëª©ë¡

    Returns:
        í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆìœ¼ë©´ True
    """
    try:
        resolved_path = path.resolve()
        for allowed_dir in allowed_dirs:
            resolved_allowed = allowed_dir.resolve()
            # pathê°€ allowed_dirì˜ í•˜ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
            try:
                resolved_path.relative_to(resolved_allowed)
                return True
            except ValueError:
                continue
        return False
    except (OSError, RuntimeError):
        # ê²½ë¡œ í•´ì„ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ê±°ë¶€
        return False


def _get_curriculum_yaml_path() -> Path:
    """ì»¤ë¦¬í˜ëŸ¼ YAML íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    # í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ëª©ë¡ (Path Traversal ë°©ì–´)
    allowed_dirs = [
        project_root,  # í”„ë¡œì íŠ¸ ë£¨íŠ¸
        Path.cwd(),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
    ]

    # 1. í™˜ê²½ë³€ìˆ˜ì—ì„œ ê²½ë¡œ í™•ì¸ (Path Traversal ê²€ì¦ í¬í•¨)
    env_path = os.environ.get("CURRICULUM_YAML_PATH")
    if env_path:
        env_path_obj = Path(env_path)
        if env_path_obj.exists():
            if _is_path_within_allowed_dirs(env_path_obj, allowed_dirs):
                return env_path_obj
            else:
                logger.warning(f"CURRICULUM_YAML_PATH '{env_path}' is outside allowed directories. " f"Ignoring for security.")

    # 2. ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
    config_path = project_root / "config" / "learning_curriculum.yaml"
    if config_path.exists():
        return config_path

    # 3. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€
    cwd_path = Path.cwd() / "config" / "learning_curriculum.yaml"
    if cwd_path.exists():
        return cwd_path

    return config_path  # ê¸°ë³¸ê°’ (ì—†ìœ¼ë©´ fallback ì‚¬ìš©)


def _load_curriculum_from_yaml() -> Tuple[Dict, Dict]:
    """YAML íŒŒì¼ì—ì„œ ì»¤ë¦¬í˜ëŸ¼ê³¼ íŒ¨í„´ ë¡œë“œ

    Returns:
        (LEARNING_CURRICULUM, CHECKPOINT_PATTERNS) íŠœí”Œ
    """
    yaml_path = _get_curriculum_yaml_path()

    if not yaml_path.exists():
        # Fallback: í•˜ë“œì½”ë”©ëœ ìµœì†Œ ì»¤ë¦¬í˜ëŸ¼
        logger.info(f"Curriculum YAML not found at {yaml_path}. Using fallback.")
        return _get_fallback_curriculum(), _get_fallback_patterns()

    try:
        with open(yaml_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)

        # ì»¤ë¦¬í˜ëŸ¼ ë³€í™˜: "1-2" -> (1, 2) + ìŠ¤í‚¤ë§ˆ ê²€ì¦
        curriculum = {}
        validation_errors = []
        for key, value in data.get("curriculum", {}).items():
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦
            is_valid, error_msg = _validate_curriculum_entry(key, value)
            if not is_valid:
                validation_errors.append(error_msg)
                continue

            # í‚¤ í˜•ì‹ ê²€ì¦ ë° ë³€í™˜
            parts = key.split("-")
            if len(parts) == 2:
                try:
                    month, week = int(parts[0]), int(parts[1])
                    curriculum[(month, week)] = value
                except ValueError:
                    validation_errors.append(f"Invalid key format '{key}': must be 'N-N'")

        # ê²€ì¦ ì˜¤ë¥˜ ë¡œê¹…
        if validation_errors:
            logger.warning(
                f"Schema validation errors ({len(validation_errors)}): "
                f"{validation_errors[:3]}{'...' if len(validation_errors) > 3 else ''}"
            )

        # íŒ¨í„´ ë¡œë“œ
        patterns = data.get("checkpoint_patterns", {})

        logger.info(f"Curriculum loaded from {yaml_path}: " f"{len(curriculum)} entries, {len(patterns)} patterns")
        return curriculum, patterns

    except (yaml.YAMLError, IOError) as e:
        logger.warning(f"Failed to load curriculum YAML: {e}. Using fallback.")
        return _get_fallback_curriculum(), _get_fallback_patterns()


def _get_fallback_curriculum() -> Dict:
    """YAML ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìµœì†Œ fallback ì»¤ë¦¬í˜ëŸ¼"""
    return {
        (1, 1): {
            "title": "ê¸°ì´ˆ ë‹¤ì§€ê¸° - Claude Code ê¸°ë³¸",
            "focus": "Claude Code ê¸°ë³¸ ëª…ë ¹ì–´ ìµíˆê¸°",
            "checkpoints": ["/sc:analyze 3íšŒ ì´ìƒ ì‚¬ìš©", "ê°„ë‹¨í•œ í•¨ìˆ˜ êµ¬í˜„ 1íšŒ"],
            "considerations": ["AI ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë³µë¶™í•˜ì§€ ë§ê³  ì´í•´í•œ í›„ ì‚¬ìš©"],
            "warnings": ["AIê°€ ìƒì„±í•œ ì½”ë“œë„ ë°˜ë“œì‹œ ê²€í†  í•„ìš”"],
            "guide": "Claude-Skills-Curriculum",
        }
    }


def _get_fallback_patterns() -> Dict:
    """YAML ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìµœì†Œ fallback íŒ¨í„´"""
    return {
        "/sc:analyze": ["sc:analyze", "ë¶„ì„\\s*ì™„ë£Œ"],
        "í•¨ìˆ˜ êµ¬í˜„": ["def\\s+\\w+\\s*\\(", "function\\s+\\w+\\s*\\("],
    }


# YAMLì—ì„œ ì»¤ë¦¬í˜ëŸ¼ ë¡œë“œ (ëª¨ë“ˆ ë¡œë“œ ì‹œ 1íšŒë§Œ ì‹¤í–‰)
LEARNING_CURRICULUM, CHECKPOINT_PATTERNS = _load_curriculum_from_yaml()


# =============================================================================
# v3.5: Learning Progress Tracking (í•™ìŠµ ì§„í–‰ ìƒí™© ì¶”ì )
# =============================================================================


def load_learning_progress() -> Dict[str, Any]:
    """í•™ìŠµ ì§„í–‰ ìƒí™© ë¡œë“œ

    Returns:
        learning_progress: {month, week, started_at, checkpoints_done}
    """
    session_file = Path(".udo/session_state.json")
    if not session_file.exists():
        return {"month": 1, "week": 1, "started_at": None, "checkpoints_done": []}

    try:
        with open(session_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        progress = data.get("learning_progress", {})
        if not progress:
            return {"month": 1, "week": 1, "started_at": None, "checkpoints_done": []}
        return progress
    except (json.JSONDecodeError, IOError):
        return {"month": 1, "week": 1, "started_at": None, "checkpoints_done": []}


def save_learning_progress(progress: Dict[str, Any]) -> bool:
    """í•™ìŠµ ì§„í–‰ ìƒí™© ì €ì¥"""
    session_file = Path(".udo/session_state.json")
    session_file.parent.mkdir(parents=True, exist_ok=True)

    try:
        if session_file.exists():
            with open(session_file, "r", encoding="utf-8") as f:
                data = json.load(f)
        else:
            data = {}

        # ì‹œì‘ì¼ ìë™ ì„¤ì •
        if not progress.get("started_at"):
            progress["started_at"] = datetime.now().isoformat()

        data["learning_progress"] = progress
        data["learning_progress_updated"] = datetime.now().isoformat()

        with open(session_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except (json.JSONDecodeError, IOError):
        return False


def get_current_curriculum() -> Dict[str, Any]:
    """í˜„ì¬ í•™ìŠµ ë‹¨ê³„ì˜ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ ë°˜í™˜"""
    progress = load_learning_progress()
    month = progress.get("month", 1)
    week = progress.get("week", 1)

    # ë²”ìœ„ ì²´í¬ (month=0ì€ ì‚¬ì „ ì¤€ë¹„ ì£¼ê°„ìœ¼ë¡œ í—ˆìš©)
    if month < 0:
        month = 0
    if month > 3:
        month = 3
    if month == 0:
        week = 0  # month=0ì¼ ë•ŒëŠ” weekë„ 0ìœ¼ë¡œ ê³ ì •
    elif week < 1:
        week = 1
    elif week > 4:
        week = 4

    key = (month, week)
    curriculum = LEARNING_CURRICULUM.get(key, LEARNING_CURRICULUM[(1, 1)])

    return {
        "month": month,
        "week": week,
        "title": curriculum["title"],
        "focus": curriculum["focus"],
        "checkpoints": curriculum["checkpoints"],
        "considerations": curriculum.get("considerations", []),
        "warnings": curriculum.get("warnings", []),
        "guide": curriculum["guide"],
        "checkpoints_done": progress.get("checkpoints_done", []),
    }


# =============================================================================
# v3.6: Checkpoint Auto-Detection (ì²´í¬í¬ì¸íŠ¸ ìë™ ê°ì§€)
# =============================================================================
# NOTE: CHECKPOINT_PATTERNSëŠ” config/learning_curriculum.yamlì—ì„œ ë¡œë“œë¨
# ì´ ë¶€ë¶„ì€ ìœ„ì˜ _load_curriculum_from_yaml() í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬ë¨


def detect_checkpoint_completion(commit_message: str, diff: str, current_curriculum: Dict[str, Any]) -> List[str]:
    """ì»¤ë°‹ ë©”ì‹œì§€ì™€ diffë¥¼ ë¶„ì„í•˜ì—¬ ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ê°ì§€

    Args:
        commit_message: Git ì»¤ë°‹ ë©”ì‹œì§€
        diff: Git diff ë‚´ìš©
        current_curriculum: í˜„ì¬ í•™ìŠµ ë‹¨ê³„ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´

    Returns:
        ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ì„¤ëª… ë¦¬ìŠ¤íŠ¸ (ìƒˆë¡œ ê°ì§€ëœ ê²ƒë§Œ)
    """
    newly_completed = []
    checkpoints = current_curriculum.get("checkpoints", [])
    already_done = set(current_curriculum.get("checkpoints_done", []))

    # ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ ê²°í•© (ì»¤ë°‹ ë©”ì‹œì§€ + ì¶”ê°€ëœ ì¤„ë§Œ)
    added_lines = extract_added_lines(diff)
    combined_text = f"{commit_message}\n{added_lines}".lower()

    for checkpoint in checkpoints:
        # ì´ë¯¸ ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ëŠ” ìŠ¤í‚µ
        if checkpoint in already_done:
            continue

        # ì²´í¬í¬ì¸íŠ¸ì™€ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì°¾ê¸°
        checkpoint_matched = False
        for pattern_key, patterns in CHECKPOINT_PATTERNS.items():
            # íŒ¨í„´ í‚¤ê°€ ì²´í¬í¬ì¸íŠ¸ ì„¤ëª…ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if pattern_key.lower() in checkpoint.lower():
                # í•´ë‹¹ íŒ¨í„´ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ ì™„ë£Œë¡œ íŒì •
                for pattern in patterns:
                    if re.search(pattern, combined_text, re.IGNORECASE):
                        newly_completed.append(checkpoint)
                        checkpoint_matched = True
                        break
                if checkpoint_matched:
                    break

    return newly_completed


def update_checkpoints_done(newly_completed: List[str]) -> bool:
    """ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ learning_progressì— ì €ì¥

    Args:
        newly_completed: ìƒˆë¡œ ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    if not newly_completed:
        return True

    progress = load_learning_progress()
    existing = set(progress.get("checkpoints_done", []))
    updated = existing.union(set(newly_completed))

    if updated != existing:
        progress["checkpoints_done"] = list(updated)
        return save_learning_progress(progress)
    return True


def is_real_comment(line: str, pattern: str) -> bool:
    """ì‹¤ì œ ì£¼ì„ì¸ì§€ ë¬¸ìì—´ ë¦¬í„°ëŸ´ì¸ì§€ êµ¬ë¶„

    Args:
        line: ê²€ì‚¬í•  ë¼ì¸
        pattern: ì°¾ëŠ” íŒ¨í„´ (ì˜ˆ: "# TODO:")

    Returns:
        True if ì‹¤ì œ ì£¼ì„, False if ë¬¸ìì—´ ë¦¬í„°ëŸ´
    """
    # ë¬¸ìì—´ ë¦¬í„°ëŸ´ ë‚´ë¶€ì¸ì§€ í™•ì¸
    # íŒ¨í„´ ì•ì— ë”°ì˜´í‘œê°€ ìˆìœ¼ë©´ ë¬¸ìì—´ ë‚´ë¶€ì¼ ê°€ëŠ¥ì„±
    pattern_pos = line.find(pattern)
    if pattern_pos == -1:
        return False

    before = line[:pattern_pos]

    # ì—´ë¦° ë”°ì˜´í‘œ ê°œìˆ˜ í™•ì¸ (í™€ìˆ˜ë©´ ë¬¸ìì—´ ë‚´ë¶€)
    single_quotes = before.count("'") - before.count("\\'")
    double_quotes = before.count('"') - before.count('\\"')

    # í™€ìˆ˜ë©´ ë¬¸ìì—´ ë‚´ë¶€ë¡œ íŒë‹¨
    if single_quotes % 2 == 1 or double_quotes % 2 == 1:
        return False

    return True


def clean_extracted_text(text: str) -> str:
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ë…¸ì´ì¦ˆ ì œê±°

    - ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì œê±°
    - ì§§ì€ ë¬´ì˜ë¯¸ ë¬¸ìì—´ ì œê±°
    - ë”°ì˜´í‘œ ì œê±°
    - ì½”ë“œ ì„¤ëª… ì£¼ì„ í•„í„°ë§
    """
    if not text:
        return ""

    # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì í¬í•¨ ì‹œ ë¬´íš¨
    if "\\n" in text or "\\r" in text or "\\t" in text:
        return ""

    # ë”°ì˜´í‘œë¡œ ì‹œì‘/ëë‚˜ë©´ ë¬¸ìì—´ ë¦¬í„°ëŸ´
    text = text.strip()
    if text.startswith('"') or text.startswith("'"):
        return ""
    if text.endswith('",') or text.endswith("',"):
        return ""

    # ë„ˆë¬´ ì§§ê±°ë‚˜ ë¬´ì˜ë¯¸í•œ íŒ¨í„´
    if len(text) < 5:
        return ""

    # ì½”ë“œ ì¡°ê° í•„í„°ë§
    noise_patterns = [
        r"^\s*\(",
        r"^\s*\)",
        r"^\s*\[",
        r"^\s*\]",
        r"^\s*\{",
        r"^\s*\}",
        r"^\s*#\s*$",
        r"^[,;:\"\']",
    ]
    for pattern in noise_patterns:
        if re.match(pattern, text):
            return ""

    # ì½”ë“œ ì„¤ëª… ì£¼ì„ í•„í„°ë§ (ì½”ë“œ ë™ì‘ ì„¤ëª…ì€ ì œì™¸)
    # "ì¶”ì¶œ", "ë°˜í™˜", "ìƒì„±", "ê²€ì‚¬" ë“±ìœ¼ë¡œë§Œ êµ¬ì„±ëœ ì§§ì€ ì„¤ëª…ì€ ì œì™¸
    code_desc_patterns = [
        r"^(ì¶”ì¶œ|ë°˜í™˜|ìƒì„±|ê²€ì‚¬|í™•ì¸|ë³€í™˜|ì²˜ë¦¬|í˜¸ì¶œ|ì„¤ì •|ì´ˆê¸°í™”|ë¡œë“œ|ì €ì¥)\s*$",
        r"^(ì—ì„œ|ì—ê²Œ|ìœ¼ë¡œ|ë¡œ|ë¥¼|ì„|ì´|ê°€)\s",  # ì¡°ì‚¬ë¡œ ì‹œì‘í•˜ë©´ ë¶ˆì™„ì „í•œ ë¬¸ì¥
        r"^\w{1,3}\s+(ì¶”ì¶œ|ë°˜í™˜|ìƒì„±|ê²€ì‚¬)$",  # ì§§ì€ ëª…ì‚¬ + ë™ì‘
    ]
    for pattern in code_desc_patterns:
        if re.match(pattern, text, re.I):
            return ""

    return text


def extract_real_comments(diff: str, prefix: str, require_colon: bool = None) -> List[str]:
    """diffì—ì„œ ì‹¤ì œ ì£¼ì„ë§Œ ì¶”ì¶œ (ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì œì™¸)

    Args:
        diff: Git diff ì „ì²´ í…ìŠ¤íŠ¸
        prefix: ì°¾ì„ ì£¼ì„ ì ‘ë‘ì‚¬ (ì˜ˆ: "TODO", "FIXME", "TIL")
        require_colon: ì½œë¡  í•„ìˆ˜ ì—¬ë¶€ (None=ìë™ ê²°ì •)
            - TODO, FIXME, HACK, XXX, RISK: ì½œë¡  í•„ìˆ˜ (ì•¡ì…˜ ì•„ì´í…œ)
            - TIL, Solution, Pattern, Decision, Why, Rollback: ì½œë¡  ì„ íƒ

    Returns:
        ì¶”ì¶œëœ ì£¼ì„ ë‚´ìš© ë¦¬ìŠ¤íŠ¸
    """
    added_lines = extract_added_lines(diff)
    results = []

    # ì•¡ì…˜ ì•„ì´í…œ ì ‘ë‘ì‚¬ëŠ” ì½œë¡  í•„ìˆ˜ (ì½”ë“œ ì„¤ëª… ì£¼ì„ê³¼ êµ¬ë¶„)
    action_prefixes = ["TODO", "FIXME", "HACK", "XXX", "RISK"]

    if require_colon is None:
        require_colon = prefix.upper() in action_prefixes

    # íŒ¨í„´ êµ¬ì„±: ì½œë¡  í•„ìˆ˜ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¦„
    if require_colon:
        # ì½œë¡  í•„ìˆ˜: # TODO: ë‚´ìš© (ê³µë°± í—ˆìš©)
        pattern = rf"^\s*#\s*{prefix}\s*:\s*(.+)"
    else:
        # ì½œë¡  ì„ íƒ: # TIL ë‚´ìš© ë˜ëŠ” # TIL: ë‚´ìš©
        pattern = rf"^\s*#\s*{prefix}:?\s+(.+)"

    for line in added_lines.split("\n"):
        match = re.search(pattern, line, re.I)
        if match:
            content = match.group(1).strip()
            # ë¬¸ìì—´ ë¦¬í„°ëŸ´ ë‚´ë¶€ì¸ì§€ í™•ì¸
            if is_real_comment(line, f"# {prefix}"):
                cleaned = clean_extracted_text(content)
                if cleaned:
                    results.append(cleaned)

    return results


# =============================================================================
# v3.0: Flag Detection System
# =============================================================================


class FlagDetector:
    """Git diffì™€ ì»¤ë°‹ ì •ë³´ì—ì„œ í”Œë˜ê·¸ ìë™ ê°ì§€

    v3.0.1: ì¶”ê°€ëœ ì¤„ë§Œ ë¶„ì„í•˜ì—¬ ì˜¤íƒì§€ ë°©ì§€
    """

    def __init__(self, diff: str, commit_info: Dict):
        self.diff = diff
        # ì¶”ê°€ëœ ì¤„ë§Œ ì¶”ì¶œí•˜ì—¬ ë¶„ì„ (ì‚­ì œëœ ì¤„, ì»¨í…ìŠ¤íŠ¸ ì œì™¸)
        self.added_lines = extract_added_lines(diff)
        self.commit_info = commit_info
        self.message = commit_info.get("message", "").lower()
        self.files = commit_info.get("files_changed", [])

    def detect_all(self) -> Dict[str, bool]:
        """ëª¨ë“  í”Œë˜ê·¸ ê°ì§€"""
        return {
            "has_til": self.detect_til(),
            "has_solution": self.detect_solution(),
            "has_pattern": self.detect_pattern(),
            "has_uncertainty": self.detect_uncertainty(),
            "has_rollback": self.detect_rollback(),
            "has_debt": self.detect_debt(),
            "has_decision": self.detect_decision(),
        }

    def detect_til(self) -> bool:
        """ë°°ìš´ ì  ê°ì§€: ìƒˆë¡œìš´ íŒ¨í„´, í…ŒìŠ¤íŠ¸ ì¶”ê°€, ë¬¸ì„œí™”"""
        patterns = [
            r"def test_",  # ìƒˆ í…ŒìŠ¤íŠ¸ ì¶”ê°€
            r"learned|í•™ìŠµ|ë°°ì›€",  # í‚¤ì›Œë“œ
            r"refactor",  # ë¦¬íŒ©í† ë§ (í•™ìŠµ í¬í•¨)
        ]
        # íŒŒì¼ ê¸°ë°˜ ê°ì§€
        if any("test" in f.lower() for f in self.files):
            return True
        # ì¶”ê°€ëœ ì¤„ ê¸°ë°˜ ê°ì§€
        if any(re.search(p, self.added_lines, re.I) for p in patterns):
            return True
        # ëª…ì‹œì  TIL ì£¼ì„ (ì‹¤ì œ ì£¼ì„ë§Œ)
        return len(extract_real_comments(self.diff, "TIL")) > 0

    def detect_solution(self) -> bool:
        """í•´ê²°ì±… ê°ì§€: ë²„ê·¸ ìˆ˜ì •, ë¬¸ì œ í•´ê²°"""
        patterns = [
            r"í•´ê²°|ìˆ˜ì •|ê³ ì¹¨",  # í•œê¸€ í‚¤ì›Œë“œ
            r"fixed|resolved",  # ì˜ì–´ í‚¤ì›Œë“œ
        ]
        if any(p in self.message for p in ["fix", "bug", "resolve", "í•´ê²°"]):
            return True
        # ì¶”ê°€ëœ ì¤„ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        if any(re.search(p, self.added_lines, re.I) for p in patterns):
            return True
        # ëª…ì‹œì  Solution ì£¼ì„ (ì‹¤ì œ ì£¼ì„ë§Œ)
        return len(extract_real_comments(self.diff, "Solution")) > 0

    def detect_pattern(self) -> bool:
        """íŒ¨í„´ ê°ì§€: ë””ìì¸ íŒ¨í„´, ì•„í‚¤í…ì²˜ íŒ¨í„´"""
        # ë””ìì¸ íŒ¨í„´ í´ë˜ìŠ¤/í•¨ìˆ˜ ì •ì˜ ê°ì§€ (ì¶”ê°€ëœ ì¤„ì—ì„œë§Œ)
        pattern_keywords = [
            r"class\s+\w*(singleton|factory|observer|strategy|decorator|adapter|facade)",
            r"def\s+\w*(factory|observer|strategy)",
        ]
        if any(re.search(p, self.added_lines, re.I) for p in pattern_keywords):
            return True
        # ëª…ì‹œì  Pattern ì£¼ì„ (ì‹¤ì œ ì£¼ì„ë§Œ)
        return len(extract_real_comments(self.diff, "Pattern")) > 0

    def detect_uncertainty(self) -> bool:
        """ë¶ˆí™•ì‹¤ì„± ê°ì§€: ë¯¸í™•ì • ì‚¬í•­, ë¦¬ìŠ¤í¬"""
        # ì‹¤ì œ TODO/FIXME ì£¼ì„ í™•ì¸
        if extract_real_comments(self.diff, "TODO"):
            return True
        if extract_real_comments(self.diff, "FIXME"):
            return True
        if extract_real_comments(self.diff, "RISK"):
            return True
        # ì¶”ê°€ëœ ì¤„ì—ì„œ ë¶ˆí™•ì‹¤ì„± í‚¤ì›Œë“œ ê²€ìƒ‰
        uncertainty_patterns = [
            r"ë¶ˆí™•ì‹¤|uncertain",  # í‚¤ì›Œë“œ
            r"\?\?\?|XXX",  # ì˜ë¬¸ ë§ˆì»¤
            r"maybe|perhaps|ì•„ë§ˆ",  # ë¶ˆí™•ì‹¤ í‘œí˜„
        ]
        return any(re.search(p, self.added_lines, re.I) for p in uncertainty_patterns)

    def detect_rollback(self) -> bool:
        """ë¡¤ë°± ê³„íš ê°ì§€: ë¡¤ë°± ì „ëµ, ë³µêµ¬ ê³„íš"""
        # ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡¤ë°± ê³„íš í•„ìš”
        if any("migration" in f.lower() for f in self.files):
            return True
        # ëª…ì‹œì  Rollback ì£¼ì„
        if extract_real_comments(self.diff, "Rollback"):
            return True
        # ì¶”ê°€ëœ ì¤„ì—ì„œ ë¡¤ë°± ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        rollback_patterns = [
            r"rollback|ë¡¤ë°±",  # í‚¤ì›Œë“œ
            r"revert|ë³µêµ¬|ë˜ëŒë¦¬",  # ë³µêµ¬ í‚¤ì›Œë“œ
            r"backup|ë°±ì—…",  # ë°±ì—… í‚¤ì›Œë“œ
            r"feature.?flag",  # í”¼ì²˜ í”Œë˜ê·¸
        ]
        return any(re.search(p, self.added_lines, re.I) for p in rollback_patterns)

    def detect_debt(self) -> bool:
        """ê¸°ìˆ ë¶€ì±„ ê°ì§€: TODO, FIXME, ì„ì‹œ í•´ê²°ì±…"""
        # ì‹¤ì œ ì£¼ì„ í™•ì¸ (ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì œì™¸)
        if extract_real_comments(self.diff, "TODO"):
            return True
        if extract_real_comments(self.diff, "FIXME"):
            return True
        if extract_real_comments(self.diff, "HACK"):
            return True
        if extract_real_comments(self.diff, "XXX"):
            return True
        # ì¶”ê°€ëœ ì¤„ì—ì„œ ê¸°ìˆ ë¶€ì±„ íŒ¨í„´ ê²€ìƒ‰
        debt_patterns = [
            r"temporary|ì„ì‹œ",  # ì„ì‹œ í‚¤ì›Œë“œ
            r"workaround",  # ìš°íšŒ í•´ê²°ì±…
            r"@pytest\.mark\.skip",  # ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸
            r"#\s*type:\s*ignore",  # íƒ€ì… ë¬´ì‹œ (ì£¼ì„ í˜•íƒœë§Œ)
        ]
        return any(re.search(p, self.added_lines, re.I) for p in debt_patterns)

    def detect_decision(self) -> bool:
        """ì˜ì‚¬ê²°ì • ê°ì§€: ì•„í‚¤í…ì²˜ ë³€ê²½, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€"""
        # requirements.txt ë˜ëŠ” package.json ë³€ê²½
        if any(f in ["requirements.txt", "package.json", "pyproject.toml"] for f in self.files):
            return True
        # ëª…ì‹œì  Decision/Why ì£¼ì„
        if extract_real_comments(self.diff, "Decision"):
            return True
        if extract_real_comments(self.diff, "Why"):
            return True
        # ì¶”ê°€ëœ ì¤„ì—ì„œ ì˜ì‚¬ê²°ì • í‚¤ì›Œë“œ ê²€ìƒ‰
        decision_patterns = [
            r"ì„ íƒ|ê²°ì •|ì±„íƒ",  # í•œê¸€ í‚¤ì›Œë“œ
            r"chose|decided|selected",  # ì˜ì–´ í‚¤ì›Œë“œ
        ]
        return any(re.search(p, self.added_lines, re.I) for p in decision_patterns)


# =============================================================================
# v3.0: AI Context Generator
# =============================================================================


class AIContextGenerator:
    """AI ì»¨í…ìŠ¤íŠ¸ ìë™ ìƒì„±

    v3.0.1: ì‹¤ì œ ì£¼ì„ë§Œ ì¶”ì¶œí•˜ì—¬ ì˜¤íƒì§€ ë°©ì§€
    """

    def __init__(self, commit_info: Dict, diff: str):
        self.commit_info = commit_info
        self.diff = diff
        self.added_lines = extract_added_lines(diff)
        self.message = commit_info.get("message", "")
        self.files = commit_info.get("files_changed", [])

    def generate(self) -> Dict[str, Any]:
        """AI ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        return {
            "summary": self._generate_summary(),
            "next_actions": self._extract_next_actions(),
            "warnings": self._extract_warnings(),
        }

    def _generate_summary(self) -> str:
        """1-2ë¬¸ì¥ ìš”ì•½ ìƒì„±"""
        # ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„ ì‚¬ìš©
        first_line = self.message.split("\n")[0]

        # íƒ€ì… ì¶”ì¶œ
        work_type = "ì‘ì—…"
        if "feat" in first_line.lower():
            work_type = "ê¸°ëŠ¥ ì¶”ê°€"
        elif "fix" in first_line.lower():
            work_type = "ë²„ê·¸ ìˆ˜ì •"
        elif "refactor" in first_line.lower():
            work_type = "ë¦¬íŒ©í† ë§"
        elif "docs" in first_line.lower():
            work_type = "ë¬¸ì„œí™”"
        elif "test" in first_line.lower():
            work_type = "í…ŒìŠ¤íŠ¸"

        files_count = len(self.files)
        return f"{work_type}: {files_count}ê°œ íŒŒì¼ ë³€ê²½. {first_line[:50]}"

    def _extract_next_actions(self) -> List[str]:
        """ë‹¤ìŒ ì•¡ì…˜ ì¶”ì¶œ"""
        actions = []

        # ì‹¤ì œ TODO ì£¼ì„ì—ì„œ ì¶”ì¶œ (ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì œì™¸)
        real_todos = extract_real_comments(self.diff, "TODO")
        for todo in real_todos[:3]:
            actions.append(f"TODO: {todo[:50]}")

        # ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜ ì¶”ë¡ 
        if "feat" in self.message.lower():
            actions.append("í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        if "fix" in self.message.lower():
            actions.append("íšŒê·€ í…ŒìŠ¤íŠ¸ í™•ì¸")
        if not actions:
            actions.append("ì½”ë“œ ë¦¬ë·° ìš”ì²­")

        return actions[:5]  # ìµœëŒ€ 5ê°œ

    def _extract_warnings(self) -> List[str]:
        """ê²½ê³ ì‚¬í•­ ì¶”ì¶œ"""
        warnings = []

        # ì‹¤ì œ FIXME ì£¼ì„ì—ì„œ ì¶”ì¶œ (ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì œì™¸)
        real_fixmes = extract_real_comments(self.diff, "FIXME")
        for fixme in real_fixmes[:3]:
            warnings.append(f"FIXME: {fixme[:50]}")

        # ì¶”ê°€ëœ ì¤„ì—ì„œ ìœ„í—˜ íŒ¨í„´ ê°ì§€
        if re.search(r"rm\s+-rf|DROP\s+TABLE|DELETE\s+FROM", self.added_lines, re.I):
            warnings.append("ìœ„í—˜í•œ ëª…ë ¹ì–´ ê°ì§€ - ì£¼ì˜ í•„ìš”")

        if re.search(r"password|secret|api.?key", self.added_lines, re.I):
            warnings.append("ë¯¼ê° ì •ë³´ ë…¸ì¶œ ê°€ëŠ¥ì„± - í™•ì¸ í•„ìš”")

        if len(self.files) > 20:
            warnings.append(f"ëŒ€ê·œëª¨ ë³€ê²½ ({len(self.files)}ê°œ íŒŒì¼) - ì‹ ì¤‘í•œ ë¦¬ë·° í•„ìš”")

        return warnings[:5]  # ìµœëŒ€ 5ê°œ


# =============================================================================
# v3.0: Section Generator (9 Daily Sections + Conditional Rendering)
# =============================================================================


class SectionGenerator:
    """9ê°œ Daily ì„¹ì…˜ ìƒì„±ê¸° (ì¡°ê±´ë¶€ ë Œë”ë§ ì§€ì›)

    v3.0.1: ì‹¤ì œ ì£¼ì„ë§Œ ì¶”ì¶œí•˜ì—¬ ì˜¤íƒì§€ ë°©ì§€
    """

    def __init__(self, commit_info: Dict, flags: Dict[str, bool], session_state: Dict, diff: str, repo_root: Path):
        self.commit_info = commit_info
        self.flags = flags
        self.session_state = session_state
        self.diff = diff
        self.added_lines = extract_added_lines(diff)
        self.repo_root = repo_root
        self.message = commit_info.get("message", "")
        self.files = commit_info.get("files_changed", [])

    def generate_all_sections(self) -> str:
        """ëª¨ë“  ì„¹ì…˜ ìƒì„± (ì¡°ê±´ë¶€ ë Œë”ë§ ì ìš©)"""
        content = ""

        # 1. Executive Summary (í•­ìƒ)
        content += self._section_executive_summary()

        # 2. Work Timeline (í•­ìƒ)
        content += self._section_work_timeline()

        # 3. TIL (has_til)
        if self.flags.get("has_til"):
            content += self._section_til()

        # 4. Solutions & Patterns (has_solution OR has_pattern)
        if self.flags.get("has_solution") or self.flags.get("has_pattern"):
            content += self._section_solutions_patterns()

        # 5. Uncertainty & Blockers (has_uncertainty)
        if self.flags.get("has_uncertainty"):
            content += self._section_uncertainty()

        # 6. Rollback Plans (has_rollback)
        if self.flags.get("has_rollback"):
            content += self._section_rollback()

        # 7. Related Docs (í•­ìƒ)
        content += self._section_related_docs()

        # 8. Technical Debt Daily (has_debt)
        if self.flags.get("has_debt"):
            content += self._section_tech_debt()

        # 9. Decisions Made (has_decision)
        if self.flags.get("has_decision"):
            content += self._section_decisions()

        return content

    # -------------------------------------------------------------------------
    # Section 1: Executive Summary (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_executive_summary(self) -> str:
        """Executive Summary ì„¹ì…˜"""
        title = self.message.split("\n")[0]
        files_count = len(self.files)

        # ì‘ì—… ìœ í˜• ì¶”ë¡ 
        work_type = "ì‘ì—…"
        if "feat" in title.lower():
            work_type = "ê¸°ëŠ¥ ì¶”ê°€"
        elif "fix" in title.lower():
            work_type = "ë²„ê·¸ ìˆ˜ì •"
        elif "refactor" in title.lower():
            work_type = "ë¦¬íŒ©í† ë§"
        elif "docs" in title.lower():
            work_type = "ë¬¸ì„œí™”"
        elif "test" in title.lower():
            work_type = "í…ŒìŠ¤íŠ¸"

        content = f"\n# {title}\n\n"
        content += "## Executive Summary\n\n"
        content += f"**ì‘ì—… ìœ í˜•**: {work_type}  \n"
        content += f"**ë³€ê²½ íŒŒì¼**: {files_count}ê°œ  \n"

        # ì£¼ìš” ë³€ê²½ ì˜ì—­ (ì¹´í…Œê³ ë¦¬ë³„)
        categories = self._categorize_files()
        if categories:
            areas = [f"{cat} ({count})" for cat, count in categories.items() if count > 0]
            content += f"**ë³€ê²½ ì˜ì—­**: {', '.join(areas[:4])}  \n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 2: Work Timeline (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_work_timeline(self) -> str:
        """Work Timeline ì„¹ì…˜ - session_state.jsonì—ì„œ ì¶”ì¶œ"""
        content = "## Work Timeline\n\n"

        checkpoints = self.session_state.get("checkpoints", [])
        if checkpoints:
            content += "| ì‹œê°„ | ì‘ì—… ë‚´ìš© |\n"
            content += "|------|----------|\n"

            for cp in checkpoints[-10:]:  # ìµœê·¼ 10ê°œë§Œ
                time_str = cp.get("time", "")[:16]  # YYYY-MM-DD HH:MM
                notes = cp.get("notes", "ì²´í¬í¬ì¸íŠ¸")[:50]
                content += f"| {time_str} | {notes} |\n"

            content += "\n"
        else:
            # session_stateê°€ ì—†ìœ¼ë©´ ì»¤ë°‹ ì •ë³´ ê¸°ë°˜
            commit_time = self.commit_info.get("time", "")[:16]
            content += f"- **{commit_time}**: {self.message.split(chr(10))[0][:50]}\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 3: TIL - Today I Learned (has_til)
    # -------------------------------------------------------------------------
    def _section_til(self) -> str:
        """TIL ì„¹ì…˜ - ë°°ìš´ ì  ìë™ ì¶”ì¶œ (êµ¬ì²´ì  ì¸ì‚¬ì´íŠ¸ + ì´ˆë³´ì í•™ìŠµ í¬ì¸íŠ¸)

        v3.2: ì´ˆë³´ìê°€ ë°°ì›Œì•¼ í•  ì ê³¼ ì ìš© ë°©ë²• ì¶”ê°€
        v3.4: ì „ë¬¸ê°€ ê²€ì¦ëœ ë©”íŠ¸ë¦­ ì¶”ê°€ (ì¹´í…Œê³ ë¦¬ + ì ìš© ê°€ëŠ¥ì„±)
              - ì œê±°: difficulty, utility, acquisition_time (ì¸¡ì • ë¶ˆê°€)
              - ì¶”ê°€: category (Pattern/Tool/Concept/Debug/Performance)
              - ì¶”ê°€: applicability (Immediate/Future/General)
        """
        content = "## Today I Learned (TIL)\n\n"

        # v3.4: êµ¬ì¡°í™”ëœ TIL í•­ëª© (ì¹´í…Œê³ ë¦¬ + ì ìš© ê°€ëŠ¥ì„±)
        til_items: List[Dict[str, str]] = []
        beginner_tips = []  # ì´ˆë³´ì í•™ìŠµ í¬ì¸íŠ¸

        # í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê°ì§€ - êµ¬ì²´ì ì¸ íŒŒì¼ëª… í¬í•¨
        test_files = [f for f in self.files if "test" in f.lower()]
        if test_files:
            test_names = [Path(f).stem for f in test_files[:2]]
            til_items.append(
                {
                    "item": f"í…ŒìŠ¤íŠ¸ ì‘ì„±: `{', '.join(test_names)}`",
                    "category": "Tool",
                    "applicability": "Immediate",
                }
            )
            beginner_tips.append(
                "**[ì´ˆë³´ì íŒ]** í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ë©´ ìš”êµ¬ì‚¬í•­ì´ ëª…í™•í•´ì§€ê³ , "
                "ë‚˜ì¤‘ì— ì½”ë“œë¥¼ ìˆ˜ì •í•´ë„ ê¸°ì¡´ ê¸°ëŠ¥ì´ ê¹¨ì§€ì§€ ì•Šì•˜ëŠ”ì§€ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”."
            )

        # ë¦¬íŒ©í† ë§ ê°ì§€ - ë¬´ì—‡ì„ ë¦¬íŒ©í† ë§í–ˆëŠ”ì§€ ì¶”ì¶œ
        if "refactor" in self.message.lower():
            # ë¦¬íŒ©í† ë§ ëŒ€ìƒ ì¶”ì¶œ
            refactor_target = re.search(r"refactor[:\s]+(.+?)(?:\n|$)", self.message, re.I)
            if refactor_target:
                target = refactor_target.group(1).strip()[:40]
                til_items.append(
                    {
                        "item": f"ë¦¬íŒ©í† ë§: {target}",
                        "category": "Pattern",
                        "applicability": "Immediate",
                    }
                )
            else:
                til_items.append(
                    {
                        "item": "ë¦¬íŒ©í† ë§ìœ¼ë¡œ ì½”ë“œ êµ¬ì¡° ê°œì„ ",
                        "category": "Pattern",
                        "applicability": "Immediate",
                    }
                )
            beginner_tips.append(
                "**[ì´ˆë³´ì íŒ]** ë¦¬íŒ©í† ë§ì€ ê¸°ëŠ¥ì€ ê·¸ëŒ€ë¡œ ë‘ê³  ì½”ë“œ êµ¬ì¡°ë§Œ ê°œì„ í•˜ëŠ” ê²ƒì´ì—ìš”. "
                "í•­ìƒ í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ëŠ” ìƒíƒœì—ì„œ ì¡°ê¸ˆì”© ë³€ê²½í•˜ì„¸ìš”."
            )

        # ìƒˆ íŒ¨í„´/í´ë˜ìŠ¤ ê°ì§€ - êµ¬ì²´ì ì¸ í´ë˜ìŠ¤ëª… í¬í•¨
        new_classes = re.findall(r"class\s+(\w+)", self.added_lines)
        if new_classes:
            class_names = list(set(new_classes))[:3]
            til_items.append(
                {
                    "item": f"ìƒˆ í´ë˜ìŠ¤ ì„¤ê³„: `{', '.join(class_names)}`",
                    "category": "Concept",
                    "applicability": "Future",
                }
            )
            beginner_tips.append(
                "**[ì´ˆë³´ì íŒ]** í´ë˜ìŠ¤ëŠ” ê´€ë ¨ëœ ë°ì´í„°ì™€ ê¸°ëŠ¥ì„ ë¬¶ëŠ” ì„¤ê³„ ë„êµ¬ì˜ˆìš”. "
                "í•˜ë‚˜ì˜ í´ë˜ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì±…ì„ë§Œ ê°–ë„ë¡(SRP) ì„¤ê³„í•˜ì„¸ìš”."
            )

        # ìƒˆ í•¨ìˆ˜ ê°ì§€ - êµ¬ì²´ì ì¸ í•¨ìˆ˜ëª… í¬í•¨
        new_funcs = re.findall(r"def\s+(\w+)\s*\(", self.added_lines)
        if new_funcs and not new_classes:  # í´ë˜ìŠ¤ ì—†ì´ í•¨ìˆ˜ë§Œ ìˆëŠ” ê²½ìš°
            func_names = [f for f in set(new_funcs) if not f.startswith("_")][:3]
            if func_names:
                til_items.append(
                    {
                        "item": f"ìƒˆ í•¨ìˆ˜ êµ¬í˜„: `{', '.join(func_names)}`",
                        "category": "Concept",
                        "applicability": "Future",
                    }
                )
                beginner_tips.append(
                    "**[ì´ˆë³´ì íŒ]** í•¨ìˆ˜ ì´ë¦„ì€ ë™ì‚¬ë¡œ ì‹œì‘í•˜ê³ , ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ëª…í™•íˆ ë“œëŸ¬ë‚´ì„¸ìš”. "
                    "í•œ í•¨ìˆ˜ëŠ” í•œ ê°€ì§€ ì¼ë§Œ í•˜ë„ë¡(Single Responsibility) ì‘ì„±í•˜ì„¸ìš”."
                )

        # ì„±ëŠ¥ ìµœì í™” - êµ¬ì²´ì ì¸ ê¸°ë²• ì¶”ì¶œ
        perf_patterns = {
            "cache": ("ìºì‹± ì ìš©ìœ¼ë¡œ ë°˜ë³µ ì—°ì‚° ìµœì†Œí™”", "ê°™ì€ ê³„ì‚°ì„ ì—¬ëŸ¬ ë²ˆ í•˜ì§€ ì•Šë„ë¡ ê²°ê³¼ë¥¼ ì €ì¥í•´ë‘ëŠ” ê¸°ë²•"),
            "memoiz": ("ë©”ëª¨ì´ì œì´ì…˜ìœ¼ë¡œ í•¨ìˆ˜ ê²°ê³¼ ì¬ì‚¬ìš©", "í•¨ìˆ˜ì˜ ì…ë ¥ê°’ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ê¸°ì–µí•´ì„œ ì¬ê³„ì‚° ë°©ì§€"),
            "async": ("ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì‘ë‹µì„± í–¥ìƒ", "I/O ì‘ì—… ì¤‘ ë‹¤ë¥¸ ì‘ì—…ì„ í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒ¨í„´"),
            "parallel": ("ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ê°œì„ ", "ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•´ ì „ì²´ ì‹œê°„ ë‹¨ì¶•"),
            "batch": ("ë°°ì¹˜ ì²˜ë¦¬ë¡œ I/O ìµœì í™”", "ì—¬ëŸ¬ ìš”ì²­ì„ ëª¨ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê¸°ë²•"),
            "lazy": ("ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì´ˆê¸°í™” ì‹œê°„ ë‹¨ì¶•", "í•„ìš”í•  ë•Œê¹Œì§€ ë¡œë”©ì„ ë¯¸ë£¨ëŠ” ìµœì í™” ê¸°ë²•"),
        }
        for pattern, (desc, tip) in perf_patterns.items():
            if pattern in self.added_lines.lower():
                til_items.append(
                    {
                        "item": f"ì„±ëŠ¥ ìµœì í™”: {desc}",
                        "category": "Performance",
                        "applicability": "General",
                    }
                )
                beginner_tips.append(f"**[ì´ˆë³´ì íŒ]** {tip}. ë¨¼ì € ì¸¡ì •í•˜ê³ , ë³‘ëª© ì§€ì ì„ ì°¾ì€ í›„ ìµœì í™”í•˜ì„¸ìš”.")
                break

        # ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
        if "try:" in self.added_lines or "except" in self.added_lines:
            til_items.append(
                {
                    "item": "ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”: ì˜ˆì™¸ ìƒí™©ì— ëŒ€í•œ ì•ˆì •ì„± í™•ë³´",
                    "category": "Debug",
                    "applicability": "General",
                }
            )
            beginner_tips.append(
                "**[ì´ˆë³´ì íŒ]** try-exceptëŠ” ì˜ˆìƒ ê°€ëŠ¥í•œ ì—ëŸ¬ë§Œ ì¡ìœ¼ì„¸ìš”. "
                "`except Exception:`ì²˜ëŸ¼ ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ê²Œ ì¡ìœ¼ë©´ ë²„ê·¸ë¥¼ ìˆ¨ê¸¸ ìˆ˜ ìˆì–´ìš”."
            )

        # íƒ€ì… íŒíŒ… ì¶”ê°€
        if ": str" in self.added_lines or ": int" in self.added_lines or "-> " in self.added_lines:
            til_items.append(
                {
                    "item": "íƒ€ì… íŒíŒ… ì ìš©: ì½”ë“œ ë¬¸ì„œí™” ë° IDE ì§€ì› í–¥ìƒ",
                    "category": "Tool",
                    "applicability": "General",
                }
            )
            beginner_tips.append(
                "**[ì´ˆë³´ì íŒ]** íƒ€ì… íŒíŒ…ì€ í•¨ìˆ˜ê°€ ì–´ë–¤ ê°’ì„ ë°›ê³  ë°˜í™˜í•˜ëŠ”ì§€ ëª…ì‹œí•´ìš”. "
                "IDE ìë™ì™„ì„±ê³¼ ë²„ê·¸ ì¡°ê¸° ë°œê²¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤."
            )

        # ëª…ì‹œì  TIL ì£¼ì„ ì¶”ì¶œ (ì‹¤ì œ ì£¼ì„ë§Œ)
        til_comments = extract_real_comments(self.diff, "TIL")
        for comment in til_comments[:3]:
            til_items.append(
                {
                    "item": comment[:80],
                    "category": self._estimate_til_category(comment),
                    "applicability": "Immediate",
                }
            )

        # v3.4: í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë Œë”ë§
        if til_items:
            content += "| í•™ìŠµ í•­ëª© | ì¹´í…Œê³ ë¦¬ | ì ìš© ê°€ëŠ¥ì„± |\n"
            content += "|----------|---------|-------------|\n"
            for item in til_items[:6]:
                cat_emoji = {
                    "Pattern": "ğŸ”„",
                    "Tool": "ğŸ”§",
                    "Concept": "ğŸ’¡",
                    "Debug": "ğŸ›",
                    "Performance": "âš¡",
                }.get(item["category"], "ğŸ“")
                appl_emoji = {
                    "Immediate": "ğŸ¯ ì´ë²ˆ í”„ë¡œì íŠ¸",
                    "Future": "ğŸ”® ë‹¤ë¥¸ í”„ë¡œì íŠ¸",
                    "General": "ğŸŒ ë²”ìš©",
                }.get(item["applicability"], item["applicability"])
                content += f"| {item['item']} | {cat_emoji} {item['category']} | {appl_emoji} |\n"
            content += "\n"

            # ì´ˆë³´ì í•™ìŠµ í¬ì¸íŠ¸ ì¶”ê°€
            if beginner_tips:
                content += "### ğŸ’¡ ì´ˆë³´ì í•™ìŠµ í¬ì¸íŠ¸\n\n"
                for tip in beginner_tips[:3]:
                    content += f"{tip}\n\n"
        else:
            content += "- (ìë™ ê°ì§€ëœ í•™ìŠµ í•­ëª© ì—†ìŒ - ìˆ˜ë™ ì‘ì„± ê¶Œì¥)\n\n"

        return content

    def _estimate_til_category(self, item: str) -> str:
        """TIL í•­ëª©ì˜ ì¹´í…Œê³ ë¦¬ ì¶”ì • (v3.4)

        Categories: Pattern, Tool, Concept, Debug, Performance
        """
        item_lower = item.lower()

        # Performance í‚¤ì›Œë“œ
        if any(k in item_lower for k in ["ì„±ëŠ¥", "ìµœì í™”", "cache", "async", "parallel", "lazy"]):
            return "Performance"

        # Debug í‚¤ì›Œë“œ
        if any(k in item_lower for k in ["ì—ëŸ¬", "ë²„ê·¸", "ë””ë²„ê·¸", "fix", "debug", "exception"]):
            return "Debug"

        # Pattern í‚¤ì›Œë“œ
        if any(k in item_lower for k in ["íŒ¨í„´", "ë¦¬íŒ©í† ë§", "factory", "singleton", "observer"]):
            return "Pattern"

        # Tool í‚¤ì›Œë“œ
        if any(k in item_lower for k in ["í…ŒìŠ¤íŠ¸", "ë„êµ¬", "ì„¤ì •", "config", "pytest", "lint"]):
            return "Tool"

        # Default: Concept
        return "Concept"

    def _estimate_debt_severity(self, debt_type: str, desc: str) -> int:
        """ê¸°ìˆ ë¶€ì±„ ì‹¬ê°ë„ ì¶”ì • (0-100) (v3.4)

        Args:
            debt_type: ë¶€ì±„ ìœ í˜• (TODO, FIXME, HACK)
            desc: ë¶€ì±„ ì„¤ëª… í…ìŠ¤íŠ¸

        Returns:
            0-100 ë²”ìœ„ì˜ ì‹¬ê°ë„ ì ìˆ˜
        """
        # ìœ í˜•ë³„ ê¸°ë³¸ ì‹¬ê°ë„
        base_severity = {
            "FIXME": 80,  # ë²„ê·¸/ë¬¸ì œ â†’ ë†’ì€ ì‹¬ê°ë„
            "HACK": 70,  # ì„ì‹œ í•´ê²°ì±… â†’ ì¤‘ìƒ ì‹¬ê°ë„
            "TODO": 50,  # êµ¬í˜„ ì˜ˆì • â†’ ì¤‘ê°„ ì‹¬ê°ë„
            "SKIP": 60,  # ìŠ¤í‚µ í…ŒìŠ¤íŠ¸ â†’ ì¤‘ê°„ ì‹¬ê°ë„
            "TYPE": 40,  # íƒ€ì… ë¬´ì‹œ â†’ ë‚®ì€ ì‹¬ê°ë„
        }.get(debt_type, 50)

        desc_lower = desc.lower()

        # ì‹¬ê°ë„ ì¦ê°€ í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["security", "ë³´ì•ˆ", "auth", "ì¸ì¦"]):
            base_severity = min(100, base_severity + 20)
        elif any(k in desc_lower for k in ["critical", "ê¸´ê¸‰", "urgent", "asap"]):
            base_severity = min(100, base_severity + 15)
        elif any(k in desc_lower for k in ["production", "í”„ë¡œë•ì…˜", "ë°°í¬"]):
            base_severity = min(100, base_severity + 10)

        # ì‹¬ê°ë„ ê°ì†Œ í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["later", "ë‚˜ì¤‘ì—", "eventually", "maybe"]):
            base_severity = max(20, base_severity - 10)
        elif any(k in desc_lower for k in ["minor", "ì‚¬ì†Œí•œ", "cosmetic"]):
            base_severity = max(20, base_severity - 15)

        return base_severity

    def _estimate_debt_effort(self, desc: str) -> str:
        """ê¸°ìˆ ë¶€ì±„ ìˆ˜ì • ë…¸ë ¥ ì¶”ì • (T-shirt sizing) (v3.4)

        Args:
            desc: ë¶€ì±„ ì„¤ëª… í…ìŠ¤íŠ¸

        Returns:
            S (< 1ì‹œê°„), M (1-4ì‹œê°„), L (1-3ì¼), XL (> 3ì¼)
        """
        desc_lower = desc.lower()

        # XL í‚¤ì›Œë“œ (ëŒ€ê·œëª¨ ë¦¬íŒ©í† ë§, ì•„í‚¤í…ì²˜ ë³€ê²½)
        if any(k in desc_lower for k in ["refactor entire", "ì „ì²´ ë¦¬íŒ©í† ë§", "architecture", "ì•„í‚¤í…ì²˜"]):
            return "XL"

        # L í‚¤ì›Œë“œ (ë³µì¡í•œ êµ¬í˜„)
        if any(k in desc_lower for k in ["implement", "êµ¬í˜„", "migration", "ë§ˆì´ê·¸ë ˆì´ì…˜", "redesign"]):
            return "L"

        # S í‚¤ì›Œë“œ (ê°„ë‹¨í•œ ìˆ˜ì •)
        if any(k in desc_lower for k in ["typo", "ì˜¤íƒ€", "rename", "ì´ë¦„ ë³€ê²½", "comment", "ì£¼ì„"]):
            return "S"

        # Default: M
        return "M"

    def _estimate_debt_impact(self, desc: str) -> str:
        """ê¸°ìˆ ë¶€ì±„ ëˆ„ì  ë¦¬ìŠ¤í¬ ìœ í˜• ì¶”ì • (v3.4)

        Args:
            desc: ë¶€ì±„ ì„¤ëª… í…ìŠ¤íŠ¸

        Returns:
            Security, Performance, Maintenance, Reliability ì¤‘ í•˜ë‚˜
        """
        desc_lower = desc.lower()

        # Security í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["security", "ë³´ì•ˆ", "auth", "ì¸ì¦", "xss", "injection", "ê¶Œí•œ"]):
            return "Security"

        # Performance í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["performance", "ì„±ëŠ¥", "slow", "ëŠë¦¼", "optimize", "ìµœì í™”", "cache"]):
            return "Performance"

        # Reliability í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["test", "í…ŒìŠ¤íŠ¸", "error", "ì—ëŸ¬", "exception", "crash", "fail"]):
            return "Reliability"

        # Default: Maintenance
        return "Maintenance"

    def _estimate_decision_scope(self, desc: str) -> str:
        """ì˜ì‚¬ê²°ì • ë²”ìœ„ ì¶”ì • (v3.4)

        Args:
            desc: ê²°ì • ì„¤ëª… í…ìŠ¤íŠ¸

        Returns:
            Local (ë‹¨ì¼ íŒŒì¼), Module (ëª¨ë“ˆ), System (ì‹œìŠ¤í…œ ì „ì²´)
        """
        desc_lower = desc.lower()

        # System í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["architecture", "ì•„í‚¤í…ì²˜", "ì „ì²´", "system", "global", "all"]):
            return "System"

        # Local í‚¤ì›Œë“œ
        if any(k in desc_lower for k in ["local", "í•¨ìˆ˜", "function", "method", "ë³€ìˆ˜", "variable"]):
            return "Local"

        # Default: Module
        return "Module"

    # -------------------------------------------------------------------------
    # Section 4: Solutions & Patterns (has_solution OR has_pattern)
    # -------------------------------------------------------------------------
    def _section_solutions_patterns(self) -> str:
        """Solutions & Patterns ì„¹ì…˜

        v3.2: ì´ˆë³´ìë¥¼ ìœ„í•œ íŒ¨í„´ ì„¤ëª… ë° ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ì§€ ê°€ì´ë“œ ì¶”ê°€
        """
        content = "## Solutions & Patterns\n\n"

        # ë””ìì¸ íŒ¨í„´ ì„¤ëª… ì‚¬ì „ (ì´ˆë³´ììš©)
        pattern_explanations = {
            "Singleton": (
                "ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì²´ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ê°€ í•˜ë‚˜ë§Œ ì¡´ì¬í•´ì•¼ í•  ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì„¤ì • ê´€ë¦¬ì, ë¡œê±°, DB ì—°ê²° í’€",
            ),
            "Factory": (
                "ê°ì²´ ìƒì„± ë¡œì§ì„ ë¶„ë¦¬í•´ì„œ ìœ ì—°ì„±ì„ ë†’ì¼ ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ë‹¤ì–‘í•œ íƒ€ì…ì˜ ê°ì²´ë¥¼ ì¡°ê±´ì— ë”°ë¼ ìƒì„±í•  ë•Œ",
            ),
            "Observer": (
                "í•œ ê°ì²´ì˜ ìƒíƒœ ë³€í™”ë¥¼ ì—¬ëŸ¬ ê°ì²´ì—ê²Œ ì•Œë¦´ ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ, êµ¬ë…/ë°œí–‰ íŒ¨í„´",
            ),
            "Strategy": (
                "ì•Œê³ ë¦¬ì¦˜ì„ ëŸ°íƒ€ì„ì— êµì²´í•  ìˆ˜ ìˆê²Œ í•  ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì •ë ¬ ë°©ì‹, ê²°ì œ ë°©ì‹ ì„ íƒ",
            ),
            "Decorator": (
                "ê¸°ì¡´ í´ë˜ìŠ¤ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê¸°ëŠ¥ì„ ì¶”ê°€í•  ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ë¡œê¹…, ìºì‹±, ê¶Œí•œ ì²´í¬ ë˜í¼",
            ),
            "Adapter": (
                "í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì—°ê²°í•  ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë‚´ë¶€ ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶œ ë•Œ",
            ),
            "Facade": (
                "ë³µì¡í•œ ì„œë¸Œì‹œìŠ¤í…œì„ ë‹¨ìˆœí•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ìŒ€ ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì—¬ëŸ¬ APIë¥¼ í•˜ë‚˜ì˜ ê°„ë‹¨í•œ í•¨ìˆ˜ë¡œ ë¬¶ì„ ë•Œ",
            ),
            "Proxy": (
                "ê°ì²´ì— ëŒ€í•œ ì ‘ê·¼ì„ ì œì–´í•˜ê±°ë‚˜ ì¶”ê°€ ë™ì‘ì„ ë„£ì„ ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ì§€ì—° ë¡œë”©, ì ‘ê·¼ ê¶Œí•œ ì²´í¬, ë¡œê¹…",
            ),
            "Mixin": (
                "ë‹¤ì¤‘ ìƒì† ì—†ì´ ì—¬ëŸ¬ í´ë˜ìŠ¤ì— ê¸°ëŠ¥ì„ ì¶”ê°€í•  ë•Œ ì‚¬ìš©",
                "ì˜ˆ: ê³µí†µ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ ê³µìœ ",
            ),
        }

        # í•´ê²°ì±… ì¶”ì¶œ (v3.5: ìë™ ì¶”ì¶œ ë¡œì§ ê°•í™”)
        if self.flags.get("has_solution"):
            content += "### Solutions\n\n"
            extracted_solutions = []

            # 1. ì‹¤ì œ Solution ì£¼ì„ ì¶”ì¶œ
            solutions = extract_real_comments(self.diff, "Solution")
            if solutions:
                for sol in solutions[:5]:
                    extracted_solutions.append(sol[:80])

            # 2. ì»¤ë°‹ ë©”ì‹œì§€ì—ì„œ í•´ê²°ì±… íŒ¨í„´ ìë™ ì¶”ì¶œ (v3.5)
            fix_patterns = {
                r"fix(?:ed|es)?[:\s]+(.+?)(?:\n|$)": "ë²„ê·¸ ìˆ˜ì •",
                r"resolve[ds]?[:\s]+(.+?)(?:\n|$)": "ì´ìŠˆ í•´ê²°",
                r"(?:ìˆ˜ì •|ê³ ì¹¨|í•´ê²°)[:\s]+(.+?)(?:\n|$)": "ë¬¸ì œ í•´ê²°",
                r"by[:\s]+(.+?)(?:\n|$)": "í•´ê²° ë°©ë²•",
            }
            for pattern, prefix in fix_patterns.items():
                matches = re.findall(pattern, self.message, re.I)
                for match in matches[:2]:
                    if len(match) > 5:
                        extracted_solutions.append(f"{prefix}: {match[:60]}")

            # 3. diffì—ì„œ ìˆ˜ì • íŒ¨í„´ ìë™ ë¶„ì„ (v3.5)
            code_fix_patterns = {
                r"[-]\s*.*(?:bug|error|issue).*\n[+]\s*(.+)": "ì½”ë“œ ìˆ˜ì •",
                r"[-]\s*#.*(?:TODO|FIXME).*\n[+]\s*(.+)": "ê¸°ìˆ ë¶€ì±„ í•´ê²°",
                r"[+]\s*try:.*\n[+]\s*(.+?)\n[+]\s*except": "ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€",
            }
            for pattern, prefix in code_fix_patterns.items():
                matches = re.findall(pattern, self.diff, re.I | re.MULTILINE)
                for match in matches[:2]:
                    if len(match) > 10:
                        extracted_solutions.append(f"{prefix}: {match[:50]}...")

            # ê²°ê³¼ ë Œë”ë§
            if extracted_solutions:
                for sol in extracted_solutions[:5]:
                    content += f"- {sol}\n"
            elif "fix" in self.message.lower():
                content += f"- {self.message.split(chr(10))[0]}\n"
            else:
                content += "- (Solution ì£¼ì„ì„ ì¶”ê°€í•˜ì—¬ í•´ê²°ì±… ê¸°ë¡ ê¶Œì¥)\n"
            content += "\n"

            # ë°”ì´ë¸Œì½”ë”© í•™ìŠµ ê°€ì´ë“œ (v3.5 ì¶”ê°€)
            content += "### ğŸ¯ ë°”ì´ë¸Œì½”ë”© ì„±ì¥ ê°€ì´ë“œ (ì´ˆë³´ììš©)\n\n"
            content += "**[í”„ë¡¬í”„íŠ¸ íŒ]** AIì—ê²Œ ëª…í™•í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”:\n"
            content += "- í˜„ì¬ ìƒí™© â†’ ì›í•˜ëŠ” ê²°ê³¼ â†’ ì œì•½ ì¡°ê±´ ìˆœìœ¼ë¡œ ì„¤ëª…\n"
            content += '- ì˜ˆ: "FastAPIì—ì„œ 401 ì—ëŸ¬ ë°œìƒ. JWT í† í° ê²€ì¦ ë¡œì§ ìˆ˜ì • í•„ìš”. Python 3.11 ì‚¬ìš© ì¤‘"\n\n'

            content += "**[SW ì„¤ê³„ ì›ì¹™]** ê²€ì¦ëœ ì´ë¡  í•™ìŠµ ì¶”ì²œ:\n"
            content += "- **SOLID ì›ì¹™**: ë‹¨ì¼ ì±…ì„(S), ê°œë°©-íì‡„(O), ë¦¬ìŠ¤ì½”í”„ ì¹˜í™˜(L), ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬(I), ì˜ì¡´ì„± ì—­ì „(D)\n"
            content += "- **DRY/KISS/YAGNI**: ë°˜ë³µ ê¸ˆì§€, ë‹¨ìˆœí•˜ê²Œ, í•„ìš”í•  ë•Œë§Œ êµ¬í˜„\n"
            content += '- ğŸ“š ì¶”ì²œ: "Clean Code" (Robert C. Martin), "Refactoring" (Martin Fowler)\n\n'

            content += "**[ì˜¤ë¥˜ ì •ì • í”„ë¡œì„¸ìŠ¤]** ì²´ê³„ì  ë””ë²„ê¹… 5ë‹¨ê³„:\n"
            content += "1. ì—ëŸ¬ ë©”ì‹œì§€ ì •í™•íˆ ì½ê¸° (ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ë¶„ì„)\n"
            content += "2. ìµœì†Œ ì¬í˜„ ì¼€ì´ìŠ¤ ë§Œë“¤ê¸°\n"
            content += "3. ê°€ì„¤ ìˆ˜ë¦½ â†’ ê²€ì¦ â†’ ë°˜ë³µ\n"
            content += "4. ìˆ˜ì • í›„ íšŒê·€ í…ŒìŠ¤íŠ¸\n"
            content += "5. í•´ê²°ì±… ë¬¸ì„œí™” (ë‹¤ìŒì— ì¬ì‚¬ìš©)\n\n"

            content += "**[í…ŒìŠ¤íŠ¸ ì „ëµ]** TDD/BDD ì ‘ê·¼ë²•:\n"
            content += "- í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‘ì„± â†’ ì‹¤íŒ¨ í™•ì¸ â†’ ì½”ë“œ ì‘ì„± â†’ í†µê³¼ í™•ì¸ â†’ ë¦¬íŒ©í† ë§\n"
            content += "- ê²½ê³„ê°’, ì—£ì§€ ì¼€ì´ìŠ¤, ì˜ˆì™¸ ìƒí™© ìš°ì„  í…ŒìŠ¤íŠ¸\n"
            content += '- ğŸ“š ì¶”ì²œ: "Test-Driven Development" (Kent Beck)\n\n'

        # íŒ¨í„´ ì¶”ì¶œ
        if self.flags.get("has_pattern"):
            content += "### Patterns Applied\n\n"
            # í´ë˜ìŠ¤/í•¨ìˆ˜ ì •ì˜ì—ì„œ íŒ¨í„´ëª… ì¶”ì¶œ
            pattern_defs = re.findall(
                r"class\s+(\w*(?:Singleton|Factory|Observer|Strategy|Decorator|Adapter|Facade|Mixin|Proxy))",
                self.added_lines,
                re.I,
            )
            # ì‹¤ì œ Pattern ì£¼ì„ë§Œ ì¶”ì¶œ
            pattern_comments = extract_real_comments(self.diff, "Pattern")

            detected_patterns = []
            if pattern_defs:
                for p in set(pattern_defs):
                    content += f"- **{p}** í´ë˜ìŠ¤\n"
                    # íŒ¨í„´ëª…ì—ì„œ íŒ¨í„´ íƒ€ì… ì¶”ì¶œ
                    for pattern_type in pattern_explanations:
                        if pattern_type.lower() in p.lower():
                            detected_patterns.append(pattern_type)
                            break
            if pattern_comments:
                for pc in pattern_comments[:3]:
                    content += f"- {pc[:80]}\n"
            if not pattern_defs and not pattern_comments:
                content += "- (Pattern ì£¼ì„ì„ ì¶”ê°€í•˜ì—¬ íŒ¨í„´ ê¸°ë¡ ê¶Œì¥)\n"
            content += "\n"

            # ì´ˆë³´ìë¥¼ ìœ„í•œ íŒ¨í„´ ì„¤ëª… ì¶”ê°€
            if detected_patterns:
                content += "### ğŸ’¡ íŒ¨í„´ ì´í•´í•˜ê¸° (ì´ˆë³´ì ê°€ì´ë“œ)\n\n"
                for pattern_type in set(detected_patterns):
                    if pattern_type in pattern_explanations:
                        when_to_use, example = pattern_explanations[pattern_type]
                        content += f"**{pattern_type} íŒ¨í„´**\n"
                        content += f"- **ì–¸ì œ ì‚¬ìš©?** {when_to_use}\n"
                        content += f"- **ì‹¤ì œ ì˜ˆì‹œ:** {example}\n"
                        content += "- **ì£¼ì˜ì :** íŒ¨í„´ì„ ìœ„í•œ íŒ¨í„´ì€ í”¼í•˜ì„¸ìš”. " "ë¬¸ì œê°€ ëª…í™•í•  ë•Œë§Œ ì ìš©í•˜ì„¸ìš”.\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 5: Uncertainty Map (has_uncertainty)
    # v3.1: A + B ì¡°í•© - ê¸°ìˆ ì  ë¶ˆí™•ì‹¤ì„± + AI ë©”íƒ€ì¸ì§€ + Blockers
    # -------------------------------------------------------------------------
    def _section_uncertainty(self) -> str:
        """Uncertainty Map ì„¹ì…˜ - ë‹¤ì¸µ ë¶ˆí™•ì‹¤ì„± ë¶„ì„

        êµ¬ì„±:
        1. ğŸ” ê¸°ìˆ ì  ë¶ˆí™•ì‹¤ì„± (Option A): Git diff ìë™ ë¶„ì„
        2. ğŸ¤” AI ë©”íƒ€ì¸ì§€ (Option B): ì„¸ì…˜ ê¸°ë°˜ ìê¸° ì„±ì°°
        3. ğŸš§ Blockers: ì‘ì—… ì°¨ë‹¨ ìš”ì†Œ
        """
        content = "## Uncertainty Map\n\n"

        # =====================================================================
        # Part 1: ğŸ” ê¸°ìˆ ì  ë¶ˆí™•ì‹¤ì„± (Option A - Git diff ê¸°ë°˜ ìë™ ë¶„ì„)
        # =====================================================================
        content += "### ğŸ” ê¸°ìˆ ì  ë¶ˆí™•ì‹¤ì„± (ìë™ ë¶„ì„)\n\n"

        tech_uncertainties = []

        # 1-1. ì£¼ì„ ê¸°ë°˜ ëª…ì‹œì  ë¶ˆí™•ì‹¤ì„±
        todos = extract_real_comments(self.diff, "TODO")
        tech_uncertainties.extend([f"**TODO**: {t[:60]}" for t in todos[:3]])

        fixmes = extract_real_comments(self.diff, "FIXME")
        tech_uncertainties.extend([f"**FIXME**: {f[:60]}" for f in fixmes[:2]])

        risks = extract_real_comments(self.diff, "RISK")
        tech_uncertainties.extend([f"**RISK**: {r[:60]}" for r in risks[:2]])

        # 1-2. ë³µì¡ë„ ê¸°ë°˜ ì¶”ë¡  (Option A ê°•í™”)
        complexity_indicators = {
            r"if.*if.*if": "âš ï¸ ì¤‘ì²© ì¡°ê±´ë¬¸ 3ë‹¨ê³„ - ë¡œì§ ë‹¨ìˆœí™” ê²€í†  í•„ìš”",
            r"for.*for": "âš ï¸ ì¤‘ì²© ë£¨í”„ - O(nÂ²) ì„±ëŠ¥ ì˜í–¥ í™•ì¸ í•„ìš”",
            r"try.*try": "âš ï¸ ì¤‘ì²© ì˜ˆì™¸ ì²˜ë¦¬ - ì—ëŸ¬ íë¦„ ì •ë¦¬ í•„ìš”",
            r"except\s*:": "âš ï¸ ê´‘ë²”ìœ„ ì˜ˆì™¸ ì²˜ë¦¬ - êµ¬ì²´ì  ì˜ˆì™¸ íƒ€ì… ê¶Œì¥",
        }
        for pattern, msg in complexity_indicators.items():
            if re.search(pattern, self.added_lines, re.DOTALL):
                tech_uncertainties.append(msg)

        # 1-3. ë³€ê²½ ê·œëª¨ ê¸°ë°˜ ì¶”ë¡  (Option A ê°•í™”)
        lines_added = len(self.added_lines.split("\n"))
        files_changed = len(self.files)

        if lines_added > 200:
            tech_uncertainties.append(f"ğŸ“Š ëŒ€ê·œëª¨ ë³€ê²½ ({lines_added}ì¤„) - ëª¨ë“  ì—£ì§€ ì¼€ì´ìŠ¤ ê³ ë ¤í–ˆëŠ”ì§€ ê²€í†  í•„ìš”")
        if files_changed > 5:
            tech_uncertainties.append(f"ğŸ“ ë‹¤ì¤‘ íŒŒì¼ ë³€ê²½ ({files_changed}ê°œ) - íŒŒì¼ ê°„ ì¼ê´€ì„± í™•ì¸ í•„ìš”")

        # 1-4. ì™¸ë¶€ ì˜ì¡´ì„± ì¶”ê°€ ê°ì§€
        new_imports = re.findall(r"(?:import|from)\s+(\w+)", self.added_lines)
        new_deps = re.findall(r'"([^"]+)":\s*"[\^~]?\d', self.added_lines)  # package.json
        if new_imports or new_deps:
            dep_names = list(set(new_imports[:3] + new_deps[:2]))
            if dep_names:
                tech_uncertainties.append(f"ğŸ“¦ ì™¸ë¶€ ì˜ì¡´ì„± ì¶”ê°€: `{', '.join(dep_names)}` - í˜¸í™˜ì„± í™•ì¸ í•„ìš”")

        # 1-5. í…ŒìŠ¤íŠ¸ ë¯¸ì‘ì„± ì‹ ê·œ ì½”ë“œ
        new_funcs = re.findall(r"def\s+(\w+)\s*\(", self.added_lines)
        new_classes = re.findall(r"class\s+(\w+)", self.added_lines)
        test_files = [f for f in self.files if "test" in f.lower()]

        if (new_funcs or new_classes) and not test_files:
            items = [f for f in set(new_funcs) if not f.startswith("_")][:2]
            items += [c for c in set(new_classes)][:1]
            if items:
                tech_uncertainties.append(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë¯¸ì‘ì„±: `{', '.join(items)}` - í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê¶Œì¥")

        # 1-6. ë¶ˆí™•ì‹¤ì„± í‚¤ì›Œë“œ (ì½”ë“œ ë‚´ maybe, ì•„ë§ˆ ë“±)
        uncertainty_keywords = []
        for line in self.added_lines.split("\n"):
            if re.search(r"maybe|perhaps|ì•„ë§ˆ|possibly|\?\?\?|ì„ì‹œ|temp", line, re.I):
                cleaned = line.strip()[:40]
                if cleaned and not cleaned.startswith("#"):
                    uncertainty_keywords.append(cleaned)

        if uncertainty_keywords:
            tech_uncertainties.append(f"â“ ë¶ˆí™•ì‹¤í•œ êµ¬í˜„ ê°ì§€: `{uncertainty_keywords[0][:30]}...`")

        # ê¸°ìˆ ì  ë¶ˆí™•ì‹¤ì„± ì¶œë ¥
        if tech_uncertainties:
            for item in tech_uncertainties[:6]:
                content += f"- {item}\n"
        else:
            content += "> âœ… ì½”ë“œ ë¶„ì„ì—ì„œ ì£¼ìš” ë¶ˆí™•ì‹¤ì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"

        content += "\n"

        # =====================================================================
        # Part 2: ğŸ¤” AI ë©”íƒ€ì¸ì§€ v3.3 (ì •ëŸ‰ì  ì§€í‘œ + ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤)
        # =====================================================================
        content += "### ğŸ¤” AI ë©”íƒ€ì¸ì§€ (ì‹ ë¢°ë„ ê¸°ë°˜)\n\n"

        ai_meta = load_ai_metacognition()
        all_priority_items = []  # ìš°ì„ ìˆœìœ„ ì •ë ¬ìš©

        if ai_meta:
            # 2-1. ê°€ì¥ ëœ ìì‹ ìˆëŠ” ë¶€ë¶„ (ì‹ ë¢°ë„ %)
            least_confident = ai_meta.get("least_confident", [])
            if least_confident:
                content += "**1. ğŸ”´ ëœ ìì‹ ìˆëŠ” ë¶€ë¶„** (ì‹ ë¢°ë„: êµ¬í˜„ ì •í™•ì„± í™•ì‹  ìˆ˜ì¤€)\n\n"
                content += "| í•­ëª© | ì‹ ë¢°ë„ | ë³´ì™„ ì‹œ ê¸°ëŒ€íš¨ê³¼ |\n"
                content += "|------|--------|------------------|\n"
                for item in least_confident[:4]:
                    if isinstance(item, dict):
                        name = item.get("item", str(item))
                        conf = item.get("confidence", 40)
                        effect = item.get("expected_effect", "ì •í™•ë„ í–¥ìƒ")
                    else:
                        name = str(item)[:40]
                        conf = self._estimate_confidence(name)
                        effect = self._estimate_effect("confidence", name)
                    content += f"| {name} | **{conf}%** | {effect} |\n"
                    all_priority_items.append(
                        {
                            "category": "ì‹ ë¢°ë„",
                            "item": name,
                            "score": conf,
                            "urgency": "high" if conf < 40 else "medium" if conf < 60 else "low",
                            "effect": effect,
                        }
                    )
                content += "\n"

            # 2-2. ë‹¨ìˆœí™”í•œ ê°€ì • (ìœ íš¨í™•ë¥  %)
            simplifications = ai_meta.get("simplifications", [])
            if simplifications:
                content += "**2. ğŸŸ¡ ë‹¨ìˆœí™”í•œ ê°€ì •** (ìœ íš¨í™•ë¥ : ê°€ì •ì´ í˜„ì‹¤ì—ì„œ ì„±ë¦½í•  í™•ë¥ )\n\n"
                content += "| ê°€ì • | ìœ íš¨í™•ë¥  | ê²€ì¦ ì‹œ ê¸°ëŒ€íš¨ê³¼ |\n"
                content += "|------|----------|------------------|\n"
                for item in simplifications[:4]:
                    if isinstance(item, dict):
                        name = item.get("item", str(item))
                        validity = item.get("validity", 55)
                        effect = item.get("expected_effect", "ì„¤ê³„ ì•ˆì •ì„± í™•ë³´")
                    else:
                        name = str(item)[:40]
                        validity = self._estimate_validity(name)
                        effect = self._estimate_effect("validity", name)
                    content += f"| {name} | **{validity}%** | {effect} |\n"
                    all_priority_items.append(
                        {
                            "category": "ìœ íš¨í™•ë¥ ",
                            "item": name,
                            "score": validity,
                            "urgency": "high" if validity < 40 else "medium" if validity < 60 else "low",
                            "effect": effect,
                        }
                    )
                content += "\n"

            # 2-3. ì˜ê²¬ ë³€ê²½ ê°€ëŠ¥ ì§ˆë¬¸ (ë³€ê²½í™•ë¥  %)
            opinion_changers = ai_meta.get("opinion_changers", [])
            if opinion_changers:
                content += "**3. ğŸŸ  ì˜ê²¬ ë³€ê²½ ê°€ëŠ¥ ì§ˆë¬¸** (ë³€ê²½í™•ë¥ : ê²€ì¦ ì‹œ ì„¤ê³„ê°€ ë°”ë€” í™•ë¥ )\n\n"
                content += "| ì§ˆë¬¸ | ë³€ê²½í™•ë¥  | ì¡°ê¸° ê²€ì¦ íš¨ê³¼ |\n"
                content += "|------|----------|----------------|\n"
                for item in opinion_changers[:4]:
                    if isinstance(item, dict):
                        name = item.get("item", str(item))
                        change_prob = item.get("change_prob", 65)
                        effect = item.get("expected_effect", "ì¬ì‘ì—… ë°©ì§€")
                    else:
                        name = str(item)[:40]
                        change_prob = self._estimate_change_prob(name)
                        effect = self._estimate_effect("change", name)
                    content += f"| {name} | **{change_prob}%** | {effect} |\n"
                    all_priority_items.append(
                        {
                            "category": "ë³€ê²½í™•ë¥ ",
                            "item": name,
                            "score": 100 - change_prob,  # ë†’ì€ ë³€ê²½í™•ë¥  = ë‚®ì€ ì•ˆì •ì„±
                            "urgency": "high" if change_prob > 70 else "medium" if change_prob > 50 else "low",
                            "effect": effect,
                        }
                    )
                content += "\n"

            # 2-4. ë³´ì™„ í•„ìš” ì˜ì—­ (ì™„ì„±ë„ + ê¸´ê¸‰ë„ 2ì°¨ì›)
            areas_to_improve = ai_meta.get("areas_to_improve", [])
            if areas_to_improve:
                content += "**4. ğŸ”µ ë³´ì™„ í•„ìš” ì˜ì—­** (ì™„ì„±ë„ Ã— ê¸´ê¸‰ë„ 2ì°¨ì› ë¶„ì„)\n\n"
                content += "| ì˜ì—­ | ì™„ì„±ë„ | ê¸´ê¸‰ë„ | ìš°ì„ ìˆœìœ„ | ë³´ì™„ ì‹œ ê¸°ëŒ€íš¨ê³¼ |\n"
                content += "|------|--------|--------|----------|------------------|\n"
                for item in areas_to_improve[:5]:
                    if isinstance(item, dict):
                        name = item.get("item", str(item))
                        completeness = item.get("completeness", 45)
                        urgency = item.get("urgency", "medium")
                        remaining = 100 - completeness
                        effect = item.get("expected_effect", f"+{remaining}% ê¸°ëŠ¥ ì™„ì„±")
                    else:
                        name = str(item)[:35]
                        completeness = self._estimate_completeness(name)
                        urgency = self._estimate_urgency(name, completeness)
                        effect = self._estimate_effect("completeness", name)

                    # ìš°ì„ ìˆœìœ„ ê³„ì‚°: ì™„ì„±ë„ ë‚®ê³  ê¸´ê¸‰ë„ ë†’ìœ¼ë©´ ìµœìš°ì„ 
                    urgency_score = {"high": 3, "medium": 2, "low": 1}.get(urgency.lower(), 2)
                    priority_score = (100 - completeness) * urgency_score
                    priority_label = "ğŸš¨ ì¦‰ì‹œ" if priority_score > 150 else "âš¡ ìš°ì„ " if priority_score > 100 else "ğŸ“‹ ê³„íš"

                    urgency_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(urgency.lower(), "ğŸŸ¡")
                    content += (
                        f"| {name} | {completeness}% | {urgency_icon} {urgency.capitalize()} | {priority_label} | {effect} |\n"
                    )

                    all_priority_items.append(
                        {
                            "category": "ì™„ì„±ë„",
                            "item": name,
                            "score": completeness,
                            "urgency": urgency.lower(),
                            "priority_score": priority_score,
                            "effect": effect,
                        }
                    )
                content += "\n"

                # 2ì°¨ì› í•´ì„ ê°€ì´ë“œ (ì´ˆë³´ììš©)
                content += "**ğŸ’¡ ìš°ì„ ìˆœìœ„ íŒë‹¨ ê¸°ì¤€:**\n"
                content += "```\n"
                content += "              ê¸´ê¸‰ë„\n"
                content += "         Low    Medium    High\n"
                content += "ì™„ì„±ë„  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
                content += " High   â”‚ ê´€ì°°   â”‚ ê³„íš   â”‚ ì¦‰ì‹œ   â”‚\n"
                content += " (>70%) â”‚        â”‚        â”‚ ë§ˆë¬´ë¦¬ â”‚\n"
                content += "        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
                content += " Medium â”‚ ë°±ë¡œê·¸ â”‚ ë‹¤ìŒ   â”‚ ìš°ì„    â”‚\n"
                content += " (40-70)â”‚ ë“±ë¡   â”‚ ìŠ¤í”„ë¦°íŠ¸â”‚ ì²˜ë¦¬   â”‚\n"
                content += "        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
                content += " Low    â”‚ ì¥ê¸°   â”‚ ë‹¨ê¸°   â”‚ ğŸš¨     â”‚\n"
                content += " (<40%) â”‚ ë¡œë“œë§µ â”‚ ê³„íš   â”‚ í¬ë¦¬í‹°ì»¬â”‚\n"
                content += "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
                content += "```\n\n"

            # ì „ì²´ ìš°ì„ ìˆœìœ„ ì •ë ¬ ìš”ì•½
            if all_priority_items:
                content += "**ğŸ“Š ì „ì²´ ë©”íƒ€ì¸ì§€ ìš°ì„ ìˆœìœ„ (ì ìˆ˜ ê¸°ì¤€ ì •ë ¬)**\n\n"
                # ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ (ë¶ˆí™•ì‹¤í• ìˆ˜ë¡) ìš°ì„ ìˆœìœ„ ë†’ìŒ
                sorted_items = sorted(
                    all_priority_items,
                    key=lambda x: ({"high": 0, "medium": 1, "low": 2}.get(x.get("urgency", "medium"), 1), x.get("score", 50)),
                )

                content += "| ìˆœìœ„ | ì¹´í…Œê³ ë¦¬ | í•­ëª© | ì ìˆ˜ | ê¸´ê¸‰ë„ | ì¡°ì¹˜ |\n"
                content += "|------|----------|------|------|--------|------|\n"
                for idx, item in enumerate(sorted_items[:8], 1):
                    urgency = item.get("urgency", "medium")
                    urgency_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(urgency, "ğŸŸ¡")
                    action = "ì¦‰ì‹œ ê²€ì¦" if urgency == "high" else "ëª¨ë‹ˆí„°ë§" if urgency == "medium" else "ê´€ì°°"
                    cat = item["category"]
                    name = item["item"][:25]
                    score = item["score"]
                    content += f"| {idx} | {cat} | {name} | {score}% | {urgency_icon} | {action} |\n"
                content += "\n"

            if not any([least_confident, simplifications, opinion_changers, areas_to_improve]):
                content += "> AI ì„¸ì…˜ ë©”íƒ€ì¸ì§€ê°€ ë¡œë“œë˜ì—ˆìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\n\n"
        else:
            content += "> ğŸ’¡ AI ì„¸ì…˜ ë©”íƒ€ì¸ì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            content += "> `save_ai_metacognition()` í•¨ìˆ˜ë¡œ AI ì‘ì—… ì¤‘ ë©”íƒ€ì¸ì§€ë¥¼ ì €ì¥í•˜ë©´ ìë™ í¬í•¨ë©ë‹ˆë‹¤.\n\n"
            content += self._generate_default_metacognition()

        # =====================================================================
        # Part 3: ğŸš§ Blockers (ì‘ì—… ì°¨ë‹¨ ìš”ì†Œ)
        # =====================================================================
        content += "### ğŸš§ Blockers\n\n"

        blockers = []

        # 3-1. ì£¼ì„ ê¸°ë°˜ Blockers
        blocked_comments = extract_real_comments(self.diff, "BLOCKED")
        blockers.extend([f"ğŸ”´ {b[:60]}" for b in blocked_comments[:2]])

        decision_comments = extract_real_comments(self.diff, "DECISION")
        blockers.extend([f"ğŸŸ¡ ê²°ì • ëŒ€ê¸°: {d[:50]}" for d in decision_comments[:2]])

        waiting_comments = extract_real_comments(self.diff, "WAITING")
        blockers.extend([f"ğŸŸ  ëŒ€ê¸° ì¤‘: {w[:50]}" for w in waiting_comments[:2]])

        # 3-2. AI ì„¸ì…˜ Blockers
        ai_blockers = ai_meta.get("blockers", [])
        for b in ai_blockers[:3]:
            blockers.append(f"ğŸ”µ {b}")

        # 3-3. ì™¸ë¶€ ì˜ì¡´ì„± ëŒ€ê¸°
        if re.search(r"#.*ì™¸ë¶€.*ëŒ€ê¸°|#.*external.*wait", self.added_lines, re.I):
            blockers.append("ğŸŸ£ ì™¸ë¶€ ì‹œìŠ¤í…œ ì‘ë‹µ ëŒ€ê¸° ì¤‘")

        # Blockers ì¶œë ¥
        if blockers:
            for item in blockers[:5]:
                content += f"- {item}\n"
        else:
            content += "> âœ… í˜„ì¬ ì°¨ë‹¨ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # v3.3 Metacognition Helper Methods
    # -------------------------------------------------------------------------
    def _estimate_confidence(self, item: str) -> int:
        """í•­ëª©ëª…ì—ì„œ ì‹ ë¢°ë„ ì¶”ì • (íœ´ë¦¬ìŠ¤í‹±)"""
        item_lower = item.lower()
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„ ì¶”ì •
        if any(k in item_lower for k in ["regex", "ì •ê·œ", "íŒ¨í„´", "edge", "ì—£ì§€"]):
            return 35
        elif any(k in item_lower for k in ["ì„±ëŠ¥", "performance", "ìµœì í™”"]):
            return 45
        elif any(k in item_lower for k in ["api", "ì¸í„°í˜ì´ìŠ¤", "ì—°ë™"]):
            return 50
        elif any(k in item_lower for k in ["í…ŒìŠ¤íŠ¸", "test", "ê²€ì¦"]):
            return 55
        else:
            return 40  # ê¸°ë³¸ê°’

    def _estimate_validity(self, item: str) -> int:
        """ê°€ì •ì˜ ìœ íš¨í™•ë¥  ì¶”ì •"""
        item_lower = item.lower()
        if any(k in item_lower for k in ["ì¶©ë¶„", "enough", "ë§Œìœ¼ë¡œ"]):
            return 55
        elif any(k in item_lower for k in ["í•­ìƒ", "always", "ëª¨ë“ "]):
            return 40  # ì ˆëŒ€ì  ê°€ì •ì€ ë‚®ì€ í™•ë¥ 
        elif any(k in item_lower for k in ["ëŒ€ë¶€ë¶„", "most", "ì¼ë°˜ì "]):
            return 65
        else:
            return 55

    def _estimate_change_prob(self, item: str) -> int:
        """ì˜ê²¬ ë³€ê²½ í™•ë¥  ì¶”ì •"""
        item_lower = item.lower()
        if any(k in item_lower for k in ["ì‚¬ìš©ì", "user", "í”¼ë“œë°±", "feedback"]):
            return 75  # ì‚¬ìš©ì ì˜ê²¬ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥ì„± ë†’ìŒ
        elif any(k in item_lower for k in ["ì„±ëŠ¥", "performance", "ì†ë„"]):
            return 65
        elif any(k in item_lower for k in ["êµ¬ì¡°", "architecture", "ì„¤ê³„"]):
            return 70
        else:
            return 60

    def _estimate_completeness(self, item: str) -> int:
        """ì™„ì„±ë„ ì¶”ì •"""
        item_lower = item.lower()
        if any(k in item_lower for k in ["ë¯¸êµ¬í˜„", "todo", "not implemented"]):
            return 20
        elif any(k in item_lower for k in ["ë¶€ë¶„", "partial", "ì¼ë¶€"]):
            return 45
        elif any(k in item_lower for k in ["ê°œì„ ", "improve", "ë³´ì™„"]):
            return 60
        elif any(k in item_lower for k in ["ì¡°ì •", "adjust", "íŠœë‹"]):
            return 70
        else:
            return 45

    def _estimate_urgency(self, item: str, completeness: int) -> str:
        """ê¸´ê¸‰ë„ ì¶”ì • (ì™„ì„±ë„ì™€ í•­ëª©ëª… ê¸°ë°˜)"""
        item_lower = item.lower()
        # í‚¤ì›Œë“œ ê¸°ë°˜
        if any(k in item_lower for k in ["ë³´ì•ˆ", "security", "ì¸ì¦", "auth"]):
            return "high"
        elif any(k in item_lower for k in ["ë²„ê·¸", "bug", "ì—ëŸ¬", "error", "crash"]):
            return "high"
        elif any(k in item_lower for k in ["ì„±ëŠ¥", "performance", "ëŠë¦¼", "slow"]):
            return "medium"
        # ì™„ì„±ë„ ê¸°ë°˜
        elif completeness < 30:
            return "high"
        elif completeness < 50:
            return "medium"
        else:
            return "low"

    def _estimate_effect(self, effect_type: str, item: str) -> str:
        """ê¸°ëŒ€íš¨ê³¼ ì¶”ì •"""
        item_lower = item.lower()

        if effect_type == "confidence":
            if "regex" in item_lower or "ì •ê·œ" in item_lower:
                return "+40% ì •í™•ë„, ì—£ì§€ì¼€ì´ìŠ¤ 90% í•´ê²°"
            elif "ì„±ëŠ¥" in item_lower:
                return "+30% ì‘ë‹µì†ë„, ë¦¬ì†ŒìŠ¤ ìµœì í™”"
            else:
                return "+25% ì •í™•ë„ í–¥ìƒ"

        elif effect_type == "validity":
            if "ì¶©ë¶„" in item_lower:
                return "ê²€ì¦ ì‹œ ì„¤ê³„ ì•ˆì •ì„± í™•ë³´"
            else:
                return "ê°€ì • ê²€ì¦ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ê°ì†Œ"

        elif effect_type == "change":
            if "ì‚¬ìš©ì" in item_lower or "user" in item_lower:
                return "ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ìœ¼ë¡œ ë§Œì¡±ë„ +20%"
            else:
                return "ì¡°ê¸° ê²€ì¦ìœ¼ë¡œ ì¬ì‘ì—… -50%"

        elif effect_type == "completeness":
            if "ìë™" in item_lower or "auto" in item_lower:
                return "ìë™í™”ë¡œ ìˆ˜ì‘ì—… -70%"
            elif "ì €ì¥" in item_lower or "save" in item_lower:
                return "ë°ì´í„° ì—°ì†ì„± í™•ë³´"
            else:
                return "ê¸°ëŠ¥ ì™„ì„±ë„ í–¥ìƒ"

        return "ê°œì„  íš¨ê³¼ ê¸°ëŒ€"

    def _generate_default_metacognition(self) -> str:
        """Diff ë¶„ì„ ê¸°ë°˜ ê¸°ë³¸ ë©”íƒ€ì¸ì§€ ìƒì„± (ì„¸ì…˜ ë°ì´í„° ì—†ì„ ë•Œ)"""
        content = "\n**ğŸ“ ìë™ ë¶„ì„ ê¸°ë°˜ ë©”íƒ€ì¸ì§€:**\n\n"

        items = []

        # ë³µì¡ë„ ê¸°ë°˜ ì¶”ì •
        nested_count = len(re.findall(r"if.*:\s*\n\s+if", self.added_lines))
        if nested_count > 0:
            items.append(
                {
                    "category": "ì‹ ë¢°ë„",
                    "item": f"ì¤‘ì²© ì¡°ê±´ë¬¸ {nested_count}ê°œ",
                    "score": max(30, 60 - nested_count * 10),
                    "urgency": "high" if nested_count > 2 else "medium",
                    "effect": "ë¡œì§ ë‹¨ìˆœí™”ë¡œ ë²„ê·¸ ê°ì†Œ",
                }
            )

        # í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜
        has_tests = any("test" in f.lower() for f in self.files)
        if not has_tests and len(self.files) > 2:
            items.append(
                {
                    "category": "ì™„ì„±ë„",
                    "item": "í…ŒìŠ¤íŠ¸ ì½”ë“œ ë¯¸ì‘ì„±",
                    "score": 30,
                    "urgency": "medium",
                    "effect": "í…ŒìŠ¤íŠ¸ ì¶”ê°€ë¡œ ì•ˆì •ì„± +50%",
                }
            )

        # TODO ì£¼ì„ ê¸°ë°˜
        todos = re.findall(r"#\s*TODO[:\s](.{10,40})", self.added_lines, re.I)
        if todos:
            items.append(
                {
                    "category": "ì™„ì„±ë„",
                    "item": f"TODO í•­ëª© {len(todos)}ê°œ",
                    "score": 40,
                    "urgency": "low",
                    "effect": "ê¸°ìˆ ë¶€ì±„ í•´ì†Œ",
                }
            )

        if items:
            content += "| ì¹´í…Œê³ ë¦¬ | í•­ëª© | ì ìˆ˜ | ê¸´ê¸‰ë„ | ê¸°ëŒ€íš¨ê³¼ |\n"
            content += "|----------|------|------|--------|----------|\n"
            for item in items[:5]:
                urgency_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(item["urgency"], "ğŸŸ¡")
                content += f"| {item['category']} | {item['item']} | {item['score']}% | {urgency_icon} | {item['effect']} |\n"
            content += "\n"
        else:
            content += "> ìë™ ë¶„ì„ì—ì„œ ì£¼ìš” ë©”íƒ€ì¸ì§€ í•­ëª©ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 6: Rollback Plans (has_rollback)
    # -------------------------------------------------------------------------
    def _section_rollback(self) -> str:
        """Rollback Plans ì„¹ì…˜

        v3.2: ì‹¤ì „ ëª…ë ¹ì–´ + ì´ˆë³´ì ê°€ì´ë“œ ì¶”ê°€
        v3.4: ì „ë¬¸ê°€ ê²€ì¦ëœ ë©”íŠ¸ë¦­ ì¶”ê°€ (ì˜í–¥ ë²”ìœ„ + ë³µì¡ë„)
              - ì œê±°: success_rate (ì¸¡ì • ë¶ˆê°€, ì˜¤íƒë¥  70%+)
              - ì¶”ê°€: impact_scope (Code/Config/DB/Full)
              - ì¶”ê°€: complexity (Low/Medium/High)
        """
        content = "## Rollback Plans\n\n"

        # v3.4: êµ¬ì¡°í™”ëœ ë¡¤ë°± ì „ëµ (ì˜í–¥ ë²”ìœ„ + ë³µì¡ë„)
        rollbacks: List[Dict[str, str]] = []
        commit_hash = self.commit_info.get("hash", "HEAD")[:7]

        # ì‹¤ì œ Rollback ì£¼ì„ ì¶”ì¶œ (ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì œì™¸)
        rollback_comments = extract_real_comments(self.diff, "Rollback")
        rollbacks.extend(
            [
                {
                    "strategy": r[:60],
                    "cmd": "",
                    "time": "",
                    "impact": "Code-only",
                    "complexity": "Low",
                }
                for r in rollback_comments[:2]
            ]
        )

        # ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ê°ì§€ (v3.4: ì˜í–¥ ë²”ìœ„ = Code+DB)
        migrations = [f for f in self.files if "migration" in f.lower()]
        if migrations:
            rollbacks.append(
                {
                    "strategy": f"DB ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± ({len(migrations)}ê°œ)",
                    "cmd": "python manage.py migrate <app> <previous_migration>",
                    "time": "~5ë¶„",
                    "impact": "Code+DB",
                    "complexity": "High",
                }
            )

        # Feature flag ê°ì§€ (v3.4: ì˜í–¥ ë²”ìœ„ = Code+Config)
        if re.search(r"feature.?flag", self.added_lines, re.I):
            rollbacks.append(
                {
                    "strategy": "Feature Flag ë¹„í™œì„±í™”",
                    "cmd": "configì—ì„œ í”Œë˜ê·¸ OFF ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ë³€ê²½",
                    "time": "<10ì´ˆ",
                    "impact": "Code+Config",
                    "complexity": "Low",
                }
            )

        # ë°±ì—… ì „ëµ (v3.4: ì˜í–¥ ë²”ìœ„ = Full-system)
        if re.search(r"backup|ë°±ì—…", self.added_lines, re.I):
            rollbacks.append(
                {
                    "strategy": "ë°±ì—… ë³µì›",
                    "cmd": "ë°±ì—… íŒŒì¼ì—ì„œ ë³µì› (ìœ„ì¹˜ í™•ì¸ í•„ìš”)",
                    "time": "~10ë¶„",
                    "impact": "Full-system",
                    "complexity": "High",
                }
            )

        # ê¸°ë³¸ ë¡¤ë°± ê°€ì´ë“œ (í•­ìƒ ì¶”ê°€)
        rollbacks.append(
            {
                "strategy": "Git Revert (ì»¤ë°‹ ë˜ëŒë¦¬ê¸°)",
                "cmd": f"git revert {commit_hash}",
                "time": "~1ë¶„",
                "impact": "Code-only",
                "complexity": "Low",
            }
        )
        rollbacks.append(
            {
                "strategy": "Git Reset (íˆìŠ¤í† ë¦¬ ì‚­ì œ)",
                "cmd": f"git reset --hard {commit_hash}~1",
                "time": "<30ì´ˆ (ì£¼ì˜: í‘¸ì‹œ ì „ì—ë§Œ!)",
                "impact": "Code-only",
                "complexity": "Medium",
            }
        )

        # v3.4: 5ì—´ í…Œì´ë¸” (ì „ëµ, ì˜í–¥ ë²”ìœ„, ë³µì¡ë„, ëª…ë ¹ì–´, ì˜ˆìƒ ì‹œê°„)
        content += "| ì „ëµ | ì˜í–¥ ë²”ìœ„ | ë³µì¡ë„ | ëª…ë ¹ì–´/ë°©ë²• | ì˜ˆìƒ ì‹œê°„ |\n"
        content += "|------|----------|--------|------------|----------|\n"
        for idx, item in enumerate(rollbacks[:5], 1):
            if isinstance(item, dict):
                strategy = item.get("strategy", "-")
                impact = item.get("impact", "Code-only")
                complexity = item.get("complexity", "Low")
                complexity_emoji = {"Low": "ğŸŸ¢", "Medium": "ğŸŸ¡", "High": "ğŸ”´"}.get(complexity, "ğŸŸ¡")
                cmd = f"`{item['cmd']}`" if item.get("cmd") else "-"
                time = item.get("time", "-")
                content += f"| Tier {idx}: {strategy} | {impact} | {complexity_emoji} {complexity} | {cmd} | {time} |\n"
            else:
                content += f"| Tier {idx} | {item} | - | - | - |\n"

        content += "\n"

        # ì´ˆë³´ìë¥¼ ìœ„í•œ ë¡¤ë°± ê°€ì´ë“œ
        content += "### ğŸ’¡ ë¡¤ë°± ê°€ì´ë“œ (ì´ˆë³´ììš©)\n\n"
        content += "**ìƒí™©ë³„ ë¡¤ë°± ì„ íƒ:**\n"
        content += "1. **ì½”ë“œë§Œ ë¬¸ì œ** â†’ `git revert` (ì•ˆì „, íˆìŠ¤í† ë¦¬ ìœ ì§€)\n"
        content += "2. **DBë„ ë³€ê²½ë¨** â†’ DB ë¡¤ë°± ë¨¼ì € â†’ ì½”ë“œ ë¡¤ë°±\n"
        content += "3. **ì„¤ì •ë§Œ ë³€ê²½** â†’ Feature Flag OFF ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ë³µì›\n"
        content += "4. **ê¸´ê¸‰ ìƒí™©** â†’ `git reset --hard` (íˆìŠ¤í† ë¦¬ ì‚­ì œë¨, ì‹ ì¤‘íˆ!)\n\n"

        content += "**ë¡¤ë°± ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸:**\n"
        content += "- [ ] ë‹¤ë¥¸ íŒ€ì›ì—ê²Œ ì•Œë¦¼\n"
        content += "- [ ] í˜„ì¬ ìƒíƒœ ë°±ì—…/ìŠ¤ëƒ…ìƒ·\n"
        content += "- [ ] ë¡¤ë°± í›„ í…ŒìŠ¤íŠ¸ ê³„íš ì¤€ë¹„\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 7: Related Docs (í•­ìƒ)
    # -------------------------------------------------------------------------
    def _section_related_docs(self) -> str:
        """Related Docs ì„¹ì…˜ - ê´€ë ¨ ë¬¸ì„œ ìë™ ë§í¬"""
        content = "## Related Docs\n\n"

        # ë³€ê²½ëœ docs íŒŒì¼
        doc_files = [f for f in self.files if f.startswith("docs/") or f.endswith(".md")]
        if doc_files:
            content += "### ë³€ê²½ëœ ë¬¸ì„œ\n"
            for doc in doc_files[:5]:
                content += f"- [[{Path(doc).stem}]] (`{doc}`)\n"
            content += "\n"

        # ê´€ë ¨ ë§í¬ ì¶”ë¡ 
        content += "### ê´€ë ¨ ë§í¬\n"

        # CLAUDE.md ì°¸ì¡°
        if any("claude" in f.lower() for f in self.files):
            content += "- [[CLAUDE]] (í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸)\n"

        # í…ŒìŠ¤íŠ¸ ê´€ë ¨
        if any("test" in f.lower() for f in self.files):
            content += "- [[Testing Guide]]\n"

        # Backend ê´€ë ¨
        if any("backend" in f.lower() for f in self.files):
            content += "- [[Backend Architecture]]\n"

        # Frontend ê´€ë ¨
        if any("web-dashboard" in f.lower() or "frontend" in f.lower() for f in self.files):
            content += "- [[Frontend Guide]]\n"

        # v3.5: í•™ìŠµ ê°€ì´ë“œ + í˜„ì¬ ë‹¨ê³„ í‘œì‹œ
        curriculum = get_current_curriculum()
        month = curriculum["month"]
        week = curriculum["week"]
        title = curriculum["title"]
        focus = curriculum["focus"]
        checkpoints = curriculum["checkpoints"]
        considerations = curriculum["considerations"]
        warnings = curriculum["warnings"]
        guide = curriculum["guide"]

        # v3.6: Bridge content for smooth month transitions
        key = (month, week)
        raw_curriculum = LEARNING_CURRICULUM.get(key, {})
        bridge_preview = raw_curriculum.get("bridge_preview")
        bridge_review = raw_curriculum.get("bridge_review")

        content += "\n### ğŸ“š Learning Progress (VibeCoding)\n\n"

        # Progress bar visualization
        # Week 0 = week 1 of 13, Month 1 Week 1 = week 2 of 13, etc.
        # Formula: ((month-1)*4 + week) gives 0-based week index
        # For Week 0 (month=0, week=0): total_weeks = 1
        # For Month 1-3: total_weeks = month*4 + week
        if month == 0:
            total_weeks_completed = week  # Week 0 = 0 weeks completed initially
        else:
            total_weeks_completed = (month - 1) * 4 + week

        # Calculate progress percentage (13 weeks total: Week 0 + 3 months * 4 weeks)
        progress_percent = min(100, int((total_weeks_completed / 13) * 100))

        # Create ASCII progress bar (10 characters wide)
        filled_chars = int(progress_percent / 10)
        empty_chars = 10 - filled_chars
        progress_bar = "â–ˆ" * filled_chars + "â–‘" * empty_chars

        # Calculate current week number (1-indexed for display)
        if month == 0:
            current_week_num = 1  # Week 0 is displayed as Week 1/13
        else:
            current_week_num = 1 + (month - 1) * 4 + week  # +1 for Week 0

        content += f"**ì§„í–‰ë¥ **: {progress_bar} {progress_percent}% (Week {current_week_num}/13)\n\n"
        content += f"**í˜„ì¬ ë‹¨ê³„**: Month {month} Week {week} - {title}\n"
        content += f"**ì´ë²ˆ ì£¼ í¬ì»¤ìŠ¤**: {focus}\n\n"

        # v3.6: ì²´í¬í¬ì¸íŠ¸ ìë™ ê°ì§€
        newly_detected = detect_checkpoint_completion(self.message, self.diff, curriculum)
        already_done = set(curriculum.get("checkpoints_done", []))
        all_completed = already_done.union(set(newly_detected))

        # ìƒˆë¡œ ê°ì§€ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ session_stateì— ì €ì¥
        if newly_detected:
            update_checkpoints_done(newly_detected)

        # í•„ìˆ˜ ì²´í¬í¬ì¸íŠ¸ (ì™„ë£Œ ì—¬ë¶€ + ìë™ ê°ì§€ í‘œì‹œ)
        content += "**í•„ìˆ˜ ì²´í¬í¬ì¸íŠ¸**:\n"
        for cp in checkpoints:
            if cp in all_completed:
                if cp in newly_detected:
                    # ì´ë²ˆ ì»¤ë°‹ì—ì„œ ìƒˆë¡œ ê°ì§€ë¨
                    content += f"- [x] {cp} (ìë™ ê°ì§€ë¨)\n"
                else:
                    # ì´ì „ì— ì´ë¯¸ ì™„ë£Œë¨
                    content += f"- [x] {cp}\n"
            else:
                content += f"- [ ] {cp}\n"
        content += "\n"

        # ê³ ë ¤ì‚¬í•­
        if considerations:
            content += "**ğŸ’¡ ê³ ë ¤ì‚¬í•­**:\n"
            for c in considerations:
                content += f"- {c}\n"
            content += "\n"

        # ì£¼ì˜ì 
        if warnings:
            content += "**âš ï¸ ì£¼ì˜ì **:\n"
            for w in warnings:
                content += f"- {w}\n"
            content += "\n"

        # v3.6: Bridge Review (Week 1 of Months 2 and 3 - start of new month)
        if bridge_review:
            content += "**ğŸ”„ ì§€ë‚œ ë‹¬ ë³µìŠµ (Bridge Review)**:\n\n"
            content += f"*ì´ì „ ë‹¨ê³„*: {bridge_review['previous_month']}\n\n"
            content += "í•µì‹¬ ê°œë… í™•ì¸:\n"
            for concept in bridge_review["key_concepts"]:
                content += f"- {concept}\n"
            content += "\nìê°€ ì ê²€:\n"
            for check in bridge_review["self_check"]:
                content += f"- [ ] {check}\n"
            content += "\n"

        # v3.6: Bridge Preview (Week 4 of Months 1 and 2 - end of month)
        if bridge_preview:
            content += "**ğŸš€ ë‹¤ìŒ ë‹¬ ë¯¸ë¦¬ë³´ê¸° (Bridge Preview)**:\n\n"
            content += f"*ë‹¤ìŒ ë‹¨ê³„*: {bridge_preview['next_month']}\n\n"
            content += f"ë¯¸ë¦¬ë³´ê¸°: {bridge_preview['preview']}\n\n"
            content += "ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­:\n"
            for prep in bridge_preview["preparation"]:
                content += f"- [ ] {prep}\n"
            content += "\n"

        # ì°¸ê³  ê°€ì´ë“œ ë§í¬
        content += f"**ì°¸ê³ **: [[{guide}]]\n\n"

        # ì „ì²´ ê°€ì´ë“œ ë§í¬ (ì ‘íŒ ìƒíƒœ)
        content += "<details>\n<summary>ğŸ“– ì „ì²´ ê°€ì´ë“œ ëª©ë¡</summary>\n\n"
        content += "- [[VibeCoding-Growth-Guide]] - 3ê°œì›” ì„±ì¥ ë¡œë“œë§µ\n"
        content += "- [[MCP-Combination-Patterns]] - MCP ì„œë²„ ì¡°í•© íŒ¨í„´\n"
        content += "- [[Claude-Skills-Curriculum]] - í´ë¡œë“œ ìŠ¤í‚¬ 4ì£¼ ì»¤ë¦¬í˜ëŸ¼\n"
        content += "- [[Prompt-Pattern-Library]] - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ íŒ¨í„´\n"
        content += "- [[Multi-Agent-Workflows]] - ë©€í‹°ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°\n"
        content += "</details>\n"

        content += "\n"
        return content

    # -------------------------------------------------------------------------
    # Section 8: Technical Debt Daily (has_debt)
    # -------------------------------------------------------------------------
    def _section_tech_debt(self) -> str:
        """Technical Debt Daily ì„¹ì…˜

        v3.2: ì´ˆë³´ì í•™ìŠµ ê°€ì´ë“œ + ê¸°ìˆ ë¶€ì±„ ê´€ë¦¬ ë°©ë²• ì¶”ê°€
        v3.4: ì „ë¬¸ê°€ ê²€ì¦ëœ ë©”íŠ¸ë¦­ ì¶”ê°€ (ì‹¬ê°ë„ + ë…¸ë ¥ + ëˆ„ì  ë¦¬ìŠ¤í¬)
              - ì¶”ê°€: severity_score (0-100, ìë™ ê³„ì‚°)
              - ì¶”ê°€: effort (T-shirt: S/M/L/XL)
              - ì¶”ê°€: impact_type (security/performance/maintenance/reliability)
        """
        content = "## Technical Debt (Daily)\n\n"

        # v3.4: êµ¬ì¡°í™”ëœ ê¸°ìˆ ë¶€ì±„ (ì‹¬ê°ë„ + ë…¸ë ¥ + ëˆ„ì  ë¦¬ìŠ¤í¬)
        debts: List[Dict[str, Any]] = []

        # TODO ì¶”ì¶œ (ì‹¤ì œ ì£¼ì„ë§Œ)
        todos = extract_real_comments(self.diff, "TODO")
        for t in todos[:5]:
            debts.append(
                {
                    "type": "TODO",
                    "desc": t[:60],
                    "severity": self._estimate_debt_severity("TODO", t),
                    "effort": self._estimate_debt_effort(t),
                    "impact": self._estimate_debt_impact(t),
                }
            )

        # FIXME ì¶”ì¶œ (ì‹¤ì œ ì£¼ì„ë§Œ)
        fixmes = extract_real_comments(self.diff, "FIXME")
        for f in fixmes[:3]:
            debts.append(
                {
                    "type": "FIXME",
                    "desc": f[:60],
                    "severity": self._estimate_debt_severity("FIXME", f),
                    "effort": self._estimate_debt_effort(f),
                    "impact": self._estimate_debt_impact(f),
                }
            )

        # HACK ì¶”ì¶œ (ì‹¤ì œ ì£¼ì„ë§Œ)
        hacks = extract_real_comments(self.diff, "HACK")
        for h in hacks[:2]:
            debts.append(
                {
                    "type": "HACK",
                    "desc": h[:60],
                    "severity": self._estimate_debt_severity("HACK", h),
                    "effort": self._estimate_debt_effort(h),
                    "impact": self._estimate_debt_impact(h),
                }
            )

        # ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸ (ì¶”ê°€ëœ ì¤„ì—ì„œë§Œ)
        skips = re.findall(r"@pytest\.mark\.skip\(reason=[\"'](.+?)[\"']\)", self.added_lines)
        for s in skips[:2]:
            debts.append(
                {
                    "type": "SKIP",
                    "desc": s[:60],
                    "severity": 60,  # ìŠ¤í‚µ í…ŒìŠ¤íŠ¸ëŠ” ì¤‘ê°„ ì‹¬ê°ë„
                    "effort": "S",
                    "impact": "Reliability",
                }
            )

        # íƒ€ì… ë¬´ì‹œ (ì¶”ê°€ëœ ì¤„ì—ì„œë§Œ)
        ignores = len(re.findall(r"#\s*type:\s*ignore", self.added_lines))
        if ignores > 0:
            debts.append(
                {
                    "type": "TYPE",
                    "desc": f"type: ignore ì£¼ì„ {ignores}ê°œ",
                    "severity": 40 + (ignores * 5),  # ê°œìˆ˜ì— ë”°ë¼ ì‹¬ê°ë„ ì¦ê°€
                    "effort": "S" if ignores <= 3 else "M",
                    "impact": "Maintenance",
                }
            )

        if debts:
            # v3.4: ì‹¬ê°ë„ ê¸°ì¤€ ì •ë ¬ í›„ í…Œì´ë¸” ë Œë”ë§
            debts.sort(key=lambda x: x.get("severity", 0), reverse=True)

            content += "| ìœ í˜• | ì„¤ëª… | ì‹¬ê°ë„ | ë…¸ë ¥ | ëˆ„ì  ë¦¬ìŠ¤í¬ |\n"
            content += "|------|------|--------|------|------------|\n"
            for debt in debts[:8]:
                severity = debt.get("severity", 50)
                severity_emoji = "ğŸ”´" if severity >= 80 else "ğŸŸ " if severity >= 60 else "ğŸŸ¡" if severity >= 40 else "ğŸŸ¢"
                effort = debt.get("effort", "M")
                impact = debt.get("impact", "Maintenance")
                content += f"| {debt['type']} | {debt['desc']} | {severity_emoji} {severity}% | {effort} | {impact} |\n"

            content += "\n"

            # ì´ˆë³´ìë¥¼ ìœ„í•œ ê¸°ìˆ ë¶€ì±„ ê°€ì´ë“œ
            content += "### ğŸ’¡ ê¸°ìˆ ë¶€ì±„ ì´í•´í•˜ê¸° (ì´ˆë³´ììš©)\n\n"
            content += "**ê¸°ìˆ ë¶€ì±„ ìœ í˜•ë³„ ì˜ë¯¸:**\n"
            content += "| ìœ í˜• | ì˜ë¯¸ | ì¡°ì¹˜ ì‹œì  |\n"
            content += "|------|------|----------|\n"
            content += "| TODO | ë‚˜ì¤‘ì— êµ¬í˜„í•  ê¸°ëŠ¥ | ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œ |\n"
            content += "| FIXME | ì•Œë ¤ì§„ ë²„ê·¸/ë¬¸ì œ | **ê°€ëŠ¥í•œ ë¹¨ë¦¬!** |\n"
            content += "| HACK | ì„ì‹œ í•´ê²°ì±… | ë‹¤ìŒ ë¦¬íŒ©í† ë§ ì‹œ |\n"
            content += "| SKIP | ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸ | í…ŒìŠ¤íŠ¸ ì•ˆì •í™” í›„ |\n"
            content += "| TYPE | íƒ€ì… ë¬´ì‹œ | íƒ€ì… ì •ì˜ ì™„ë£Œ í›„ |\n\n"

            content += "**ê¸°ìˆ ë¶€ì±„ ê´€ë¦¬ ì›ì¹™:**\n"
            content += "1. **ì˜ë„ì  ë¶€ì±„** (ë§ˆê°ì— ë§ì¶”ê¸° ìœ„í•´) â†’ ë°˜ë“œì‹œ ê¸°ë¡í•˜ê³  ìƒí™˜ ê³„íš ì„¸ìš°ê¸°\n"
            content += "2. **ë¬´ì˜ì‹ì  ë¶€ì±„** (ë‚˜ì¤‘ì— ë°œê²¬) â†’ ë°œê²¬ ì¦‰ì‹œ ê¸°ë¡, ìš°ì„ ìˆœìœ„ íŒë‹¨\n"
            content += "3. **20% ê·œì¹™** - ë§¤ ìŠ¤í”„ë¦°íŠ¸ ì‹œê°„ì˜ 20%ëŠ” ë¶€ì±„ ìƒí™˜ì— í• ë‹¹\n\n"

        else:
            # ê¸°ìˆ ë¶€ì±„ í”Œë˜ê·¸ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ êµ¬ì²´ì  í•­ëª©ì´ ì—†ëŠ” ê²½ìš°
            possible_reasons = []
            if any("test" in f.lower() and "skip" in self.added_lines.lower() for f in self.files):
                possible_reasons.append("ìŠ¤í‚µëœ í…ŒìŠ¤íŠ¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ")
            if "# type: ignore" in self.added_lines:
                possible_reasons.append("íƒ€ì… ë¬´ì‹œ ì£¼ì„ì´ ìˆìŒ")

            if possible_reasons:
                content += f"> ê°ì§€ëœ íŒ¨í„´: {', '.join(possible_reasons)}\n\n"
            else:
                content += "> ê¸°ìˆ ë¶€ì±„ í”Œë˜ê·¸ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ êµ¬ì²´ì  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"

            content += "### ğŸ’¡ ê¸°ìˆ ë¶€ì±„ ê¸°ë¡ ë°©ë²• (ì´ˆë³´ììš©)\n\n"
            content += "ì½”ë“œì— ë‹¤ìŒ ì£¼ì„ì„ ì¶”ê°€í•˜ë©´ ìë™ìœ¼ë¡œ ì¶”ì¶œë©ë‹ˆë‹¤:\n"
            content += "```python\n"
            content += "# TODO: ë‚˜ì¤‘ì— êµ¬í˜„í•  ê¸°ëŠ¥ ì„¤ëª…\n"
            content += "# FIXME: ì•Œë ¤ì§„ ë²„ê·¸ ì„¤ëª… (ë¹¨ë¦¬ ê³ ì³ì•¼ í•¨)\n"
            content += "# HACK: ì„ì‹œ í•´ê²°ì±… ì„¤ëª… (ë‚˜ì¤‘ì— ì œëŒ€ë¡œ ê³ ì³ì•¼ í•¨)\n"
            content += "```\n\n"

        return content

    # -------------------------------------------------------------------------
    # Section 9: Decisions Made (has_decision)
    # -------------------------------------------------------------------------
    def _section_decisions(self) -> str:
        """Decisions Made ì„¹ì…˜ - êµ¬ì²´ì  ì˜ì‚¬ê²°ì • ë¶„ì„

        v3.2: ì´ˆë³´ìë¥¼ ìœ„í•œ ê²°ì • ë°°ê²½ ë° íŠ¸ë ˆì´ë“œì˜¤í”„ ì„¤ëª… ì¶”ê°€
        v3.4: ì „ë¬¸ê°€ ê²€ì¦ëœ ë©”íŠ¸ë¦­ ì¶”ê°€ (ìœ í˜• + ë˜ëŒë¦¼ ê°€ëŠ¥ì„± + ê²°ì • ë²”ìœ„)
              - ì¶”ê°€: type (Architecture/Dependency/Config/Process)
              - ì¶”ê°€: reversibility (Easy/Medium/Hard) - AI ì‹ ë¢°ë„ì™€ êµ¬ë¶„
              - ì¶”ê°€: scope (Local/Module/System)
        """
        content = "## Decisions Made (Daily)\n\n"

        # v3.4: êµ¬ì¡°í™”ëœ ì˜ì‚¬ê²°ì • (ìœ í˜• + ë˜ëŒë¦¼ + ë²”ìœ„)
        decisions: List[Dict[str, Any]] = []
        decision_contexts = []  # ê²°ì • ë°°ê²½/íŠ¸ë ˆì´ë“œì˜¤í”„

        # ëª…ì‹œì  Decision ì£¼ì„ (ì‹¤ì œ ì£¼ì„ë§Œ)
        decision_comments = extract_real_comments(self.diff, "Decision")
        for d in decision_comments[:5]:
            decisions.append(
                {
                    "desc": d[:70],
                    "type": "Process",
                    "reversibility": "Medium",
                    "scope": self._estimate_decision_scope(d),
                }
            )

        # Why ì£¼ì„ (ì‹¤ì œ ì£¼ì„ë§Œ) - ë°°ê²½ ì»¨í…ìŠ¤íŠ¸ìš©
        why_comments = extract_real_comments(self.diff, "Why")
        for w in why_comments[:3]:
            decision_contexts.append(f"**ì´ìœ **: {w[:80]}")

        # ì˜ì¡´ì„± ë³€ê²½ ê°ì§€ (v3.4: Dependency ìœ í˜•)
        if "requirements.txt" in self.files:
            added_deps = re.findall(r"^\+([a-zA-Z0-9_-]+)==([0-9.]+)", self.added_lines, re.M)
            for name, version in added_deps[:3]:
                decisions.append(
                    {
                        "desc": f"ì˜ì¡´ì„± ì¶”ê°€: {name}=={version}",
                        "type": "Dependency",
                        "reversibility": "Easy",  # pip uninstall ê°€ëŠ¥
                        "scope": "Module",
                    }
                )
            if added_deps:
                decision_contexts.append("**ì˜ì¡´ì„± ì¶”ê°€ ì£¼ì˜**: ë¼ì´ì„ ìŠ¤ í˜¸í™˜ì„±, ë³´ì•ˆ ì·¨ì•½ì , ìœ ì§€ë³´ìˆ˜ ìƒíƒœ í™•ì¸")

        if "package.json" in self.files:
            added_npm = re.findall(r'"([^"]+)":\s*"[\^~]?([0-9.]+)"', self.added_lines)
            for name, version in added_npm[:3]:
                if not name.startswith("@types"):
                    decisions.append(
                        {
                            "desc": f"NPM íŒ¨í‚¤ì§€: {name}@{version}",
                            "type": "Dependency",
                            "reversibility": "Easy",
                            "scope": "Module",
                        }
                    )

        # ì•„í‚¤í…ì²˜ ê²°ì • ê°ì§€ (v3.4: Architecture ìœ í˜•)
        arch_patterns = {
            r"class\s+(\w+Factory)": ("Factory íŒ¨í„´", "Hard", "System"),
            r"class\s+(\w+Singleton)": ("Singleton íŒ¨í„´", "Hard", "System"),
            r"class\s+(\w+Service)": ("Service ê³„ì¸µ", "Medium", "Module"),
            r"class\s+(\w+Repository)": ("Repository íŒ¨í„´", "Medium", "Module"),
            r"class\s+(\w+Controller)": ("Controller ê³„ì¸µ", "Medium", "Module"),
        }
        for pattern, (desc, rev, scope) in arch_patterns.items():
            matches = re.findall(pattern, self.added_lines)
            if matches:
                decisions.append(
                    {
                        "desc": f"{desc}: {matches[0]}",
                        "type": "Architecture",
                        "reversibility": rev,
                        "scope": scope,
                    }
                )
                break

        # ì„¤ì • íŒŒì¼ ë³€ê²½ ê°ì§€ (v3.4: Config ìœ í˜•)
        config_files = [f for f in self.files if f.endswith((".yaml", ".yml", ".json", ".toml", ".env"))]
        if config_files:
            config_names = [Path(f).name for f in config_files[:2]]
            decisions.append(
                {
                    "desc": f"ì„¤ì • ë³€ê²½: {', '.join(config_names)}",
                    "type": "Config",
                    "reversibility": "Easy",
                    "scope": "System" if any("prod" in f.lower() for f in config_files) else "Local",
                }
            )
            decision_contexts.append("**ì„¤ì • ë³€ê²½ ì£¼ì˜**: í™˜ê²½ë³„(dev/staging/prod) ì°¨ì´, ë¯¼ê°ì •ë³´ ë…¸ì¶œ í™•ì¸ í•„ìš”")

        # ì»¤ë°‹ ë©”ì‹œì§€ì—ì„œ ê²°ì •ì‚¬í•­ ì¶”ì¶œ (v3.4: Process ìœ í˜•)
        commit_decision_patterns = [
            (r"ëŒ€ì‹ |instead of|rather than", "ëŒ€ì•ˆ ì„ íƒ", "Medium", "Module"),
            (r"ì „í™˜|migrate|switch", "ê¸°ìˆ  ì „í™˜", "Hard", "System"),
            (r"ë„ì…|introduce|adopt", "ìƒˆ ê¸°ìˆ  ë„ì…", "Medium", "Module"),
            (r"ì œê±°|remove|deprecate", "ê¸°ëŠ¥ ì œê±°", "Hard", "System"),
        ]
        for pattern, desc, rev, scope in commit_decision_patterns:
            if re.search(pattern, self.message, re.I):
                decisions.append(
                    {
                        "desc": f"{desc}: {self.message.split(chr(10))[0][:40]}",
                        "type": "Process",
                        "reversibility": rev,
                        "scope": scope,
                    }
                )
                break

        if decisions:
            # v3.4: í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë Œë”ë§ (ë˜ëŒë¦¼ ê°€ëŠ¥ì„± ê¸°ì¤€ ì •ë ¬)
            reversibility_order = {"Hard": 0, "Medium": 1, "Easy": 2}
            decisions.sort(key=lambda x: reversibility_order.get(x.get("reversibility", "Medium"), 1))

            content += "| ê²°ì • ë‚´ìš© | ìœ í˜• | ë˜ëŒë¦¼ | ë²”ìœ„ |\n"
            content += "|----------|------|--------|------|\n"
            for dec in decisions[:8]:
                rev = dec.get("reversibility", "Medium")
                rev_emoji = {"Easy": "ğŸŸ¢", "Medium": "ğŸŸ¡", "Hard": "ğŸ”´"}.get(rev, "ğŸŸ¡")
                scope = dec.get("scope", "Module")
                scope_emoji = {"Local": "ğŸ“„", "Module": "ğŸ“¦", "System": "ğŸŒ"}.get(scope, "ğŸ“¦")
                content += f"| {dec['desc']} | {dec['type']} | {rev_emoji} {rev} | {scope_emoji} {scope} |\n"
            content += "\n"

            # ì´ˆë³´ìë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì„¤ëª…
            content += "### ğŸ’¡ ì˜ì‚¬ê²°ì • ë©”íŠ¸ë¦­ ì´í•´í•˜ê¸° (ì´ˆë³´ììš©)\n\n"
            content += "**ë˜ëŒë¦¼ ê°€ëŠ¥ì„± (Reversibility)**:\n"
            content += "- ğŸŸ¢ Easy: ì‰½ê²Œ ë˜ëŒë¦´ ìˆ˜ ìˆìŒ (ì˜ì¡´ì„± ì œê±°, ì„¤ì • ë³€ê²½)\n"
            content += "- ğŸŸ¡ Medium: ì•½ê°„ì˜ ì‘ì—… í•„ìš” (ì½”ë“œ ë¦¬íŒ©í† ë§, DB ë§ˆì´ê·¸ë ˆì´ì…˜)\n"
            content += "- ğŸ”´ Hard: ë˜ëŒë¦¬ê¸° ì–´ë ¤ì›€ (ì•„í‚¤í…ì²˜ ë³€ê²½, ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë³€ê²½)\n\n"

            content += "**ê²°ì • ë²”ìœ„ (Scope)**:\n"
            content += "- ğŸ“„ Local: ë‹¨ì¼ íŒŒì¼/í•¨ìˆ˜ ìˆ˜ì¤€\n"
            content += "- ğŸ“¦ Module: ëª¨ë“ˆ/íŒ¨í‚¤ì§€ ìˆ˜ì¤€\n"
            content += "- ğŸŒ System: ì‹œìŠ¤í…œ ì „ì²´ ì˜í–¥\n\n"

            # ê²°ì • ë°°ê²½ ì„¤ëª…
            if decision_contexts:
                content += "### ğŸ“ ê²°ì •ì˜ ë°°ê²½\n\n"
                for ctx in decision_contexts[:3]:
                    content += f"{ctx}\n\n"

        else:
            # êµ¬ì²´ì ì¸ í´ë°± ë©”ì‹œì§€
            content += "> ì˜ì‚¬ê²°ì • í”Œë˜ê·¸ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ êµ¬ì²´ì  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"

            content += "### ğŸ’¡ ì˜ì‚¬ê²°ì • ê¸°ë¡ì˜ ì¤‘ìš”ì„± (ì´ˆë³´ììš©)\n\n"
            content += "ì½”ë“œëŠ” **ë¬´ì—‡**ì„ í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ì§€ë§Œ, **ì™œ** ê·¸ë ‡ê²Œ í–ˆëŠ”ì§€ëŠ” ë³´ì—¬ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
            content += "6ê°œì›” í›„ì˜ ìì‹ (ë˜ëŠ” ë™ë£Œ)ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê²°ì • ì´ìœ ë¥¼ ë‚¨ê¸°ì„¸ìš”:\n\n"
            content += "```python\n"
            content += "# Decision: ì—¬ê¸°ì— ê²°ì • ë‚´ìš©\n"
            content += "# Why: ì—¬ê¸°ì— ì´ìœ \n"
            content += "```\n\n"

        return content

    # -------------------------------------------------------------------------
    # Helper Methods
    # -------------------------------------------------------------------------
    def _categorize_files(self) -> Dict[str, int]:
        """íŒŒì¼ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            "Backend": 0,
            "Frontend": 0,
            "Tests": 0,
            "Docs": 0,
            "Scripts": 0,
            "Config": 0,
        }

        for f in self.files:
            if f.startswith("backend/"):
                categories["Backend"] += 1
            elif f.startswith("web-dashboard/") or f.startswith("frontend/"):
                categories["Frontend"] += 1
            elif "test" in f.lower():
                categories["Tests"] += 1
            elif f.startswith("docs/") or f.endswith(".md"):
                categories["Docs"] += 1
            elif f.startswith("scripts/"):
                categories["Scripts"] += 1
            elif any(f.endswith(ext) for ext in [".yaml", ".yml", ".json", ".toml", ".env"]):
                categories["Config"] += 1

        return {k: v for k, v in categories.items() if v > 0}


# =============================================================================
# v3.0: Weekly Summary Generator (4 Weekly Sections with Dataview)
# =============================================================================


class WeeklySummaryGenerator:
    """4ê°œ Weekly ì„¹ì…˜ ìƒì„±ê¸° (Dataview ì¿¼ë¦¬ í™œìš©)"""

    def __init__(self, week_start: datetime, week_end: datetime, project: str = "UDO-Development-Platform"):
        self.week_start = week_start
        self.week_end = week_end
        self.project = project
        self.week_str = week_start.strftime("%Y-W%W")

    def generate_weekly_note(self) -> str:
        """ì£¼ê°„ ìš”ì•½ ë…¸íŠ¸ ìƒì„±"""
        content = self._generate_frontmatter()
        content += f"\n# Weekly Summary: {self.week_str}\n\n"
        content += f"**ê¸°ê°„**: {self.week_start.strftime('%Y-%m-%d')} ~ {self.week_end.strftime('%Y-%m-%d')}\n\n"

        # 4ê°œ Weekly ì„¹ì…˜
        content += self._section_tech_debt_summary()
        content += self._section_decision_audit()
        content += self._section_performance_trends()
        content += self._section_next_week_actions()

        # í‘¸í„°
        content += "\n---\n"
        content += "**ìë™ ìƒì„±**: Obsidian Auto-Sync v3.0 Weekly  \n"
        content += f"**ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M')}  \n"

        return content

    def _generate_frontmatter(self) -> str:
        """Weekly Frontmatter ìƒì„±"""
        frontmatter = f"""---
title: "{self.week_str} Weekly Summary"
created: {datetime.now().strftime('%Y-%m-%d')}
type: weekly
status: completed
week_start: {self.week_start.strftime('%Y-%m-%d')}
week_end: {self.week_end.strftime('%Y-%m-%d')}
project: {self.project}
schema_version: "1.0"
tags: [weekly, summary, review]
---
"""
        return frontmatter

    # -------------------------------------------------------------------------
    # Section 1: Tech Debt Summary (ì£¼ê°„ ê¸°ìˆ ë¶€ì±„ ì§‘ê³„)
    # -------------------------------------------------------------------------
    def _section_tech_debt_summary(self) -> str:
        """Tech Debt Summary - Dataview ì¿¼ë¦¬ë¡œ ì§‘ê³„"""
        content = "## Tech Debt Summary\n\n"
        content += "> ì´ë²ˆ ì£¼ ë°œìƒí•œ ê¸°ìˆ ë¶€ì±„ë¥¼ Dataviewë¡œ ìë™ ì§‘ê³„í•©ë‹ˆë‹¤.\n\n"

        # Dataview ì¿¼ë¦¬ (has_debt=trueì¸ Daily ë…¸íŠ¸ ì§‘ê³„)
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  length(filter(file.outlinks, (l) => contains(string(l), "TODO"))) as "TODO",\n'
        content += '  length(filter(file.outlinks, (l) => contains(string(l), "FIXME"))) as "FIXME"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_debt = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ìˆ˜ë™ ì²´í¬ë¦¬ìŠ¤íŠ¸
        content += "### ì£¼ê°„ ê¸°ìˆ ë¶€ì±„ ì•¡ì…˜\n\n"
        content += "- [ ] ì´ë²ˆ ì£¼ TODO ì •ë¦¬ (ìš°ì„ ìˆœìœ„ P1 ë¨¼ì €)\n"
        content += "- [ ] FIXME í•­ëª© ë¦¬ë·°\n"
        content += "- [ ] ë‹¤ìŒ ì£¼ ì´ì›” í•­ëª© ê²°ì •\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 2: Decision Audit Summary (ì£¼ê°„ ì˜ì‚¬ê²°ì • ê°ì‚¬)
    # -------------------------------------------------------------------------
    def _section_decision_audit(self) -> str:
        """Decision Audit - ì£¼ê°„ ì˜ì‚¬ê²°ì • ê°ì‚¬"""
        content = "## Decision Audit Summary\n\n"
        content += "> ì´ë²ˆ ì£¼ ë‚´ë¦° ì£¼ìš” ê²°ì •ë“¤ì„ ì¶”ì í•©ë‹ˆë‹¤.\n\n"

        # Dataview ì¿¼ë¦¬ (has_decision=trueì¸ Daily ë…¸íŠ¸)
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  context_summary as "ìš”ì•½"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_decision = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ê²°ì • ê²€í†  ì²´í¬ë¦¬ìŠ¤íŠ¸
        content += "### ê²°ì • ê²€í†  ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"
        content += "| ê²°ì • | ê²°ê³¼ | í›„ì† ì¡°ì¹˜ |\n"
        content += "|------|------|----------|\n"
        content += "| (ìˆ˜ë™ ì…ë ¥) | (ì„±ê³µ/ì‹¤íŒ¨/ì§„í–‰ì¤‘) | (í•„ìš”ì‹œ) |\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 3: Performance Trends (ì„±ëŠ¥ íŠ¸ë Œë“œ)
    # -------------------------------------------------------------------------
    def _section_performance_trends(self) -> str:
        """Performance Trends - ìƒì‚°ì„± ë° ì„±ê³¼ íŠ¸ë Œë“œ"""
        content = "## Performance Trends\n\n"
        content += "> ì´ë²ˆ ì£¼ ê°œë°œ ìƒì‚°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n\n"

        # ì»¤ë°‹ í†µê³„ Dataview
        content += "### ì»¤ë°‹ í†µê³„\n\n"
        content += "```dataview\n"
        content += "TABLE WITHOUT ID\n"
        content += '  file.link as "ë‚ ì§œ",\n'
        content += '  files_changed as "íŒŒì¼ìˆ˜",\n'
        content += '  commits as "ì»¤ë°‹ìˆ˜"\n'
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "SORT created ASC\n"
        content += "```\n\n"

        # í•™ìŠµ ì¶”ì 
        content += "### í•™ìŠµ í†µê³„ (TIL)\n\n"
        content += "```dataview\n"
        content += "LIST\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND has_til = true\n"
        content += "SORT created ASC\n"
        content += "```\n\n"

        # ì£¼ê°„ ìš”ì•½ ë©”íŠ¸ë¦­
        content += "### ì£¼ê°„ ë©”íŠ¸ë¦­ (ìˆ˜ë™ ì…ë ¥)\n\n"
        content += "| ì§€í‘œ | ì´ë²ˆ ì£¼ | ì§€ë‚œ ì£¼ | ë³€í™” |\n"
        content += "|------|---------|---------|------|\n"
        content += "| ì´ ì»¤ë°‹ ìˆ˜ | - | - | - |\n"
        content += "| ë³€ê²½ íŒŒì¼ ìˆ˜ | - | - | - |\n"
        content += "| TIL í•­ëª© ìˆ˜ | - | - | - |\n"
        content += "| í•´ê²°ëœ ì´ìŠˆ | - | - | - |\n"
        content += "\n"

        return content

    # -------------------------------------------------------------------------
    # Section 4: Next Week Actions (ë‹¤ìŒ ì£¼ ê³„íš)
    # -------------------------------------------------------------------------
    def _section_next_week_actions(self) -> str:
        """Next Week Actions - ë‹¤ìŒ ì£¼ ê³„íš"""
        content = "## Next Week Actions\n\n"
        content += "> ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ ì‘ì—…ì„ ì •ì˜í•©ë‹ˆë‹¤.\n\n"

        # ì´ì›” í•­ëª© ìë™ ì¶”ì¶œ (Dataview)
        content += "### ì´ì›” í•­ëª© (ìë™ ì§‘ê³„)\n\n"
        content += "```dataview\n"
        content += "LIST next_actions\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND length(next_actions) > 0\n"
        content += "FLATTEN next_actions\n"
        content += "LIMIT 10\n"
        content += "```\n\n"

        # ì£¼ê°„ ê²½ê³ ì‚¬í•­ ì§‘ê³„
        content += "### ê²½ê³ ì‚¬í•­ (ìë™ ì§‘ê³„)\n\n"
        content += "```dataview\n"
        content += "LIST warnings\n"
        content += 'FROM "ê°œë°œì¼ì§€"\n'
        content += f'WHERE created >= date("{self.week_start.strftime("%Y-%m-%d")}")\n'
        content += f'  AND created <= date("{self.week_end.strftime("%Y-%m-%d")}")\n'
        content += "  AND length(warnings) > 0\n"
        content += "FLATTEN warnings\n"
        content += "LIMIT 5\n"
        content += "```\n\n"

        # ìˆ˜ë™ ê³„íš
        content += "### ë‹¤ìŒ ì£¼ ìš°ì„ ìˆœìœ„ (ìˆ˜ë™ ì…ë ¥)\n\n"
        content += "| ìš°ì„ ìˆœìœ„ | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ë‹´ë‹¹ |\n"
        content += "|----------|------|----------|------|\n"
        content += "| P0 | (í•„ìˆ˜ ì‘ì—…) | - | - |\n"
        content += "| P1 | (ì¤‘ìš” ì‘ì—…) | - | - |\n"
        content += "| P2 | (ì„ íƒ ì‘ì—…) | - | - |\n"
        content += "\n"

        return content


class ObsidianAutoSync:
    """Obsidian ìë™ ë™ê¸°í™” í´ë˜ìŠ¤"""

    def __init__(self, repo_root: Path, vault_path: Optional[Path] = None):
        self.repo_root = repo_root
        self.vault_path = vault_path or self._get_default_vault_path()
        self.dev_log_dir = self.vault_path / "ê°œë°œì¼ì§€"

    def _get_default_vault_path(self) -> Path:
        """ê¸°ë³¸ Obsidian vault ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¨¼ì € í™•ì¸
        vault_env = os.getenv("OBSIDIAN_VAULT_PATH")
        if vault_env:
            return Path(vault_env)

        # Windows ê¸°ë³¸ ê²½ë¡œ
        default_path = Path.home() / "Documents" / "Obsidian Vault"
        if default_path.exists():
            return default_path

        # Fallback
        return Path.home() / "obsidian-vault"

    def get_commit_info(self, commit_hash: str) -> Dict:
        """ì»¤ë°‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ì»¤ë°‹ ë©”ì‹œì§€
            message = subprocess.check_output(
                ["git", "log", "-1", "--pretty=%B", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # ì»¤ë°‹ ì‹œê°„
            commit_time = subprocess.check_output(
                ["git", "log", "-1", "--pretty=%ai", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # ë³€ê²½ íŒŒì¼ ëª©ë¡
            files_changed = (
                subprocess.check_output(
                    ["git", "diff-tree", "--no-commit-id", "--name-only", "-r", commit_hash],
                    cwd=self.repo_root,
                    encoding="utf-8",
                    errors="replace",
                )
                .strip()
                .split("\n")
            )

            # í†µê³„
            stats = subprocess.check_output(
                ["git", "log", "-1", "--stat", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            # diff (ê°„ë‹¨í•œ ë²„ì „)
            diff = subprocess.check_output(
                ["git", "show", "--stat", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()

            return {
                "hash": commit_hash,
                "message": message,
                "time": commit_time,
                "files_changed": [f for f in files_changed if f],
                "stats": stats,
                "diff": diff,
            }
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] Failed to get commit info: {e}", file=sys.stderr)
            return {}

    def check_trigger_conditions(self, commit_info: Dict) -> Tuple[bool, str]:
        """íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸"""
        files_count = len(commit_info.get("files_changed", []))
        message = commit_info.get("message", "")

        # ì¡°ê±´ 1: 3ê°œ ì´ìƒ íŒŒì¼ ë³€ê²½
        if files_count >= 3:
            return True, f"{files_count} files changed (>=3)"

        # ì¡°ê±´ 2: feat:/fix:/docs: ë“± ì»¤ë°‹ ë©”ì‹œì§€
        trigger_patterns = [r"^feat:", r"^feature:", r"^fix:", r"^bug:", r"^docs:", r"^refactor:", r"^analyze:", r"^analysis:"]

        for pattern in trigger_patterns:
            if re.match(pattern, message, re.IGNORECASE):
                return True, f"Commit message matches: {pattern}"

        return False, f"No trigger (files: {files_count}, message: {message[:30]}...)"

    def generate_ai_insights(self, commit_info: Dict) -> Dict[str, List[str]]:
        """AI ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„± (íŒ¨í„´ ê¸°ë°˜)"""
        files = commit_info.get("files_changed", [])
        message = commit_info.get("message", "")
        diff = commit_info.get("diff", "")

        insights = {"learned": [], "challenges": [], "next_steps": []}

        # ë°°ìš´ ì  ì¶”ì¶œ
        if any("test" in f.lower() for f in files):
            insights["learned"].append("TDD ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìš°ì„  ì‘ì„±")

        if "refactor" in message.lower():
            insights["learned"].append("ì½”ë“œ êµ¬ì¡° ê°œì„ ì„ í†µí•œ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ")

        if any(keyword in message.lower() for keyword in ["performance", "optimize"]):
            insights["learned"].append("ì„±ëŠ¥ ìµœì í™” ê¸°ë²• ì ìš©")

        if any(keyword in message.lower() for keyword in ["security", "auth"]):
            insights["learned"].append("ë³´ì•ˆ ê°•í™” ë°©ë²• í•™ìŠµ")

        if len(files) >= 5:
            insights["learned"].append("ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì ìš© (ë‹¤ìˆ˜ íŒŒì¼ ë™ì‹œ ì‘ì—…)")

        # ì‹œí–‰ì°©ì˜¤ ê°ì§€
        if "fix" in message.lower():
            insights["challenges"].append(f"ë¬¸ì œ ë°œê²¬: {message.split(':')[0]} â†’ í•´ê²° ì™„ë£Œ")

        if len(files) > 10:
            insights["challenges"].append("ëŒ€ê·œëª¨ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ë³µì¡ë„ ê´€ë¦¬")

        # ë‹¤ìŒ ë‹¨ê³„ (TODO ì£¼ì„ ì¶”ì¶œ)
        todo_pattern = r"#\s*TODO:?\s*(.+)"
        todos_found = re.findall(todo_pattern, diff)
        if todos_found:
            insights["next_steps"].extend([f"TODO: {todo}" for todo in todos_found[:3]])

        # ê¸°ë³¸ ë‹¤ìŒ ë‹¨ê³„
        if "feat" in message.lower():
            insights["next_steps"].append("í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")

        if "fix" in message.lower():
            insights["next_steps"].append("íšŒê·€ í…ŒìŠ¤íŠ¸ë¡œ ì¬ë°œ ë°©ì§€ í™•ì¸")

        return insights

    def categorize_work_type(self, commit_info: Dict) -> str:
        """ì‘ì—… ìœ í˜• ë¶„ë¥˜"""
        message = commit_info.get("message", "").lower()

        if any(kw in message for kw in ["feat", "feature", "add"]):
            return "feature"
        elif any(kw in message for kw in ["fix", "bug", "resolve"]):
            return "bugfix"
        elif "refactor" in message:
            return "refactor"
        elif any(kw in message for kw in ["docs", "document"]):
            return "documentation"
        elif "test" in message:
            return "testing"
        else:
            return "maintenance"

    def generate_frontmatter(self, commit_info: Dict, work_type: str) -> str:
        """YAML frontmatter ìƒì„±"""
        commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
        today = commit_time.strftime("%Y-%m-%d")
        time_str = commit_time.strftime("%H:%M")

        # íŒŒì¼ ë¶„ë¥˜
        files = commit_info.get("files_changed", [])
        tags = ["commit"]

        if any("test" in f.lower() for f in files):
            tags.append("testing")
        if any("docs" in f.lower() for f in files):
            tags.append("documentation")
        if work_type not in tags:
            tags.append(work_type)

        # Topic ìƒì„± (ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„ì—ì„œ)
        topic = commit_info.get("message", "").split("\n")[0]
        if ":" in topic:
            topic = topic.split(":", 1)[1].strip()

        frontmatter = f"""---
date: {today}
time: "{time_str}"
project: UDO-Development-Platform
topic: {topic}
commit: {commit_info['hash'][:7]}
type: {work_type}
tags: [{', '.join(tags)}]
files_changed: {len(files)}
---
"""
        return frontmatter

    # =========================================================================
    # v3.0: Extended Frontmatter Generator (14 fields)
    # =========================================================================

    def generate_frontmatter_v3(
        self, commit_info: Dict, work_type: str, flags: Dict[str, bool], ai_context: Dict[str, Any]
    ) -> str:
        """v3.0 Frontmatter ìƒì„± (14ê°œ í•„ë“œ)"""
        commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
        today = commit_time.strftime("%Y-%m-%d")

        # Topic ì¶”ì¶œ (ì»¤ë°‹ ë©”ì‹œì§€ ì²« ì¤„)
        topic = commit_info.get("message", "").split("\n")[0]
        if ":" in topic:
            topic = topic.split(":", 1)[1].strip()
        topic = topic[:50]  # ìµœëŒ€ 50ì

        # íƒœê·¸ ìƒì„±
        tags = self._generate_tags_v3(commit_info, work_type, flags)

        # Frontmatter ë°ì´í„° êµ¬ì¡°
        frontmatter_data = {
            # ê¸°ë³¸ (4)
            "title": f"{today} {topic}",
            "created": today,
            "type": "daily",
            "status": "completed",
            # í”Œë˜ê·¸ (7)
            "has_til": flags.get("has_til", False),
            "has_solution": flags.get("has_solution", False),
            "has_pattern": flags.get("has_pattern", False),
            "has_uncertainty": flags.get("has_uncertainty", False),
            "has_rollback": flags.get("has_rollback", False),
            "has_debt": flags.get("has_debt", False),
            "has_decision": flags.get("has_decision", False),
            # AI ì»¨í…ìŠ¤íŠ¸ (3)
            "context_summary": ai_context.get("summary", ""),
            "next_actions": ai_context.get("next_actions", []),
            "warnings": ai_context.get("warnings", []),
            # ìë™ ìˆ˜ì§‘ (2)
            "files_changed": len(commit_info.get("files_changed", [])),
            "commits": self._count_today_commits(commit_time),
            # Schema ë²„ì „ (1)
            "schema_version": "1.0",
            # ë¶„ë¥˜ íƒœê·¸
            "tags": tags,
        }

        # YAML safe dump (ë°°ì—´ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)
        yaml_content = yaml.dump(frontmatter_data, default_flow_style=False, allow_unicode=True, sort_keys=False)

        return f"---\n{yaml_content}---\n"

    def _generate_tags_v3(self, commit_info: Dict, work_type: str, flags: Dict[str, bool]) -> List[str]:
        """v3.0 íƒœê·¸ ìƒì„±"""
        tags = ["commit", work_type]
        files = commit_info.get("files_changed", [])

        # íŒŒì¼ ê¸°ë°˜ íƒœê·¸
        if any("test" in f.lower() for f in files):
            tags.append("testing")
        if any("docs" in f.lower() for f in files):
            tags.append("documentation")
        if any("backend" in f.lower() for f in files):
            tags.append("backend")
        if any("frontend" in f.lower() or "web-dashboard" in f.lower() for f in files):
            tags.append("frontend")

        # í”Œë˜ê·¸ ê¸°ë°˜ íƒœê·¸
        if flags.get("has_debt"):
            tags.append("tech-debt")
        if flags.get("has_decision"):
            tags.append("decision")

        return list(set(tags))  # ì¤‘ë³µ ì œê±°

    def _count_today_commits(self, commit_time: datetime) -> int:
        """ë‹¹ì¼ ì»¤ë°‹ ìˆ˜ ê³„ì‚°"""
        try:
            today_str = commit_time.strftime("%Y-%m-%d")
            result = subprocess.check_output(
                ["git", "log", "--oneline", f"--since={today_str} 00:00:00", f"--until={today_str} 23:59:59"],
                cwd=self.repo_root,
                encoding="utf-8",
                errors="replace",
            ).strip()
            return len([line for line in result.split("\n") if line])
        except subprocess.CalledProcessError:
            return 1

    def _get_full_diff(self, commit_hash: str) -> str:
        """ì „ì²´ diff ê°€ì ¸ì˜¤ê¸°"""
        try:
            return subprocess.check_output(
                ["git", "show", "--format=", commit_hash], cwd=self.repo_root, encoding="utf-8", errors="replace"
            ).strip()
        except subprocess.CalledProcessError:
            return ""

    def _load_session_state(self) -> Dict:
        """session_state.json ë¡œë“œ"""
        session_file = self.repo_root / ".udo" / "session_state.json"

        if not session_file.exists():
            return {}

        try:
            with open(session_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}

    def generate_dev_log(self, commit_info: Dict) -> str:
        """ê°œë°œì¼ì§€ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        work_type = self.categorize_work_type(commit_info)
        frontmatter = self.generate_frontmatter(commit_info, work_type)
        insights = self.generate_ai_insights(commit_info)

        # ì»¤ë°‹ ë©”ì‹œì§€
        message = commit_info.get("message", "")
        message_lines = message.split("\n")
        title = message_lines[0]
        description = "\n".join(message_lines[1:]).strip() if len(message_lines) > 1 else ""

        # íŒŒì¼ ë³€ê²½ ì‚¬í•­
        files = commit_info.get("files_changed", [])
        files_by_category = {
            "Backend": [f for f in files if f.startswith("backend/")],
            "Frontend": [f for f in files if f.startswith("web-dashboard/")],
            "Docs": [f for f in files if f.startswith("docs/")],
            "Scripts": [f for f in files if f.startswith("scripts/")],
            "Tests": [f for f in files if "test" in f.lower()],
            "Other": [],
        }

        # Other ì¹´í…Œê³ ë¦¬ ì±„ìš°ê¸°
        categorized = sum(files_by_category.values(), [])
        files_by_category["Other"] = [f for f in files if f not in categorized]

        # ë§ˆí¬ë‹¤ìš´ ìƒì„±
        content = frontmatter + f"\n# {title}\n\n"

        if description:
            content += f"{description}\n\n"

        content += "## ë³€ê²½ ì‚¬í•­\n\n"
        for category, category_files in files_by_category.items():
            if category_files:
                content += f"### {category} ({len(category_files)})\n"
                for file in category_files[:10]:  # ìµœëŒ€ 10ê°œë§Œ
                    content += f"- `{file}`\n"
                if len(category_files) > 10:
                    content += f"- ... and {len(category_files) - 10} more\n"
                content += "\n"

        # AI ì¸ì‚¬ì´íŠ¸
        if insights["learned"]:
            content += "## ğŸ’¡ ë°°ìš´ ì \n\n"
            for item in insights["learned"]:
                content += f"- {item}\n"
            content += "\n"

        if insights["challenges"]:
            content += "## ğŸ”§ ì‹œí–‰ì°©ì˜¤\n\n"
            for item in insights["challenges"]:
                content += f"- {item}\n"
            content += "\n"

        if insights["next_steps"]:
            content += "## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„\n\n"
            for item in insights["next_steps"]:
                content += f"- {item}\n"
            content += "\n"

        # ì»¤ë°‹ í†µê³„
        content += "## ğŸ“Š í†µê³„\n\n"
        content += f"```\n{commit_info.get('stats', '')}\n```\n\n"

        content += f"**ì»¤ë°‹ í•´ì‹œ**: `{commit_info['hash'][:7]}`  \n"
        content += f"**ì‘ì„± ì‹œê°**: {commit_info['time']}  \n"
        content += "**ìë™ ìƒì„±**: Obsidian Auto-Sync v2.0  \n"

        return content

    def sync(self, commit_hash: str, version: int = 2) -> bool:
        """Obsidian ë™ê¸°í™” ì‹¤í–‰

        Args:
            commit_hash: Git ì»¤ë°‹ í•´ì‹œ
            version: ì‚¬ìš©í•  ë²„ì „ (2=v2.0, 3=v3.0)
        """
        try:
            # 1. ì»¤ë°‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            commit_info = self.get_commit_info(commit_hash)
            if not commit_info:
                print("[ERROR] Failed to get commit info", file=sys.stderr)
                return False

            # 2. íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¸
            triggered, reason = self.check_trigger_conditions(commit_info)
            if not triggered:
                print(f"[SKIP] Trigger condition not met: {reason}")
                return True  # ì—ëŸ¬ëŠ” ì•„ë‹˜

            print(f"[TRIGGER] {reason}")

            # 3. ê°œë°œì¼ì§€ ìƒì„± (ë²„ì „ì— ë”°ë¼ ë¶„ê¸°)
            if version >= 3:
                dev_log_content = self.generate_dev_log_v3(commit_info)
                version_str = "v3.0"
            else:
                dev_log_content = self.generate_dev_log(commit_info)
                version_str = "v2.0"

            # 4. Obsidianì— ì €ì¥
            commit_time = datetime.fromisoformat(commit_info["time"].split("+")[0].strip())
            date_folder = commit_time.strftime("%Y-%m-%d")
            topic = commit_info.get("message", "").split("\n")[0].replace(":", "-").replace("/", "-")[:50]
            filename = f"{topic}.md"

            # ë‚ ì§œ í´ë” ìƒì„±
            date_dir = self.dev_log_dir / date_folder
            date_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            file_path = date_dir / filename
            file_path.write_text(dev_log_content, encoding="utf-8")

            print(f"[OK] Obsidian dev log created ({version_str}): {date_folder}/{filename}")
            return True

        except Exception as e:
            print(f"[ERROR] Sync failed: {e}", file=sys.stderr)
            import traceback

            traceback.print_exc()
            return False

    # =========================================================================
    # v3.0: Full Dev Log Generator (9 Daily Sections)
    # =========================================================================

    def generate_dev_log_v3(self, commit_info: Dict) -> str:
        """v3.0 ê°œë°œì¼ì§€ ë§ˆí¬ë‹¤ìš´ ìƒì„± (9ê°œ Daily ì„¹ì…˜)"""
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        work_type = self.categorize_work_type(commit_info)
        commit_hash = commit_info.get("hash", "HEAD")

        # ì „ì²´ diff ê°€ì ¸ì˜¤ê¸°
        full_diff = self._get_full_diff(commit_hash)

        # í”Œë˜ê·¸ ê°ì§€
        flag_detector = FlagDetector(full_diff, commit_info)
        flags = flag_detector.detect_all()

        # AI ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        ai_context_gen = AIContextGenerator(commit_info, full_diff)
        ai_context = ai_context_gen.generate()

        # v3 Frontmatter ìƒì„±
        frontmatter = self.generate_frontmatter_v3(commit_info, work_type, flags, ai_context)

        # ì„¸ì…˜ ìƒíƒœ ë¡œë“œ
        session_state = self._load_session_state()

        # ì„¹ì…˜ ìƒì„±ê¸° ì´ˆê¸°í™”
        section_gen = SectionGenerator(
            commit_info=commit_info, flags=flags, session_state=session_state, diff=full_diff, repo_root=self.repo_root
        )

        # ì „ì²´ ì½˜í…ì¸  ì¡°í•©
        content = frontmatter
        content += section_gen.generate_all_sections()

        # í‘¸í„°
        content += "\n---\n"
        content += f"**ì»¤ë°‹ í•´ì‹œ**: `{commit_info['hash'][:7]}`  \n"
        content += f"**ì‘ì„± ì‹œê°**: {commit_info['time']}  \n"
        content += "**ìë™ ìƒì„±**: Obsidian Auto-Sync v3.0  \n"

        return content

    # =========================================================================
    # v3.0: Weekly Sync Method
    # =========================================================================

    def sync_weekly(self, week_offset: int = 0) -> bool:
        """ì£¼ê°„ ìš”ì•½ ë™ê¸°í™” ì‹¤í–‰

        Args:
            week_offset: 0=ì´ë²ˆ ì£¼, -1=ì§€ë‚œ ì£¼, -2=2ì£¼ ì „ ë“±
        """
        try:
            # ì£¼ê°„ ë²”ìœ„ ê³„ì‚°
            today = datetime.now()
            # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ ì°¾ê¸°
            week_start = today - timedelta(days=today.weekday())
            week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)

            # offset ì ìš©
            week_start = week_start + timedelta(weeks=week_offset)
            week_end = week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)

            print(f"[WEEKLY] Generating summary for {week_start.strftime('%Y-%m-%d')} ~ {week_end.strftime('%Y-%m-%d')}")

            # Weekly ìƒì„±ê¸° ì´ˆê¸°í™”
            weekly_gen = WeeklySummaryGenerator(week_start, week_end)
            weekly_content = weekly_gen.generate_weekly_note()

            # ì €ì¥ ê²½ë¡œ ì„¤ì • (ê°œë°œì¼ì§€/Weekly/)
            weekly_dir = self.dev_log_dir / "Weekly"
            weekly_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ëª…
            week_str = week_start.strftime("%Y-W%W")
            filename = f"{week_str}-weekly-summary.md"
            file_path = weekly_dir / filename

            # ì €ì¥
            file_path.write_text(weekly_content, encoding="utf-8")

            print(f"[OK] Weekly summary created: Weekly/{filename}")
            return True

        except Exception as e:
            print(f"[ERROR] Weekly sync failed: {e}", file=sys.stderr)
            import traceback

            traceback.print_exc()
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Obsidian Auto-Sync v3.0 - AI-Enhanced Development Log Generator")
    parser.add_argument("--commit-hash", default="HEAD", help="Commit hash to sync")
    parser.add_argument("--vault", help="Obsidian vault path (optional)")
    parser.add_argument(
        "--version", type=int, default=2, choices=[2, 3], help="Sync version (2=v2.0, 3=v3.0 with extended frontmatter)"
    )
    parser.add_argument("--weekly", action="store_true", help="Generate weekly summary instead of daily log")
    parser.add_argument("--week-offset", type=int, default=0, help="Week offset for weekly summary (0=current, -1=last week)")
    args = parser.parse_args()

    # Repo root ì°¾ê¸°
    repo_root = Path(__file__).resolve().parents[1]

    # Vault ê²½ë¡œ
    vault_path = Path(args.vault) if args.vault else None

    # ë™ê¸°í™” ì‹¤í–‰
    syncer = ObsidianAutoSync(repo_root, vault_path)

    if args.weekly:
        # ì£¼ê°„ ìš”ì•½ ìƒì„±
        success = syncer.sync_weekly(week_offset=args.week_offset)
    else:
        # ì¼ì¼ ë¡œê·¸ ìƒì„±
        success = syncer.sync(args.commit_hash, version=args.version)

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
