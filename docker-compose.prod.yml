version: '3.8'

# ================================
# UDO Platform - Production Docker Compose
# ================================
# Usage: docker-compose -f docker-compose.prod.yml up -d
#
# Prerequisites:
# 1. Copy .env.production.example to .env and fill in values
# 2. Ensure SSL certificates are in place (if using HTTPS)
# 3. Configure firewall rules
# 4. Set up monitoring alerts
#
# ================================

services:
  # ================================
  # PostgreSQL Database with pgvector
  # ================================
  db:
    image: pgvector/pgvector:pg16
    container_name: udo_postgres_prod
    restart: always
    ports:
      - "${DB_PORT:-5432}:5432"
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
      # Performance tuning
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_WORK_MEM: 16MB
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/01-init.sql
      - ./backups:/backups  # Backup directory
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Redis for Caching and Task Queue
  # ================================
  redis:
    image: redis:7-alpine
    container_name: udo_redis_prod
    restart: always
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_prod_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--pass", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # FastAPI Backend
  # ================================
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    image: udo-backend:production
    container_name: udo_backend_prod
    restart: always
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      # Database
      DB_HOST: db
      DB_PORT: 5432
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_POOL_MIN: ${DB_POOL_MIN:-5}
      DB_POOL_MAX: ${DB_POOL_MAX:-20}

      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}

      # API Keys
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}

      # Security
      JWT_SECRET: ${JWT_SECRET}
      JWT_ALGORITHM: ${JWT_ALGORITHM:-HS256}
      JWT_EXPIRATION_HOURS: ${JWT_EXPIRATION_HOURS:-24}

      # Environment
      ENVIRONMENT: production
      DEBUG: "False"
      LOG_LEVEL: INFO

      # CORS
      CORS_ORIGINS: ${CORS_ORIGINS}

      # Rate Limiting
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-true}
      RATE_LIMIT_PER_MINUTE: ${RATE_LIMIT_PER_MINUTE:-60}

      # Monitoring
      SENTRY_DSN: ${SENTRY_DSN}
      SENTRY_ENVIRONMENT: production
      ENABLE_PERFORMANCE_MONITORING: ${ENABLE_PERFORMANCE_MONITORING:-true}

    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/api/status', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ================================
  # Next.js Frontend
  # ================================
  frontend:
    build:
      context: .
      dockerfile: web-dashboard/Dockerfile
    image: udo-frontend:production
    container_name: udo_frontend_prod
    restart: always
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-https://api.yourdomain.com}
      NEXT_TELEMETRY_DISABLED: 1
    depends_on:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3000', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ================================
  # Nginx Reverse Proxy (Optional but Recommended)
  # ================================
  nginx:
    image: nginx:alpine
    container_name: udo_nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro  # SSL certificates
      - nginx_cache:/var/cache/nginx
    depends_on:
      - backend
      - frontend
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    profiles:
      - with-nginx  # Optional: use --profile with-nginx

  # ================================
  # Prometheus Monitoring
  # ================================
  prometheus:
    image: prom/prometheus:latest
    container_name: udo_prometheus_prod
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_prod_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=90d'  # 90 days retention
      - '--web.enable-lifecycle'
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Grafana Dashboards
  # ================================
  grafana:
    image: grafana/grafana:latest
    container_name: udo_grafana_prod
    restart: always
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3001}
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_prod_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Automated Backup Service
  # ================================
  backup:
    image: prodrigestivill/postgres-backup-local:16-alpine
    container_name: udo_backup
    restart: always
    environment:
      POSTGRES_HOST: db
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      SCHEDULE: ${BACKUP_SCHEDULE:-0 2 * * *}  # 2 AM UTC daily
      BACKUP_KEEP_DAYS: ${BACKUP_RETENTION_DAYS:-30}
      BACKUP_KEEP_WEEKS: 4
      BACKUP_KEEP_MONTHS: 6
    volumes:
      - ./backups:/backups
    depends_on:
      - db
    networks:
      - udo_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    profiles:
      - with-backup  # Optional: use --profile with-backup

# ================================
# Volumes (Persistent Data)
# ================================
volumes:
  postgres_prod_data:
    driver: local
  redis_prod_data:
    driver: local
  prometheus_prod_data:
    driver: local
  grafana_prod_data:
    driver: local
  nginx_cache:
    driver: local

# ================================
# Networks
# ================================
networks:
  udo_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16

# ================================
# Production Deployment Commands
# ================================
# 1. Build images:
#    docker-compose -f docker-compose.prod.yml build
#
# 2. Start services:
#    docker-compose -f docker-compose.prod.yml up -d
#
# 3. With optional services:
#    docker-compose -f docker-compose.prod.yml --profile with-nginx --profile with-backup up -d
#
# 4. View logs:
#    docker-compose -f docker-compose.prod.yml logs -f backend
#
# 5. Stop services:
#    docker-compose -f docker-compose.prod.yml down
#
# 6. Backup database manually:
#    docker exec udo_postgres_prod pg_dump -U ${DB_USER} ${DB_NAME} > backup.sql
#
# 7. Restore database:
#    docker exec -i udo_postgres_prod psql -U ${DB_USER} ${DB_NAME} < backup.sql
#
# ================================
