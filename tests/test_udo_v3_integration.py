#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UDO v2 + Uncertainty Map v3 í†µí•© í…ŒìŠ¤íŠ¸
ëª¨ë“  Phaseì— ëŒ€í•œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import sys
import os
from pathlib import Path
from datetime import datetime
import json

# Windows Unicode ì¸ì½”ë”© ë¬¸ì œ ê·¼ë³¸ í•´ê²°
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')

# ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent.parent / "obsidian-vibe-coding-docs" / "scripts"))

from unified_development_orchestrator_v2 import (
    UnifiedDevelopmentOrchestratorV2 as UnifiedDevelopmentOrchestrator,
    ProjectContext
)

def print_section(title: str, char: str = "="):
    """ì„¹ì…˜ êµ¬ë¶„ ì¶œë ¥"""
    line = char * 80
    print(f"\n{line}")
    print(f"  {title}")
    print(line)

def run_phase_test(udo, phase_name: str, request: str, expected_files: list = None):
    """íŠ¹ì • Phase í…ŒìŠ¤íŠ¸"""
    print_section(f"PHASE TEST: {phase_name.upper()}", "=")

    # Phase ì—…ë°ì´íŠ¸
    udo.context.current_phase = phase_name
    if expected_files:
        udo.context.files = expected_files

    print(f"ğŸ“Œ Phase: {phase_name}")
    print(f"ğŸ“ Request: {request[:100]}...")
    print(f"ğŸ“‚ Files: {len(udo.context.files)} files")

    # ê°œë°œ ì‚¬ì´í´ ì‹¤í–‰
    plan = udo.start_development_cycle(request)

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š Results:")
    print(f"  Decision: {plan.get('decision', 'UNKNOWN')}")
    print(f"  Confidence: {plan.get('confidence', 0):.1%}")
    print(f"  System: {plan.get('system', {}).get('system', 'N/A')}")

    # ë¶ˆí™•ì‹¤ì„± ì˜ˆì¸¡ í™•ì¸
    if hasattr(udo.uncertainty, 'predictions'):
        print(f"\nğŸ“ˆ Uncertainty Predictions:")
        for key, pred_model in udo.uncertainty.predictions.items():
            if hasattr(pred_model, 'trend'):
                print(f"  {key}: {pred_model.trend} trend")

    # ì‹¤í–‰ (GO ê²°ì •ì¸ ê²½ìš°)
    if plan['decision'] in ['GO', 'GO_WITH_CHECKPOINTS']:
        result = udo.execute_plan(plan)
        udo.record_outcome(plan, result)
        print(f"\nâœ… Execution: {result.get('status', 'UNKNOWN')}")
    else:
        print(f"\nâš ï¸ No execution: {plan['decision']}")

    return plan

def main():
    print_section("UDO v2 + UNCERTAINTY MAP v3 INTEGRATION TEST", "=")
    print("Testing all phases with predictive uncertainty modeling\n")

    # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    project = ProjectContext(
        project_name="AI-SaaS-Platform",
        goal="AI ê¸°ë°˜ SaaS í”Œë«í¼ ê°œë°œ",
        team_size=5,
        timeline_weeks=16,
        budget=100000,
        tech_stack=["Next.js 15", "FastAPI", "PostgreSQL", "Redis"],
        constraints=["4ê°œì›” ë‚´ ì¶œì‹œ", "í´ë¼ìš°ë“œ ë¹„ìš© ìµœì í™”"],
        success_metrics=["MAU 5000+", "MRR $5,000+", "Churn < 5%"],
        current_phase="ideation",
        files=[],
        metadata={
            "ai_tools": ["Claude Code", "Codex", "Gemini"],
            "target_launch": "2025-03-01",
            "quality_standard": "Enterprise-grade"
        }
    )

    # UDO ì´ˆê¸°í™”
    print("ğŸš€ Initializing UDO v2 with Uncertainty Map v3...")
    udo = UnifiedDevelopmentOrchestrator(project)

    # Phase 1: Ideation
    phase1_result = run_phase_test(
        udo,
        "ideation",
        "AI ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ìë™í™” SaaS í”Œë«í¼ ì•„ì´ë””ì–´ ê²€ì¦"
    )

    # Phase 2: Design
    phase2_result = run_phase_test(
        udo,
        "design",
        "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„ with API Gateway, Auth Service, Review Service",
        expected_files=["docs/architecture.md", "docs/api_spec.yaml"]
    )

    # Phase 3: MVP
    phase3_result = run_phase_test(
        udo,
        "mvp",
        "í•µì‹¬ ê¸°ëŠ¥ MVP êµ¬í˜„: GitHub ì—°ë™, ê¸°ë³¸ ë¦¬ë·° ì—”ì§„, ëŒ€ì‹œë³´ë“œ",
        expected_files=[
            "src/api/github.py",
            "src/api/review.py",
            "src/frontend/dashboard.tsx"
        ]
    )

    # Phase 4: Implementation
    phase4_result = run_phase_test(
        udo,
        "implementation",
        "ì „ì²´ ê¸°ëŠ¥ êµ¬í˜„ with ML ëª¨ë¸ í†µí•©, ì‹¤ì‹œê°„ ì•Œë¦¼, íŒ€ í˜‘ì—… ê¸°ëŠ¥",
        expected_files=[
            "src/api/github.py",
            "src/api/review.py",
            "src/ml/model.py",
            "src/workers/notification.py",
            "tests/test_review.py"
        ]
    )

    # Phase 5: Testing
    phase5_result = run_phase_test(
        udo,
        "testing",
        "ì¢…í•© í…ŒìŠ¤íŠ¸: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸, ë¶€í•˜ í…ŒìŠ¤íŠ¸, ë³´ì•ˆ í…ŒìŠ¤íŠ¸",
        expected_files=[
            "tests/unit/",
            "tests/integration/",
            "tests/load/",
            "tests/security/",
            "coverage.xml"
        ]
    )

    # ìµœì¢… ë¦¬í¬íŠ¸
    print_section("FINAL REPORT", "=")

    # í•™ìŠµ ë°ì´í„° ë¶„ì„
    if udo.learning_data:
        print("\nğŸ“š Learning Data:")
        for phase, perf in udo.learning_data.get('phase_performance', {}).items():
            success_rate = perf.get('success_rate', 0)
            total = perf.get('total', 0)
            print(f"  {phase}: {success_rate:.1%} success ({total} attempts)")

    # ë¶ˆí™•ì‹¤ì„± ì§„í™” ë¶„ì„
    if hasattr(udo, 'uncertainty_tracker'):
        print("\nğŸ“‰ Uncertainty Evolution:")
        history = udo.uncertainty_tracker.confidence_history
        if history:
            print(f"  Initial confidence: {history[0]:.1%}")
            print(f"  Final confidence: {history[-1]:.1%}")
            print(f"  Average confidence: {sum(history)/len(history):.1%}")
            print(f"  Trend: {'Improving â†‘' if history[-1] > history[0] else 'Declining â†“'}")

    # ìƒíƒœ ì €ì¥
    state_file = Path(__file__).parent / "udo_v3_test_state.json"
    udo.save_state(state_file)
    print(f"\nğŸ’¾ State saved to: {state_file}")

    # ì„±ê³µ ë©”íŠ¸ë¦­
    print_section("SUCCESS METRICS", "=")

    phases = ["ideation", "design", "mvp", "implementation", "testing"]
    results = [phase1_result, phase2_result, phase3_result, phase4_result, phase5_result]

    go_decisions = sum(1 for r in results if r.get('decision') == 'GO')
    avg_confidence = sum(r.get('confidence', 0) for r in results) / len(results)

    print(f"âœ… GO Decisions: {go_decisions}/{len(phases)} ({go_decisions/len(phases)*100:.0f}%)")
    print(f"ğŸ“Š Average Confidence: {avg_confidence:.1%}")
    print(f"ğŸ¯ Success Rate: {(go_decisions/len(phases) * avg_confidence):.1%}")

    if avg_confidence > 0.7 and go_decisions >= 4:
        print("\nğŸ† TEST PASSED: System is production-ready!")
    elif avg_confidence > 0.5 and go_decisions >= 3:
        print("\nâœ… TEST PASSED: System is functional with room for improvement")
    else:
        print("\nâš ï¸ TEST NEEDS WORK: System requires further optimization")

    print("\n" + "=" * 80)
    print("Test completed successfully!")
    print("=" * 80)

if __name__ == "__main__":
    main()